"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[67818],{25420:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"skills/speech_pathology_ai/references/therapy-interventions","title":"Therapy Intervention Strategies","description":"Minimal Pair Contrast Therapy","source":"@site/docs/skills/speech_pathology_ai/references/therapy-interventions.md","sourceDirName":"skills/speech_pathology_ai/references","slug":"/skills/speech_pathology_ai/references/therapy-interventions","permalink":"/docs/skills/speech_pathology_ai/references/therapy-interventions","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Therapy Intervention Strategies","sidebar_label":"Therapy Intervention Strate...","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"mellifluo.us Platform Integ...","permalink":"/docs/skills/speech_pathology_ai/references/mellifluo-platform"},"next":{"title":"Adhd Design Expert","permalink":"/docs/skills/adhd_design_expert/"}}');var i=t(74848),a=t(28453);const s={title:"Therapy Intervention Strategies",sidebar_label:"Therapy Intervention Strate...",sidebar_position:4},o="Therapy Intervention Strategies",c={},l=[{value:"Minimal Pair Contrast Therapy",id:"minimal-pair-contrast-therapy",level:2},{value:"Fluency Shaping Techniques",id:"fluency-shaping-techniques",level:2},{value:"AAC (Augmentative and Alternative Communication)",id:"aac-augmentative-and-alternative-communication",level:2},{value:"Progress Tracking &amp; Gamification",id:"progress-tracking--gamification",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",pre:"pre",...(0,a.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"therapy-intervention-strategies",children:"Therapy Intervention Strategies"})}),"\n",(0,i.jsx)(e.h2,{id:"minimal-pair-contrast-therapy",children:"Minimal Pair Contrast Therapy"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class MinimalPairTherapy:\n    \"\"\"\n    Therapy technique for phonological disorders\n    Uses word pairs differing by single phoneme\n    \"\"\"\n\n    minimal_pairs = {\n        'r_w': [\n            ('rip', 'whip'),\n            ('rake', 'wake'),\n            ('read', 'weed'),\n            ('row', 'woe')\n        ],\n        's_th': [\n            ('sink', 'think'),\n            ('song', 'thong'),\n            ('sum', 'thumb'),\n            ('sank', 'thank')\n        ],\n        'p_b': [\n            ('pan', 'ban'),\n            ('pear', 'bear'),\n            ('pine', 'bine'),\n            ('poke', 'broke')\n        ]\n    }\n\n    def generate_exercise(self, target_contrast):\n        \"\"\"\n        Generate discrimination and production exercises\n        \"\"\"\n        pairs = self.minimal_pairs.get(target_contrast, [])\n\n        # Discrimination task\n        discrimination = {\n            'instruction': \"Listen carefully. Are these words the same or different?\",\n            'trials': [\n                {'audio1': pair[0], 'audio2': pair[1], 'answer': 'different'}\n                for pair in pairs\n            ] + [\n                {'audio1': pair[0], 'audio2': pair[0], 'answer': 'same'}\n                for pair in pairs[:2]\n            ]\n        }\n\n        # Production task\n        production = {\n            'instruction': \"Look at the picture and say the word.\",\n            'trials': [\n                {'picture': pair[0], 'target': pair[0], 'foil': pair[1]}\n                for pair in pairs\n            ]\n        }\n\n        return {\n            'discrimination': discrimination,\n            'production': production\n        }\n"})}),"\n",(0,i.jsx)(e.h2,{id:"fluency-shaping-techniques",children:"Fluency Shaping Techniques"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class FluencyTherapy:\n    \"\"\"\n    Interventions for stuttering/cluttering\n    \"\"\"\n\n    @staticmethod\n    def easy_onset_exercise():\n        \"\"\"\n        Gentle initiation of voicing\n        \"\"\"\n        return {\n            'name': 'Easy Onset',\n            'description': 'Start words gently, like a whisper growing louder',\n            'practice_words': ['apple', 'ocean', 'elephant', 'umbrella'],\n            'instructions': [\n                '1. Take a breath',\n                '2. Start the word very softly',\n                '3. Gradually increase volume',\n                '4. Maintain airflow throughout'\n            ],\n            'visual_feedback': 'volume_meter'  # Show gradual volume increase\n        }\n\n    @staticmethod\n    def prolonged_speech():\n        \"\"\"\n        Slow, stretched speech pattern\n        \"\"\"\n        return {\n            'name': 'Prolonged Speech',\n            'target_rate': 60,  # words per minute (vs normal 150-200)\n            'technique': 'Stretch vowels, gentle transitions',\n            'practice_sentences': [\n                \"I am speaking slowly.\",\n                \"The cat is on the mat.\",\n                \"Today is a good day.\"\n            ],\n            'feedback': 'speech_rate_visualization'\n        }\n\n    def analyze_disfluencies(self, transcription, timestamps):\n        \"\"\"\n        Detect and categorize stuttering moments\n        \"\"\"\n        disfluencies = {\n            'repetitions': [],      # \"I-I-I want\"\n            'prolongations': [],    # \"Sssssnake\"\n            'blocks': [],           # Silent struggle\n            'interjections': []     # \"um\", \"uh\"\n        }\n\n        # Pattern matching for disfluencies\n        # (Would use audio analysis + transcription)\n\n        return disfluencies\n"})}),"\n",(0,i.jsx)(e.h2,{id:"aac-augmentative-and-alternative-communication",children:"AAC (Augmentative and Alternative Communication)"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-javascript",children:"class AACDevice {\n    constructor() {\n        this.vocabulary = this.loadCoreVocabulary();\n        this.userProfile = null;\n        this.predictionModel = null;\n    }\n\n    loadCoreVocabulary() {\n        // Fringe, Core vocabulary for AAC\n        return {\n            core: [\n                // High-frequency words (Fringe vocabulary)\n                'I', 'you', 'want', 'more', 'go', 'stop', 'help', 'yes', 'no',\n                'like', 'here', 'there', 'what', 'who', 'where'\n            ],\n            fringe: {\n                food: ['apple', 'banana', 'water', 'milk', 'snack'],\n                activities: ['play', 'read', 'watch', 'listen', 'walk'],\n                feelings: ['happy', 'sad', 'angry', 'tired', 'excited']\n            }\n        };\n    }\n\n    predictNextWord(currentPhrase) {\n        /**\n         * Word prediction using n-gram model or neural LM\n         * Speeds up communication significantly\n         */\n        const words = currentPhrase.split(' ');\n        const context = words.slice(-2);  // Bigram context\n\n        // Get predictions from model\n        const predictions = this.predictionModel.predict(context);\n\n        // Return top 5 predictions\n        return predictions.slice(0, 5);\n    }\n\n    speakPhrase(text, options = {}) {\n        const utterance = new SpeechSynthesisUtterance(text);\n\n        // Personalized voice settings\n        utterance.rate = options.rate || 1.0;\n        utterance.pitch = options.pitch || 1.0;\n        utterance.voice = this.userProfile?.preferredVoice || null;\n\n        speechSynthesis.speak(utterance);\n    }\n\n    createSymbolBoard(category) {\n        /**\n         * Generate visual symbol board (PCS, SymbolStix)\n         * For users who benefit from visual supports\n         */\n        return {\n            category,\n            symbols: this.vocabulary.fringe[category].map(word => ({\n                word,\n                symbol: `symbols/${word}.png`,\n                audio: `audio/${word}.mp3`\n            }))\n        };\n    }\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"progress-tracking--gamification",children:"Progress Tracking & Gamification"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import numpy as np\n\nclass TherapyProgressTracker:\n    def __init__(self, client_id):\n        self.client_id = client_id\n        self.baseline = None\n        self.sessions = []\n\n    def record_session(self, session_data):\n        \"\"\"\n        Track accuracy, consistency, generalization\n        \"\"\"\n        self.sessions.append({\n            'date': session_data['date'],\n            'target_sound': session_data['target'],\n            'accuracy': session_data['accuracy'],\n            'trials': session_data['trials'],\n            'context': session_data['context']  # isolation, word, sentence, conversation\n        })\n\n    def calculate_progress(self):\n        \"\"\"\n        Generate progress report\n        \"\"\"\n        if not self.sessions:\n            return None\n\n        recent = self.sessions[-5:]  # Last 5 sessions\n\n        avg_accuracy = np.mean([s['accuracy'] for s in recent])\n        consistency = np.std([s['accuracy'] for s in recent])\n\n        # Trend analysis\n        accuracies = [s['accuracy'] for s in self.sessions]\n        trend = np.polyfit(range(len(accuracies)), accuracies, deg=1)[0]\n\n        return {\n            'current_accuracy': avg_accuracy,\n            'consistency': consistency,\n            'trend': 'improving' if trend > 0 else 'stable' if abs(trend) < 0.01 else 'declining',\n            'sessions_completed': len(self.sessions),\n            'ready_for_generalization': avg_accuracy > 80 and consistency < 10\n        }\n\n    def suggest_next_step(self):\n        \"\"\"\n        Adaptive therapy progression\n        \"\"\"\n        progress = self.calculate_progress()\n\n        if progress['current_accuracy'] < 50:\n            return \"Continue with current level - focus on accuracy\"\n        elif progress['current_accuracy'] < 80:\n            return \"Increase difficulty slightly - add complexity\"\n        elif progress['ready_for_generalization']:\n            return \"Ready for generalization - move to conversation\"\n        else:\n            return \"Maintain current level - build consistency\"\n"})})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},28453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>o});var r=t(96540);const i={},a=r.createContext(i);function s(n){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),r.createElement(a.Provider,{value:e},n.children)}}}]);