"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[37257],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(96540);const l={},r=s.createContext(l);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},65485:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"skills/computer_vision_pipeline/references/yolo-guide","title":"YOLOv8 Guide","description":"Complete guide to YOLOv8 for object detection: setup, training, inference, and optimization.","source":"@site/docs/skills/computer_vision_pipeline/references/yolo-guide.md","sourceDirName":"skills/computer_vision_pipeline/references","slug":"/skills/computer_vision_pipeline/references/yolo-guide","permalink":"/docs/skills/computer_vision_pipeline/references/yolo-guide","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"YOLOv8 Guide","sidebar_label":"YOLOv8 Guide","sidebar_position":3}}');var l=i(74848),r=i(28453);const t={title:"YOLOv8 Guide",sidebar_label:"YOLOv8 Guide",sidebar_position:3},a="YOLOv8 Guide",d={},o=[{value:"Installation",id:"installation",level:2},{value:"Model Variants",id:"model-variants",level:2},{value:"Basic Inference",id:"basic-inference",level:2},{value:"Load Pre-trained Model",id:"load-pre-trained-model",level:3},{value:"Process Results",id:"process-results",level:3},{value:"Inference Options",id:"inference-options",level:2},{value:"Confidence and IoU Thresholds",id:"confidence-and-iou-thresholds",level:3},{value:"Image Size",id:"image-size",level:3},{value:"Device Selection",id:"device-selection",level:3},{value:"Max Detections",id:"max-detections",level:3},{value:"Batch Inference",id:"batch-inference",level:2},{value:"Training Custom Models",id:"training-custom-models",level:2},{value:"Dataset Format",id:"dataset-format",level:3},{value:"Train Model",id:"train-model",level:3},{value:"Resume Training",id:"resume-training",level:3},{value:"Augmentation",id:"augmentation",level:3},{value:"Validation",id:"validation",level:2},{value:"Export",id:"export",level:2},{value:"ONNX (Recommended for Production)",id:"onnx-recommended-for-production",level:3},{value:"Other Formats",id:"other-formats",level:3},{value:"CLI Usage",id:"cli-usage",level:2},{value:"Inference",id:"inference",level:3},{value:"Training",id:"training",level:3},{value:"Validation",id:"validation-1",level:3},{value:"Optimization Tips",id:"optimization-tips",level:2},{value:"1. Mixed Precision Training (FP16)",id:"1-mixed-precision-training-fp16",level:3},{value:"2. Optimal Batch Size",id:"2-optimal-batch-size",level:3},{value:"3. Freeze Layers",id:"3-freeze-layers",level:3},{value:"4. Multi-GPU Training",id:"4-multi-gpu-training",level:3},{value:"Common Issues",id:"common-issues",level:2},{value:"Out of Memory (OOM)",id:"out-of-memory-oom",level:3},{value:"Slow Training",id:"slow-training",level:3},{value:"Poor Accuracy",id:"poor-accuracy",level:3},{value:"Benchmarking",id:"benchmarking",level:2},{value:"Resources",id:"resources",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"yolov8-guide",children:"YOLOv8 Guide"})}),"\n",(0,l.jsx)(n.p,{children:"Complete guide to YOLOv8 for object detection: setup, training, inference, and optimization."}),"\n",(0,l.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Install ultralytics (includes YOLOv8)\npip install ultralytics\n\n# Verify installation\nyolo version\n\n# Install additional dependencies\npip install opencv-python numpy torch torchvision\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Latest version"}),": ultralytics 8.1.20 (Jan 2024)"]}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"model-variants",children:"Model Variants"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size (MB)"}),(0,l.jsx)(n.th,{children:"mAP50-95"}),(0,l.jsx)(n.th,{children:"Speed (ms)"}),(0,l.jsx)(n.th,{children:"Params (M)"}),(0,l.jsx)(n.th,{children:"Use Case"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"YOLOv8n"}),(0,l.jsx)(n.td,{children:"6"}),(0,l.jsx)(n.td,{children:"37.3%"}),(0,l.jsx)(n.td,{children:"80"}),(0,l.jsx)(n.td,{children:"3.2"}),(0,l.jsx)(n.td,{children:"Mobile, edge devices"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"YOLOv8s"}),(0,l.jsx)(n.td,{children:"22"}),(0,l.jsx)(n.td,{children:"44.9%"}),(0,l.jsx)(n.td,{children:"128"}),(0,l.jsx)(n.td,{children:"11.2"}),(0,l.jsx)(n.td,{children:"Embedded systems"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"YOLOv8m"}),(0,l.jsx)(n.td,{children:"52"}),(0,l.jsx)(n.td,{children:"50.2%"}),(0,l.jsx)(n.td,{children:"234"}),(0,l.jsx)(n.td,{children:"25.9"}),(0,l.jsx)(n.td,{children:"Balanced"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"YOLOv8l"}),(0,l.jsx)(n.td,{children:"88"}),(0,l.jsx)(n.td,{children:"52.9%"}),(0,l.jsx)(n.td,{children:"375"}),(0,l.jsx)(n.td,{children:"43.7"}),(0,l.jsx)(n.td,{children:"High accuracy"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"YOLOv8x"}),(0,l.jsx)(n.td,{children:"136"}),(0,l.jsx)(n.td,{children:"53.9%"}),(0,l.jsx)(n.td,{children:"479"}),(0,l.jsx)(n.td,{children:"68.2"}),(0,l.jsx)(n.td,{children:"Highest accuracy"})]})]})]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Naming"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"n"})," = nano (smallest)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"s"})," = small"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"m"})," = medium"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"l"})," = large"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"x"})," = extra large"]}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Speed measured on"}),": NVIDIA T4 GPU, batch size 1, image size 640x640"]}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"basic-inference",children:"Basic Inference"}),"\n",(0,l.jsx)(n.h3,{id:"load-pre-trained-model",children:"Load Pre-trained Model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"from ultralytics import YOLO\n\n# Load model\nmodel = YOLO('yolov8n.pt')  # nano model\n\n# Run inference on single image\nresults = model('image.jpg')\n\n# Access results\nfor result in results:\n    boxes = result.boxes  # Bounding boxes\n    masks = result.masks  # Segmentation masks (if using seg model)\n    probs = result.probs  # Classification probabilities\n"})}),"\n",(0,l.jsx)(n.h3,{id:"process-results",children:"Process Results"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"import cv2\n\nresults = model('image.jpg')\n\nfor result in results:\n    # Get bounding boxes\n    boxes = result.boxes\n\n    for box in boxes:\n        # Coordinates\n        x1, y1, x2, y2 = box.xyxy[0]  # Box coordinates\n\n        # Metadata\n        conf = box.conf[0]  # Confidence\n        cls = box.cls[0]    # Class ID\n        label = result.names[int(cls)]  # Class name\n\n        print(f\"{label} {conf:.2f} at ({x1}, {y1}, {x2}, {y2})\")\n\n        # Draw on image\n        img = result.orig_img\n        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n        cv2.putText(img, f'{label} {conf:.2f}', (int(x1), int(y1)-10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    cv2.imwrite('output.jpg', img)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"inference-options",children:"Inference Options"}),"\n",(0,l.jsx)(n.h3,{id:"confidence-and-iou-thresholds",children:"Confidence and IoU Thresholds"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"results = model(\n    'image.jpg',\n    conf=0.5,    # Confidence threshold (default: 0.25)\n    iou=0.7      # IoU threshold for NMS (default: 0.7)\n)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"image-size",children:"Image Size"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"results = model(\n    'image.jpg',\n    imgsz=640    # Image size (default: 640)\n                  # Can be single int or tuple (height, width)\n)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"device-selection",children:"Device Selection"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Use GPU\nresults = model('image.jpg', device=0)  # GPU 0\n\n# Use CPU\nresults = model('image.jpg', device='cpu')\n\n# Multiple GPUs\nresults = model('image.jpg', device=[0, 1])  # GPUs 0 and 1\n"})}),"\n",(0,l.jsx)(n.h3,{id:"max-detections",children:"Max Detections"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"results = model(\n    'image.jpg',\n    max_det=100  # Maximum detections per image (default: 300)\n)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"batch-inference",children:"Batch Inference"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# List of images\nimage_paths = ['img1.jpg', 'img2.jpg', 'img3.jpg']\nresults = model(image_paths)\n\n# Process results\nfor i, result in enumerate(results):\n    print(f\"Image {i}: {len(result.boxes)} detections\")\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"training-custom-models",children:"Training Custom Models"}),"\n",(0,l.jsx)(n.h3,{id:"dataset-format",children:"Dataset Format"}),"\n",(0,l.jsx)(n.p,{children:"YOLO requires this directory structure:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"dataset/\n\u251c\u2500\u2500 data.yaml\n\u251c\u2500\u2500 images/\n\u2502   \u251c\u2500\u2500 train/\n\u2502   \u2502   \u251c\u2500\u2500 img001.jpg\n\u2502   \u2502   \u2514\u2500\u2500 img002.jpg\n\u2502   \u2514\u2500\u2500 val/\n\u2502       \u251c\u2500\u2500 img101.jpg\n\u2502       \u2514\u2500\u2500 img102.jpg\n\u2514\u2500\u2500 labels/\n    \u251c\u2500\u2500 train/\n    \u2502   \u251c\u2500\u2500 img001.txt\n    \u2502   \u2514\u2500\u2500 img002.txt\n    \u2514\u2500\u2500 val/\n        \u251c\u2500\u2500 img101.txt\n        \u2514\u2500\u2500 img102.txt\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"data.yaml"}),":"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"path: /path/to/dataset\ntrain: images/train\nval: images/val\n\nnames:\n  0: dolphin\n  1: whale\n  2: shark\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Label format"})," (one line per object):"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"<class_id> <x_center> <y_center> <width> <height>\n"})}),"\n",(0,l.jsx)(n.p,{children:"All values normalized to [0, 1]."}),"\n",(0,l.jsxs)(n.p,{children:["Example (",(0,l.jsx)(n.code,{children:"img001.txt"}),"):"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"0 0.5 0.5 0.3 0.4\n1 0.7 0.3 0.2 0.2\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"train-model",children:"Train Model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"from ultralytics import YOLO\n\n# Load pre-trained model\nmodel = YOLO('yolov8n.pt')\n\n# Train\nresults = model.train(\n    data='data.yaml',\n    epochs=100,\n    imgsz=640,\n    batch=16,\n    name='dolphin_detector',\n    device=0\n)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Training parameters"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"epochs"}),": Number of training epochs"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"imgsz"}),": Image size (640, 1280, etc.)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"batch"}),": Batch size (reduce if OOM errors)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"patience"}),": Early stopping patience (default: 50)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"lr0"}),": Initial learning rate (default: 0.01)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"lrf"}),": Final learning rate (default: 0.01)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"momentum"}),": SGD momentum (default: 0.937)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"weight_decay"}),": Optimizer weight decay (default: 0.0005)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"warmup_epochs"}),": Warmup epochs (default: 3.0)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"save"}),": Save checkpoints (default: True)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"device"}),": GPU device (0, 1, ..., 'cpu')"]}),"\n"]}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"resume-training",children:"Resume Training"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Resume from last checkpoint\nmodel = YOLO('runs/detect/dolphin_detector/weights/last.pt')\nmodel.train(resume=True)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"augmentation",children:"Augmentation"}),"\n",(0,l.jsx)(n.p,{children:"YOLO automatically applies augmentations. You can customize:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(\n    data='data.yaml',\n    epochs=100,\n    # Augmentation parameters\n    hsv_h=0.015,       # HSV-Hue augmentation\n    hsv_s=0.7,         # HSV-Saturation augmentation\n    hsv_v=0.4,         # HSV-Value augmentation\n    degrees=0.0,       # Rotation (+/- deg)\n    translate=0.1,     # Translation (+/- fraction)\n    scale=0.5,         # Scale (+/- gain)\n    shear=0.0,         # Shear (+/- deg)\n    perspective=0.0,   # Perspective (+/- fraction)\n    flipud=0.0,        # Flip up-down (probability)\n    fliplr=0.5,        # Flip left-right (probability)\n    mosaic=1.0,        # Mosaic augmentation (probability)\n    mixup=0.0          # MixUp augmentation (probability)\n)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"validation",children:"Validation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Validate trained model\nmodel = YOLO(\'runs/detect/dolphin_detector/weights/best.pt\')\n\nmetrics = model.val(data=\'data.yaml\')\n\n# Access metrics\nprint(f"mAP50: {metrics.box.map50:.4f}")\nprint(f"mAP50-95: {metrics.box.map:.4f}")\nprint(f"Precision: {metrics.box.mp:.4f}")\nprint(f"Recall: {metrics.box.mr:.4f}")\n\n# Per-class metrics\nfor i, ap in enumerate(metrics.box.ap50):\n    print(f"Class {i} AP50: {ap:.4f}")\n'})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"export",children:"Export"}),"\n",(0,l.jsx)(n.h3,{id:"onnx-recommended-for-production",children:"ONNX (Recommended for Production)"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model = YOLO('best.pt')\n\n# Export to ONNX\nmodel.export(format='onnx', imgsz=640)\n\n# Use exported model\nonnx_model = YOLO('best.onnx')\nresults = onnx_model('image.jpg')\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Faster inference (~2x)"}),"\n",(0,l.jsx)(n.li,{children:"Smaller file size"}),"\n",(0,l.jsx)(n.li,{children:"Cross-platform compatibility"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"other-formats",children:"Other Formats"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# TorchScript\nmodel.export(format='torchscript')\n\n# CoreML (for iOS)\nmodel.export(format='coreml')\n\n# TensorFlow Lite (for mobile)\nmodel.export(format='tflite')\n\n# TensorFlow.js (for web)\nmodel.export(format='tfjs')\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"cli-usage",children:"CLI Usage"}),"\n",(0,l.jsx)(n.h3,{id:"inference",children:"Inference"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Single image\nyolo detect predict model=yolov8n.pt source=image.jpg\n\n# Video\nyolo detect predict model=yolov8n.pt source=video.mp4\n\n# Webcam\nyolo detect predict model=yolov8n.pt source=0\n\n# Directory\nyolo detect predict model=yolov8n.pt source=./images/\n\n# With options\nyolo detect predict model=yolov8n.pt source=image.jpg conf=0.5 iou=0.7 save=true\n"})}),"\n",(0,l.jsx)(n.h3,{id:"training",children:"Training"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"yolo detect train data=data.yaml model=yolov8n.pt epochs=100 imgsz=640\n"})}),"\n",(0,l.jsx)(n.h3,{id:"validation-1",children:"Validation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"yolo detect val model=best.pt data=data.yaml\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"optimization-tips",children:"Optimization Tips"}),"\n",(0,l.jsx)(n.h3,{id:"1-mixed-precision-training-fp16",children:"1. Mixed Precision Training (FP16)"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(\n    data='data.yaml',\n    epochs=100,\n    amp=True  # Automatic Mixed Precision (faster, less memory)\n)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"2x faster training"}),"\n",(0,l.jsx)(n.li,{children:"50% less GPU memory"}),"\n",(0,l.jsx)(n.li,{children:"Minimal accuracy loss"}),"\n"]}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"2-optimal-batch-size",children:"2. Optimal Batch Size"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Find max batch size for your GPU\nfor batch_size in [4, 8, 16, 32, 64]:\n    try:\n        model.train(data=\'data.yaml\', epochs=1, batch=batch_size)\n        print(f"Batch {batch_size}: OK")\n    except RuntimeError as e:\n        print(f"Batch {batch_size}: OOM")\n        break\n'})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"3-freeze-layers",children:"3. Freeze Layers"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Freeze backbone layers (faster convergence for similar data)\nmodel.train(\n    data='data.yaml',\n    epochs=100,\n    freeze=10  # Freeze first 10 layers\n)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"4-multi-gpu-training",children:"4. Multi-GPU Training"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Use all GPUs\nmodel.train(\n    data='data.yaml',\n    epochs=100,\n    device=[0, 1, 2, 3]  # Use GPUs 0-3\n)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"common-issues",children:"Common Issues"}),"\n",(0,l.jsx)(n.h3,{id:"out-of-memory-oom",children:"Out of Memory (OOM)"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 1"}),": Reduce batch size"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(batch=8)  # Instead of 16\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 2"}),": Reduce image size"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(imgsz=416)  # Instead of 640\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 3"}),": Use gradient accumulation"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Simulate larger batch size\nmodel.train(batch=4, accumulate=4)  # Effective batch size = 16\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"slow-training",children:"Slow Training"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 1"}),": Use smaller model"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model = YOLO('yolov8n.pt')  # Instead of yolov8x.pt\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 2"}),": Enable AMP"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(amp=True)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 3"}),": Use multiple workers"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(workers=8)  # More data loading workers\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h3,{id:"poor-accuracy",children:"Poor Accuracy"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 1"}),": Train longer"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(epochs=300, patience=100)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 2"}),": Increase image size"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(imgsz=1280)  # Higher resolution\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 3"}),": More data augmentation"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model.train(mosaic=1.0, mixup=0.15, copy_paste=0.3)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Solution 4"}),": Use larger model"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"model = YOLO('yolov8l.pt')  # Instead of yolov8n.pt\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"benchmarking",children:"Benchmarking"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"from ultralytics.utils.benchmarks import benchmark\n\n# Benchmark model\nbenchmark(model='yolov8n.pt', imgsz=640, half=False, device=0)\n"})}),"\n",(0,l.jsx)(n.p,{children:"Output:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"Model          Format    Size (MB)  mAP50-95  Inference (ms)\nyolov8n        PyTorch   6.2        37.3      80.2\nyolov8n        ONNX      12.4       37.3      42.1  (1.9x faster)\nyolov8n        TensorRT  13.1       37.3      28.5  (2.8x faster)\n"})}),"\n",(0,l.jsx)(n.hr,{}),"\n",(0,l.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://docs.ultralytics.com/",children:"YOLOv8 Documentation"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://github.com/ultralytics/ultralytics",children:"Ultralytics GitHub"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://github.com/ultralytics/assets/releases",children:"Model Zoo"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://docs.ultralytics.com/guides/model-training-tips/",children:"Training Tips"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}}}]);