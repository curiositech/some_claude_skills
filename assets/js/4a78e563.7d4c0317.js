"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[38772],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var r=t(96540);const i={},s=r.createContext(i);function o(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(s.Provider,{value:n},e.children)}},56315:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>l,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"skills/automatic_stateful_prompt_improver/references/mcp-server-spec","title":"MCP Server Specification: Prompt Learning Server","description":"This document specifies the MCP server implementation for stateful prompt learning.","source":"@site/docs/skills/automatic_stateful_prompt_improver/references/mcp-server-spec.md","sourceDirName":"skills/automatic_stateful_prompt_improver/references","slug":"/skills/automatic_stateful_prompt_improver/references/mcp-server-spec","permalink":"/docs/skills/automatic_stateful_prompt_improver/references/mcp-server-spec","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"MCP Server Specification: Prompt Learning Server","sidebar_label":"MCP Server Specification: P...","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Learning Architecture","permalink":"/docs/skills/automatic_stateful_prompt_improver/references/learning-architecture"},"next":{"title":"Optimization Techniques","permalink":"/docs/skills/automatic_stateful_prompt_improver/references/optimization-techniques"}}');var i=t(74848),s=t(28453);const o={title:"MCP Server Specification: Prompt Learning Server",sidebar_label:"MCP Server Specification: P...",sidebar_position:6},a="MCP Server Specification: Prompt Learning Server",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Tools",id:"tools",level:2},{value:"1. <code>retrieve_prompts</code>",id:"1-retrieve_prompts",level:3},{value:"2. <code>record_feedback</code>",id:"2-record_feedback",level:3},{value:"3. <code>suggest_improvements</code>",id:"3-suggest_improvements",level:3},{value:"4. <code>get_analytics</code>",id:"4-get_analytics",level:3},{value:"Implementation",id:"implementation",level:2},{value:"TypeScript Server",id:"typescript-server",level:3},{value:"Setup Instructions",id:"setup-instructions",level:2},{value:"1. Prerequisites",id:"1-prerequisites",level:3},{value:"2. Initialize Vector Collection",id:"2-initialize-vector-collection",level:3},{value:"3. Configure Claude Code",id:"3-configure-claude-code",level:3},{value:"Data Model",id:"data-model",level:2},{value:"Prompt Embedding Record",id:"prompt-embedding-record",level:3},{value:"Session State (Redis)",id:"session-state-redis",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Monitoring",id:"monitoring",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mcp-server-specification-prompt-learning-server",children:"MCP Server Specification: Prompt Learning Server"})}),"\n",(0,i.jsx)(n.p,{children:"This document specifies the MCP server implementation for stateful prompt learning."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"prompt-learning"})," MCP server provides persistent storage and retrieval of prompt performance data, enabling the skill to learn and improve over time."]}),"\n",(0,i.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Claude Code                          \u2502\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502     automatic-stateful-prompt-improver        \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                       \u2502 MCP Protocol                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       \u25bc                              \u2502\n\u2502            prompt-learning MCP Server                \u2502\n\u2502                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Tools     \u2502  \u2502  Resources  \u2502  \u2502   State     \u2502  \u2502\n\u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502  \u2502\n\u2502  \u2502 retrieve    \u2502  \u2502 performance \u2502  \u2502   Redis     \u2502  \u2502\n\u2502  \u2502 record      \u2502  \u2502 analytics   \u2502  \u2502   Cache     \u2502  \u2502\n\u2502  \u2502 suggest     \u2502  \u2502 history     \u2502  \u2502             \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u2502                \u2502                \u2502          \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                          \u2502                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                 \u25bc                 \u2502\n         \u2502          Vector Database          \u2502\n         \u2502     (Qdrant / Pinecone / Chroma)  \u2502\n         \u2502                                   \u2502\n         \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n         \u2502  \u2502     Prompt Embeddings       \u2502  \u2502\n         \u2502  \u2502   + Performance Metrics     \u2502  \u2502\n         \u2502  \u2502   + Metadata                \u2502  \u2502\n         \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n         \u2502                                   \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h2,{id:"tools",children:"Tools"}),"\n",(0,i.jsxs)(n.h3,{id:"1-retrieve_prompts",children:["1. ",(0,i.jsx)(n.code,{children:"retrieve_prompts"})]}),"\n",(0,i.jsx)(n.p,{children:"Retrieve similar high-performing prompts from the embedding database."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Input Schema"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "type": "object",\n  "properties": {\n    "query": {\n      "type": "string",\n      "description": "The prompt to find similar examples for"\n    },\n    "domain": {\n      "type": "string",\n      "description": "Domain classification (e.g., \'code_review\', \'summarization\')"\n    },\n    "top_k": {\n      "type": "integer",\n      "default": 5,\n      "description": "Number of results to return"\n    },\n    "min_performance": {\n      "type": "number",\n      "default": 0.7,\n      "description": "Minimum success_rate threshold"\n    }\n  },\n  "required": ["query"]\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "results": [\n    {\n      "prompt_id": "uuid",\n      "prompt_text": "string",\n      "similarity_score": 0.92,\n      "metrics": {\n        "success_rate": 0.85,\n        "avg_latency_ms": 450,\n        "token_efficiency": 0.78\n      },\n      "domain": "code_review",\n      "created_at": "2024-01-15T10:30:00Z"\n    }\n  ]\n}\n'})}),"\n",(0,i.jsxs)(n.h3,{id:"2-record_feedback",children:["2. ",(0,i.jsx)(n.code,{children:"record_feedback"})]}),"\n",(0,i.jsx)(n.p,{children:"Record the outcome of a prompt execution for learning."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Input Schema"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "type": "object",\n  "properties": {\n    "prompt_id": {\n      "type": "string",\n      "description": "ID of the prompt (or \'new\' to create)"\n    },\n    "prompt_text": {\n      "type": "string",\n      "description": "The prompt text (required if prompt_id is \'new\')"\n    },\n    "domain": {\n      "type": "string",\n      "description": "Domain classification"\n    },\n    "outcome": {\n      "type": "object",\n      "properties": {\n        "success": {"type": "boolean"},\n        "latency_ms": {"type": "number"},\n        "output_tokens": {"type": "integer"},\n        "quality_score": {"type": "number", "minimum": 0, "maximum": 1}\n      },\n      "required": ["success"]\n    },\n    "user_feedback": {\n      "type": "object",\n      "properties": {\n        "satisfaction": {"type": "number", "minimum": 0, "maximum": 1},\n        "comments": {"type": "string"}\n      }\n    }\n  },\n  "required": ["prompt_id", "outcome"]\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "status": "recorded",\n  "prompt_id": "uuid",\n  "updated_metrics": {\n    "success_rate": 0.82,\n    "observation_count": 15\n  }\n}\n'})}),"\n",(0,i.jsxs)(n.h3,{id:"3-suggest_improvements",children:["3. ",(0,i.jsx)(n.code,{children:"suggest_improvements"})]}),"\n",(0,i.jsx)(n.p,{children:"Generate improvement suggestions based on similar high-performers."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Input Schema"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "type": "object",\n  "properties": {\n    "prompt": {\n      "type": "string",\n      "description": "The prompt to improve"\n    },\n    "current_performance": {\n      "type": "object",\n      "properties": {\n        "success_rate": {"type": "number"},\n        "avg_latency_ms": {"type": "number"},\n        "token_efficiency": {"type": "number"}\n      }\n    },\n    "improvement_focus": {\n      "type": "string",\n      "enum": ["clarity", "specificity", "efficiency", "all"],\n      "default": "all"\n    }\n  },\n  "required": ["prompt"]\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "suggestions": [\n    {\n      "type": "add_structure",\n      "description": "Add numbered output format",\n      "example": "Respond with:\\n1. Summary\\n2. Key points\\n3. Recommendations",\n      "expected_improvement": 0.15\n    }\n  ],\n  "based_on": {\n    "similar_prompts_analyzed": 5,\n    "avg_performance_of_similar": 0.87\n  }\n}\n'})}),"\n",(0,i.jsxs)(n.h3,{id:"4-get_analytics",children:["4. ",(0,i.jsx)(n.code,{children:"get_analytics"})]}),"\n",(0,i.jsx)(n.p,{children:"Retrieve performance analytics and trends."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Input Schema"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "type": "object",\n  "properties": {\n    "domain": {\n      "type": "string",\n      "description": "Filter by domain (optional)"\n    },\n    "time_range": {\n      "type": "string",\n      "enum": ["7d", "30d", "90d", "all"],\n      "default": "30d"\n    },\n    "metrics": {\n      "type": "array",\n      "items": {"type": "string"},\n      "default": ["success_rate", "token_efficiency"]\n    }\n  }\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "summary": {\n    "total_prompts": 150,\n    "avg_success_rate": 0.78,\n    "improvement_trend": 0.05\n  },\n  "by_domain": {\n    "code_review": {"count": 45, "avg_success": 0.82},\n    "summarization": {"count": 30, "avg_success": 0.75}\n  },\n  "top_patterns": [\n    {"pattern": "structured_output", "success_rate": 0.89},\n    {"pattern": "chain_of_thought", "success_rate": 0.85}\n  ]\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(n.h3,{id:"typescript-server",children:"TypeScript Server"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { Server } from "@modelcontextprotocol/sdk/server/index.js";\nimport { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";\nimport { QdrantClient } from "@qdrant/js-client-rest";\nimport Redis from "ioredis";\n\n// Configuration\nconst EMBEDDING_MODEL = "text-embedding-3-large";\nconst EMBEDDING_DIM = 3072;\nconst COLLECTION_NAME = "prompt_embeddings";\n\ninterface PromptMetrics {\n  success_rate: number;\n  avg_latency_ms: number;\n  token_efficiency: number;\n  observation_count: number;\n}\n\nclass PromptLearningServer {\n  private server: Server;\n  private vectorDb: QdrantClient;\n  private cache: Redis;\n  private embeddingClient: any; // OpenAI or similar\n\n  constructor() {\n    this.server = new Server(\n      { name: "prompt-learning", version: "1.0.0" },\n      { capabilities: { tools: {}, resources: {} } }\n    );\n\n    this.vectorDb = new QdrantClient({\n      url: process.env.VECTOR_DB_URL || "http://localhost:6333"\n    });\n\n    this.cache = new Redis(process.env.REDIS_URL || "redis://localhost:6379");\n\n    this.registerTools();\n  }\n\n  private registerTools() {\n    this.server.setRequestHandler("tools/list", async () => ({\n      tools: [\n        {\n          name: "retrieve_prompts",\n          description: "Find similar high-performing prompts",\n          inputSchema: { /* schema above */ }\n        },\n        {\n          name: "record_feedback",\n          description: "Record prompt execution outcome",\n          inputSchema: { /* schema above */ }\n        },\n        {\n          name: "suggest_improvements",\n          description: "Generate improvement suggestions",\n          inputSchema: { /* schema above */ }\n        },\n        {\n          name: "get_analytics",\n          description: "Get performance analytics",\n          inputSchema: { /* schema above */ }\n        }\n      ]\n    }));\n\n    this.server.setRequestHandler("tools/call", async (request) => {\n      const { name, arguments: args } = request.params;\n\n      switch (name) {\n        case "retrieve_prompts":\n          return await this.retrievePrompts(args);\n        case "record_feedback":\n          return await this.recordFeedback(args);\n        case "suggest_improvements":\n          return await this.suggestImprovements(args);\n        case "get_analytics":\n          return await this.getAnalytics(args);\n        default:\n          throw new Error(`Unknown tool: ${name}`);\n      }\n    });\n  }\n\n  private async retrievePrompts(args: any) {\n    // 1. Generate embedding for query\n    const queryEmbedding = await this.getEmbedding(args.query);\n\n    // 2. Search vector DB\n    const results = await this.vectorDb.search(COLLECTION_NAME, {\n      vector: queryEmbedding,\n      limit: args.top_k * 2, // Over-retrieve for filtering\n      filter: {\n        must: [\n          { key: "metrics.success_rate", range: { gte: args.min_performance } }\n        ],\n        ...(args.domain && {\n          must: [{ key: "domain", match: { value: args.domain } }]\n        })\n      }\n    });\n\n    // 3. Format and return\n    return {\n      content: [{\n        type: "text",\n        text: JSON.stringify({\n          results: results.slice(0, args.top_k).map(r => ({\n            prompt_id: r.id,\n            prompt_text: r.payload?.prompt_text,\n            similarity_score: r.score,\n            metrics: r.payload?.metrics,\n            domain: r.payload?.domain\n          }))\n        })\n      }]\n    };\n  }\n\n  private async recordFeedback(args: any) {\n    const alpha = 0.3; // EMA weight for new observations\n\n    // Get or create prompt record\n    let metrics: PromptMetrics;\n    if (args.prompt_id === "new") {\n      // Create new prompt\n      const embedding = await this.getEmbedding(args.prompt_text);\n      const promptId = crypto.randomUUID();\n\n      metrics = {\n        success_rate: args.outcome.success ? 1.0 : 0.0,\n        avg_latency_ms: args.outcome.latency_ms || 0,\n        token_efficiency: args.outcome.quality_score || 0,\n        observation_count: 1\n      };\n\n      await this.vectorDb.upsert(COLLECTION_NAME, {\n        points: [{\n          id: promptId,\n          vector: embedding,\n          payload: {\n            prompt_text: args.prompt_text,\n            domain: args.domain,\n            metrics,\n            created_at: new Date().toISOString()\n          }\n        }]\n      });\n\n      args.prompt_id = promptId;\n    } else {\n      // Update existing\n      const existing = await this.vectorDb.retrieve(COLLECTION_NAME, {\n        ids: [args.prompt_id],\n        with_payload: true\n      });\n\n      if (existing.length === 0) {\n        throw new Error("Prompt not found");\n      }\n\n      const oldMetrics = existing[0].payload?.metrics as PromptMetrics;\n\n      // Exponential moving average update\n      metrics = {\n        success_rate: alpha * (args.outcome.success ? 1 : 0) + (1 - alpha) * oldMetrics.success_rate,\n        avg_latency_ms: alpha * (args.outcome.latency_ms || 0) + (1 - alpha) * oldMetrics.avg_latency_ms,\n        token_efficiency: alpha * (args.outcome.quality_score || oldMetrics.token_efficiency) + (1 - alpha) * oldMetrics.token_efficiency,\n        observation_count: oldMetrics.observation_count + 1\n      };\n\n      await this.vectorDb.setPayload(COLLECTION_NAME, {\n        points: [args.prompt_id],\n        payload: { metrics }\n      });\n    }\n\n    return {\n      content: [{\n        type: "text",\n        text: JSON.stringify({\n          status: "recorded",\n          prompt_id: args.prompt_id,\n          updated_metrics: metrics\n        })\n      }]\n    };\n  }\n\n  private async suggestImprovements(args: any) {\n    // Retrieve similar high-performers\n    const similar = await this.retrievePrompts({\n      query: args.prompt,\n      top_k: 5,\n      min_performance: 0.8\n    });\n\n    // Analyze patterns in high performers\n    // (In production, this would use an LLM to generate suggestions)\n\n    return {\n      content: [{\n        type: "text",\n        text: JSON.stringify({\n          suggestions: [\n            // Pattern-based suggestions\n          ],\n          based_on: {\n            similar_prompts_analyzed: 5,\n            avg_performance_of_similar: 0.87\n          }\n        })\n      }]\n    };\n  }\n\n  private async getAnalytics(args: any) {\n    // Aggregate metrics from vector DB\n    // (Implementation depends on specific vector DB capabilities)\n\n    return {\n      content: [{\n        type: "text",\n        text: JSON.stringify({\n          summary: {\n            total_prompts: 0,\n            avg_success_rate: 0,\n            improvement_trend: 0\n          }\n        })\n      }]\n    };\n  }\n\n  private async getEmbedding(text: string): Promise<number[]> {\n    // Call embedding API (OpenAI, Cohere, etc.)\n    // Implementation depends on your embedding provider\n    return [];\n  }\n\n  async start() {\n    const transport = new StdioServerTransport();\n    await this.server.connect(transport);\n  }\n}\n\nconst server = new PromptLearningServer();\nserver.start();\n'})}),"\n",(0,i.jsx)(n.h2,{id:"setup-instructions",children:"Setup Instructions"}),"\n",(0,i.jsx)(n.h3,{id:"1-prerequisites",children:"1. Prerequisites"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install dependencies\nnpm install @modelcontextprotocol/sdk @qdrant/js-client-rest ioredis openai\n\n# Start Qdrant (Docker)\ndocker run -p 6333:6333 qdrant/qdrant\n\n# Start Redis (Docker)\ndocker run -p 6379:6379 redis\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-initialize-vector-collection",children:"2. Initialize Vector Collection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'const client = new QdrantClient({ url: "http://localhost:6333" });\n\nawait client.createCollection("prompt_embeddings", {\n  vectors: {\n    size: 3072, // text-embedding-3-large\n    distance: "Cosine"\n  }\n});\n\n// Create payload indexes for filtering\nawait client.createPayloadIndex("prompt_embeddings", {\n  field_name: "metrics.success_rate",\n  field_schema: "float"\n});\n\nawait client.createPayloadIndex("prompt_embeddings", {\n  field_name: "domain",\n  field_schema: "keyword"\n});\n'})}),"\n",(0,i.jsx)(n.h3,{id:"3-configure-claude-code",children:"3. Configure Claude Code"}),"\n",(0,i.jsxs)(n.p,{children:["Add to your ",(0,i.jsx)(n.code,{children:"claude_desktop_config.json"})," or project config:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "mcpServers": {\n    "prompt-learning": {\n      "command": "node",\n      "args": ["/path/to/prompt-learning-server/dist/index.js"],\n      "env": {\n        "VECTOR_DB_URL": "http://localhost:6333",\n        "REDIS_URL": "redis://localhost:6379",\n        "OPENAI_API_KEY": "sk-..."\n      }\n    }\n  }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"data-model",children:"Data Model"}),"\n",(0,i.jsx)(n.h3,{id:"prompt-embedding-record",children:"Prompt Embedding Record"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'interface PromptRecord {\n  id: string;                    // UUID\n  vector: number[];              // Embedding (3072 dim)\n  payload: {\n    prompt_text: string;         // Original prompt\n    contextualized: string;      // With domain context\n    domain: string;              // Classification\n    task_type: string;           // e.g., "classification", "generation"\n    metrics: {\n      success_rate: number;      // 0-1, EMA\n      avg_latency_ms: number;    // Response time\n      token_efficiency: number;  // quality/tokens\n      observation_count: number; // How many times evaluated\n    };\n    created_at: string;          // ISO timestamp\n    updated_at: string;          // Last metric update\n    tags: string[];              // User-defined tags\n  };\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"session-state-redis",children:"Session State (Redis)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface SessionState {\n  session_id: string;\n  user_id: string;\n  current_prompt_id: string | null;\n  iteration_count: number;\n  best_score: number;\n  history: Array<{\n    prompt_id: string;\n    score: number;\n    timestamp: string;\n  }>;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data Isolation"}),": Use Redis key prefixes for multi-tenant isolation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"API Keys"}),": Store securely, rotate regularly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Rate Limiting"}),": Implement per-user rate limits"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Encryption"}),": TLS for all connections, encryption at rest for sensitive prompts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GDPR"}),": Implement user data deletion workflows"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"monitoring",children:"Monitoring"}),"\n",(0,i.jsx)(n.p,{children:"Track these metrics:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Embedding latency (p50, p95, p99)"}),"\n",(0,i.jsx)(n.li,{children:"Retrieval latency (p50, p95, p99)"}),"\n",(0,i.jsx)(n.li,{children:"Success rate improvement over time"}),"\n",(0,i.jsx)(n.li,{children:"Cache hit rate"}),"\n",(0,i.jsx)(n.li,{children:"Error rates by tool"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:"This MCP server enables the prompt improver skill to learn and adapt over time, making each optimization better informed by past successes."})]})}function l(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}}}]);