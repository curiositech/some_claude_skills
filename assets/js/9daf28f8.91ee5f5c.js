"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6833],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var i=t(96540);const o={},s=i.createContext(o);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},30326:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"skills/dag_performance_profiler/index","title":"\ud83d\udce6 Dag Performance Profiler","description":"Profiles DAG execution performance including latency, token usage, cost, and resource consumption. Identifies bottlenecks and optimization opportunities. Activate on \'performance profile\', \'execution metrics\', \'latency analysis\', \'token usage\', \'cost analysis\'. NOT for execution tracing (use dag-execution-tracer) or failure analysis (use dag-failure-analyzer).","source":"@site/docs/skills/dag_performance_profiler/index.md","sourceDirName":"skills/dag_performance_profiler","slug":"/skills/dag_performance_profiler/","permalink":"/docs/skills/dag_performance_profiler/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Dag Performance Profiler","sidebar_position":1}}');var o=t(74848),s=t(28453);const r={sidebar_label:"Dag Performance Profiler",sidebar_position:1},a="\ud83d\udce6 Dag Performance Profiler",c={},l=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"Core Responsibilities",id:"core-responsibilities",level:2},{value:"1. Metrics Collection",id:"1-metrics-collection",level:3},{value:"2. Bottleneck Detection",id:"2-bottleneck-detection",level:3},{value:"3. Optimization Recommendations",id:"3-optimization-recommendations",level:3},{value:"4. Cost Analysis",id:"4-cost-analysis",level:3},{value:"Profiler Architecture",id:"profiler-architecture",level:2},{value:"Metrics Collection",id:"metrics-collection",level:2},{value:"Aggregate Metrics",id:"aggregate-metrics",level:2},{value:"Bottleneck Detection",id:"bottleneck-detection",level:2},{value:"Optimization Recommendations",id:"optimization-recommendations",level:2},{value:"Performance Report",id:"performance-report",level:2},{value:"Integration Points",id:"integration-points",level:2},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"-dag-performance-profiler",children:"\ud83d\udce6 Dag Performance Profiler"})}),"\n",(0,o.jsx)(n.p,{children:"Profiles DAG execution performance including latency, token usage, cost, and resource consumption. Identifies bottlenecks and optimization opportunities. Activate on 'performance profile', 'execution metrics', 'latency analysis', 'token usage', 'cost analysis'. NOT for execution tracing (use dag-execution-tracer) or failure analysis (use dag-failure-analyzer)."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Read, Write, Edit, Glob, Grep\n"})}),"\n",(0,o.jsx)(n.h2,{id:"tags",children:"Tags"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"dag"})," ",(0,o.jsx)(n.code,{children:"observability"})," ",(0,o.jsx)(n.code,{children:"performance"})," ",(0,o.jsx)(n.code,{children:"metrics"})," ",(0,o.jsx)(n.code,{children:"optimization"})]}),"\n",(0,o.jsx)(n.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"/docs/skills/dag_execution_tracer",children:"Dag Execution Tracer"})}),": Uses execution traces"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"/docs/skills/dag_failure_analyzer",children:"Dag Failure Analyzer"})}),": Performance-related failures"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"/docs/skills/dag_pattern_learner",children:"Dag Pattern Learner"})}),": Provides performance patterns"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"/docs/skills/dag_task_scheduler",children:"Dag Task Scheduler"})}),": Scheduling optimization"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"You are a DAG Performance Profiler, an expert at analyzing execution performance across DAG workflows. You measure latency, token usage, cost, and resource consumption to identify bottlenecks, optimize scheduling, and provide actionable performance insights."}),"\n",(0,o.jsx)(n.h2,{id:"core-responsibilities",children:"Core Responsibilities"}),"\n",(0,o.jsx)(n.h3,{id:"1-metrics-collection",children:"1. Metrics Collection"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Track execution latency"}),"\n",(0,o.jsx)(n.li,{children:"Measure token consumption"}),"\n",(0,o.jsx)(n.li,{children:"Calculate costs"}),"\n",(0,o.jsx)(n.li,{children:"Monitor resource usage"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"2-bottleneck-detection",children:"2. Bottleneck Detection"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Identify slow nodes"}),"\n",(0,o.jsx)(n.li,{children:"Find critical paths"}),"\n",(0,o.jsx)(n.li,{children:"Detect resource contention"}),"\n",(0,o.jsx)(n.li,{children:"Locate inefficiencies"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"3-optimization-recommendations",children:"3. Optimization Recommendations"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Suggest parallelization"}),"\n",(0,o.jsx)(n.li,{children:"Recommend caching"}),"\n",(0,o.jsx)(n.li,{children:"Propose model selection"}),"\n",(0,o.jsx)(n.li,{children:"Identify redundancy"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"4-cost-analysis",children:"4. Cost Analysis"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Track per-node costs"}),"\n",(0,o.jsx)(n.li,{children:"Calculate total execution cost"}),"\n",(0,o.jsx)(n.li,{children:"Project costs at scale"}),"\n",(0,o.jsx)(n.li,{children:"Compare execution strategies"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"profiler-architecture",children:"Profiler Architecture"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"interface PerformanceProfile {\n  profileId: string;\n  traceId: string;\n  dagId: string;\n  profiledAt: Date;\n  metrics: AggregateMetrics;\n  nodeMetrics: Map<NodeId, NodeMetrics>;\n  analysis: PerformanceAnalysis;\n  recommendations: Optimization[];\n}\n\ninterface AggregateMetrics {\n  totalDuration: number;\n  totalTokens: TokenMetrics;\n  totalCost: CostMetrics;\n  parallelizationEfficiency: number;\n  criticalPathDuration: number;\n  resourceUtilization: ResourceMetrics;\n}\n\ninterface TokenMetrics {\n  inputTokens: number;\n  outputTokens: number;\n  totalTokens: number;\n  byModel: Record<string, number>;\n  byNode: Record<NodeId, number>;\n}\n\ninterface CostMetrics {\n  totalCost: number;\n  byModel: Record<string, number>;\n  byNode: Record<NodeId, number>;\n  currency: 'USD';\n}\n\ninterface NodeMetrics {\n  nodeId: NodeId;\n  duration: number;\n  waitTime: number;       // Time waiting for dependencies\n  executionTime: number;  // Actual execution time\n  tokens: TokenMetrics;\n  cost: number;\n  toolCalls: ToolCallMetrics[];\n  retries: number;\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"metrics-collection",children:"Metrics Collection"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"const MODEL_PRICING: Record<string, { input: number; output: number }> = {\n  'haiku': { input: 0.00025, output: 0.00125 },      // per 1K tokens\n  'sonnet': { input: 0.003, output: 0.015 },\n  'opus': { input: 0.015, output: 0.075 },\n};\n\nfunction collectNodeMetrics(\n  trace: ExecutionTrace,\n  span: TraceSpan\n): NodeMetrics {\n  const toolCalls = extractToolCalls(trace, span.spanId);\n  const tokens = calculateTokens(span, toolCalls);\n  const model = span.attributes['dag.model'] as string ?? 'sonnet';\n\n  return {\n    nodeId: span.nodeId,\n    duration: span.duration ?? 0,\n    waitTime: calculateWaitTime(trace, span),\n    executionTime: (span.duration ?? 0) - calculateWaitTime(trace, span),\n    tokens: {\n      inputTokens: tokens.input,\n      outputTokens: tokens.output,\n      totalTokens: tokens.input + tokens.output,\n      byModel: { [model]: tokens.input + tokens.output },\n      byNode: { [span.nodeId]: tokens.input + tokens.output },\n    },\n    cost: calculateCost(tokens, model),\n    toolCalls: toolCalls.map(tc => ({\n      tool: tc.tool,\n      duration: tc.duration,\n      success: tc.success,\n    })),\n    retries: span.attributes['dag.retries'] as number ?? 0,\n  };\n}\n\nfunction calculateCost(\n  tokens: { input: number; output: number },\n  model: string\n): number {\n  const pricing = MODEL_PRICING[model] ?? MODEL_PRICING.sonnet;\n  return (\n    (tokens.input / 1000) * pricing.input +\n    (tokens.output / 1000) * pricing.output\n  );\n}\n\nfunction calculateWaitTime(trace: ExecutionTrace, span: TraceSpan): number {\n  if (!span.parentSpanId) return 0;\n\n  const parent = trace.spans.get(span.parentSpanId);\n  if (!parent?.endTime) return 0;\n\n  // Time between parent ending and this span starting\n  return Math.max(\n    0,\n    span.startTime.getTime() - parent.endTime.getTime()\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"aggregate-metrics",children:"Aggregate Metrics"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"function aggregateMetrics(\n  nodeMetrics: Map<NodeId, NodeMetrics>,\n  trace: ExecutionTrace\n): AggregateMetrics {\n  let totalDuration = 0;\n  let totalInputTokens = 0;\n  let totalOutputTokens = 0;\n  let totalCost = 0;\n  const tokensByModel: Record<string, number> = {};\n  const costByModel: Record<string, number> = {};\n\n  for (const metrics of nodeMetrics.values()) {\n    totalDuration = Math.max(totalDuration, metrics.duration);\n    totalInputTokens += metrics.tokens.inputTokens;\n    totalOutputTokens += metrics.tokens.outputTokens;\n    totalCost += metrics.cost;\n\n    for (const [model, tokens] of Object.entries(metrics.tokens.byModel)) {\n      tokensByModel[model] = (tokensByModel[model] ?? 0) + tokens;\n      costByModel[model] = (costByModel[model] ?? 0) + calculateCost(\n        { input: tokens * 0.4, output: tokens * 0.6 }, // Estimate split\n        model\n      );\n    }\n  }\n\n  const criticalPath = findCriticalPath(trace);\n  const criticalPathDuration = criticalPath.reduce(\n    (sum, nodeId) => sum + (nodeMetrics.get(nodeId)?.executionTime ?? 0),\n    0\n  );\n\n  const sumExecutionTime = Array.from(nodeMetrics.values())\n    .reduce((sum, m) => sum + m.executionTime, 0);\n\n  return {\n    totalDuration,\n    totalTokens: {\n      inputTokens: totalInputTokens,\n      outputTokens: totalOutputTokens,\n      totalTokens: totalInputTokens + totalOutputTokens,\n      byModel: tokensByModel,\n      byNode: Object.fromEntries(\n        Array.from(nodeMetrics.entries()).map(\n          ([id, m]) => [id, m.tokens.totalTokens]\n        )\n      ),\n    },\n    totalCost: {\n      totalCost,\n      byModel: costByModel,\n      byNode: Object.fromEntries(\n        Array.from(nodeMetrics.entries()).map(\n          ([id, m]) => [id, m.cost]\n        )\n      ),\n      currency: 'USD',\n    },\n    parallelizationEfficiency: criticalPathDuration / sumExecutionTime,\n    criticalPathDuration,\n    resourceUtilization: calculateResourceUtilization(nodeMetrics, trace),\n  };\n}\n\nfunction findCriticalPath(trace: ExecutionTrace): NodeId[] {\n  // Find the longest path through the DAG\n  const spans = Array.from(trace.spans.values());\n  const endTimes: Record<string, number> = {};\n\n  for (const span of spans) {\n    const parentEnd = span.parentSpanId\n      ? endTimes[span.parentSpanId] ?? 0\n      : 0;\n    endTimes[span.spanId] = parentEnd + (span.duration ?? 0);\n  }\n\n  // Find span with latest end time\n  let maxSpanId = '';\n  let maxEnd = 0;\n  for (const [id, end] of Object.entries(endTimes)) {\n    if (end > maxEnd) {\n      maxEnd = end;\n      maxSpanId = id;\n    }\n  }\n\n  // Trace back to find path\n  const path: NodeId[] = [];\n  let current = maxSpanId;\n  while (current) {\n    const span = trace.spans.get(current);\n    if (!span) break;\n    path.unshift(span.nodeId);\n    current = span.parentSpanId ?? '';\n  }\n\n  return path;\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"bottleneck-detection",children:"Bottleneck Detection"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"interface Bottleneck {\n  type: BottleneckType;\n  nodeId: NodeId;\n  severity: 'low' | 'medium' | 'high';\n  impact: number;  // Percentage of total time\n  details: string;\n  recommendation: string;\n}\n\ntype BottleneckType =\n  | 'slow_node'\n  | 'high_token_usage'\n  | 'excessive_retries'\n  | 'tool_latency'\n  | 'dependency_wait'\n  | 'sequential_bottleneck';\n\nfunction detectBottlenecks(\n  metrics: AggregateMetrics,\n  nodeMetrics: Map<NodeId, NodeMetrics>\n): Bottleneck[] {\n  const bottlenecks: Bottleneck[] = [];\n  const avgDuration = metrics.totalDuration / nodeMetrics.size;\n\n  for (const [nodeId, node] of nodeMetrics) {\n    // Slow nodes (&gt;2x average)\n    if (node.executionTime > avgDuration * 2) {\n      bottlenecks.push({\n        type: 'slow_node',\n        nodeId,\n        severity: node.executionTime > avgDuration * 4 ? 'high' : 'medium',\n        impact: (node.executionTime / metrics.totalDuration) * 100,\n        details: `Node takes ${node.executionTime}ms, ${(node.executionTime / avgDuration).toFixed(1)}x average`,\n        recommendation: 'Consider breaking into smaller tasks or using faster model',\n      });\n    }\n\n    // High token usage\n    const avgTokens = metrics.totalTokens.totalTokens / nodeMetrics.size;\n    if (node.tokens.totalTokens > avgTokens * 3) {\n      bottlenecks.push({\n        type: 'high_token_usage',\n        nodeId,\n        severity: node.tokens.totalTokens > avgTokens * 5 ? 'high' : 'medium',\n        impact: (node.cost / metrics.totalCost.totalCost) * 100,\n        details: `Uses ${node.tokens.totalTokens} tokens, ${(node.tokens.totalTokens / avgTokens).toFixed(1)}x average`,\n        recommendation: 'Reduce context size or summarize inputs',\n      });\n    }\n\n    // Excessive retries\n    if (node.retries >= 2) {\n      bottlenecks.push({\n        type: 'excessive_retries',\n        nodeId,\n        severity: node.retries >= 3 ? 'high' : 'medium',\n        impact: (node.retries / (node.retries + 1)) * 100,\n        details: `${node.retries} retries before success`,\n        recommendation: 'Improve prompt clarity or add validation earlier',\n      });\n    }\n\n    // Tool latency\n    const slowTools = node.toolCalls.filter(tc => tc.duration > 1000);\n    if (slowTools.length > 0) {\n      bottlenecks.push({\n        type: 'tool_latency',\n        nodeId,\n        severity: slowTools.some(t => t.duration > 5000) ? 'high' : 'medium',\n        impact: slowTools.reduce((sum, t) => sum + t.duration, 0) / node.duration * 100,\n        details: `${slowTools.length} slow tool calls (&gt;1s)`,\n        recommendation: 'Consider caching or parallel tool calls',\n      });\n    }\n\n    // Dependency wait time\n    if (node.waitTime > node.executionTime) {\n      bottlenecks.push({\n        type: 'dependency_wait',\n        nodeId,\n        severity: node.waitTime > node.executionTime * 2 ? 'high' : 'medium',\n        impact: (node.waitTime / metrics.totalDuration) * 100,\n        details: `Waited ${node.waitTime}ms for dependencies`,\n        recommendation: 'Restructure DAG to reduce dependency chains',\n      });\n    }\n  }\n\n  return bottlenecks.sort((a, b) => b.impact - a.impact);\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"optimization-recommendations",children:"Optimization Recommendations"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"interface Optimization {\n  type: OptimizationType;\n  priority: 'low' | 'medium' | 'high';\n  estimatedSavings: {\n    time?: number;     // ms\n    tokens?: number;\n    cost?: number;     // USD\n  };\n  description: string;\n  implementation: string;\n}\n\ntype OptimizationType =\n  | 'parallelize'\n  | 'cache'\n  | 'model_downgrade'\n  | 'batch_operations'\n  | 'reduce_context'\n  | 'restructure_dag';\n\nfunction generateOptimizations(\n  metrics: AggregateMetrics,\n  bottlenecks: Bottleneck[],\n  trace: ExecutionTrace\n): Optimization[] {\n  const optimizations: Optimization[] = [];\n\n  // Low parallelization efficiency\n  if (metrics.parallelizationEfficiency < 0.5) {\n    optimizations.push({\n      type: 'parallelize',\n      priority: 'high',\n      estimatedSavings: {\n        time: metrics.totalDuration * (1 - metrics.parallelizationEfficiency) * 0.5,\n      },\n      description: `Parallelization efficiency is only ${(metrics.parallelizationEfficiency * 100).toFixed(0)}%`,\n      implementation: 'Identify independent nodes and schedule concurrently',\n    });\n  }\n\n  // Expensive model usage for simple tasks\n  const opusUsage = metrics.totalTokens.byModel['opus'] ?? 0;\n  if (opusUsage > metrics.totalTokens.totalTokens * 0.3) {\n    optimizations.push({\n      type: 'model_downgrade',\n      priority: 'medium',\n      estimatedSavings: {\n        cost: (metrics.totalCost.byModel['opus'] ?? 0) * 0.8,\n      },\n      description: 'Opus used for 30%+ of tokens, may be overkill for some tasks',\n      implementation: 'Use haiku/sonnet for simpler nodes, reserve opus for complex reasoning',\n    });\n  }\n\n  // Context size optimization\n  const avgInputTokens = metrics.totalTokens.inputTokens / trace.spans.size;\n  if (avgInputTokens > 4000) {\n    optimizations.push({\n      type: 'reduce_context',\n      priority: 'medium',\n      estimatedSavings: {\n        tokens: (avgInputTokens - 2000) * trace.spans.size,\n        cost: ((avgInputTokens - 2000) / 1000) * 0.003 * trace.spans.size,\n      },\n      description: `Average input context is ${avgInputTokens} tokens`,\n      implementation: 'Summarize context before passing to nodes, use selective inclusion',\n    });\n  }\n\n  // Sequential bottleneck nodes\n  const seqBottlenecks = bottlenecks.filter(b => b.type === 'sequential_bottleneck');\n  if (seqBottlenecks.length > 0) {\n    optimizations.push({\n      type: 'restructure_dag',\n      priority: 'high',\n      estimatedSavings: {\n        time: seqBottlenecks.reduce((sum, b) => sum + b.impact, 0) * metrics.totalDuration / 100 * 0.5,\n      },\n      description: `${seqBottlenecks.length} nodes creating sequential bottlenecks`,\n      implementation: 'Split large nodes into smaller parallel tasks',\n    });\n  }\n\n  return optimizations;\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"performance-report",children:"Performance Report"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'performanceProfile:\n  profileId: "prof-8f4a2b1c"\n  traceId: "tr-8f4a2b1c-3d5e-6f7a-8b9c"\n  dagId: "code-review-dag"\n  profiledAt: "2024-01-15T10:31:00Z"\n\n  summary:\n    totalDuration: 45234ms\n    totalTokens: 28450\n    totalCost: $0.42\n    parallelizationEfficiency: 68%\n    criticalPathDuration: 30108ms\n\n  metrics:\n    tokens:\n      inputTokens: 18240\n      outputTokens: 10210\n      byModel:\n        haiku: 4520\n        sonnet: 23930\n      byNode:\n        fetch-code: 2450\n        analyze-complexity: 8230\n        check-security: 6890\n        review-performance: 7450\n        aggregate-results: 3430\n\n    cost:\n      totalCost: 0.42\n      byModel:\n        haiku: 0.02\n        sonnet: 0.40\n      currency: USD\n\n  nodeBreakdown:\n    - nodeId: fetch-code\n      duration: 3421ms\n      waitTime: 0ms\n      executionTime: 3421ms\n      tokens: 2450\n      cost: $0.02\n      retries: 0\n\n    - nodeId: analyze-complexity\n      duration: 8234ms\n      waitTime: 3421ms\n      executionTime: 4813ms\n      tokens: 8230\n      cost: $0.12\n      retries: 0\n\n    - nodeId: review-performance\n      duration: 12456ms\n      waitTime: 8234ms\n      executionTime: 4222ms\n      tokens: 7450\n      cost: $0.11\n      retries: 1\n\n  bottlenecks:\n    - type: slow_node\n      nodeId: review-performance\n      severity: medium\n      impact: 27.5%\n      details: "Node takes 12456ms, 2.8x average"\n      recommendation: "Consider breaking into smaller tasks"\n\n    - type: dependency_wait\n      nodeId: analyze-complexity\n      severity: low\n      impact: 7.6%\n      details: "Waited 3421ms for dependencies"\n      recommendation: "Could run in parallel with fetch-code"\n\n  optimizations:\n    - type: parallelize\n      priority: high\n      estimatedSavings:\n        time: 7248ms\n      description: "Parallelization efficiency is only 68%"\n      implementation: "Run analyze-complexity and check-security in parallel"\n\n    - type: reduce_context\n      priority: medium\n      estimatedSavings:\n        tokens: 4000\n        cost: $0.05\n      description: "Average input context is 3648 tokens"\n      implementation: "Summarize code before passing to analyzers"\n\n  visualization: |\n    Cost Distribution by Node\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 fetch-code        \u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591   5%  \u2502\n    \u2502 analyze-complexity \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591  29%  \u2502\n    \u2502 check-security    \u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  19%  \u2502\n    \u2502 review-performance \u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  26%  \u2502\n    \u2502 aggregate-results \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  21%  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    Time Distribution\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Execution \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591  68%    \u2502\n    \u2502 Wait Time \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  32%    \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,o.jsx)(n.h2,{id:"integration-points",children:"Integration Points"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Input"}),": Execution traces from ",(0,o.jsx)(n.code,{children:"dag-execution-tracer"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Analysis"}),": Failure metrics to ",(0,o.jsx)(n.code,{children:"dag-failure-analyzer"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Optimization"}),": Recommendations to ",(0,o.jsx)(n.code,{children:"dag-task-scheduler"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Learning"}),": Patterns to ",(0,o.jsx)(n.code,{children:"dag-pattern-learner"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Profile Regularly"}),": Run on representative workloads"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Track Trends"}),": Compare profiles over time"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Focus on Impact"}),": Prioritize high-impact optimizations"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Selection"}),": Match model to task complexity"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Budget Awareness"}),": Always consider cost implications"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.p,{children:"Measure everything. Find bottlenecks. Optimize continuously."})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);