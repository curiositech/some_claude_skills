"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[12674],{2765:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>p});const r=JSON.parse('{"id":"skills/drone_cv_expert/references/navigation-algorithms","title":"Navigation Algorithms Reference","description":"GPS-Based Waypoint Navigation","source":"@site/docs/skills/drone_cv_expert/references/navigation-algorithms.md","sourceDirName":"skills/drone_cv_expert/references","slug":"/skills/drone_cv_expert/references/navigation-algorithms","permalink":"/docs/skills/drone_cv_expert/references/navigation-algorithms","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Navigation Algorithms Reference","sidebar_label":"Navigation Algorithms Refer...","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Drone Cv Expert","permalink":"/docs/skills/drone_cv_expert/"},"next":{"title":"Object Detection & Tracking...","permalink":"/docs/skills/drone_cv_expert/references/object-detection-tracking"}}');var s=t(74848),a=t(28453);const o={title:"Navigation Algorithms Reference",sidebar_label:"Navigation Algorithms Refer...",sidebar_position:1},i="Navigation Algorithms Reference",l={},p=[{value:"GPS-Based Waypoint Navigation",id:"gps-based-waypoint-navigation",level:2},{value:"Visual SLAM Pipeline",id:"visual-slam-pipeline",level:2},{value:"Path Planning Algorithms",id:"path-planning-algorithms",level:2},{value:"A* 3D Path Planning",id:"a-3d-path-planning",level:3},{value:"RRT (Rapidly-exploring Random Tree)",id:"rrt-rapidly-exploring-random-tree",level:3},{value:"AprilTag Localization",id:"apriltag-localization",level:2}];function f(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",pre:"pre",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"navigation-algorithms-reference",children:"Navigation Algorithms Reference"})}),"\n",(0,s.jsx)(n.h2,{id:"gps-based-waypoint-navigation",children:"GPS-Based Waypoint Navigation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class PIDController:\n    """Standard PID controller for position control"""\n    def __init__(self, kp: float, ki: float, kd: float):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.integral = 0.0\n        self.prev_error = 0.0\n\n    def update(self, error: float, dt: float = 0.02) -> float:\n        self.integral += error * dt\n        derivative = (error - self.prev_error) / dt\n        self.prev_error = error\n        return self.kp * error + self.ki * self.integral + self.kd * derivative\n\n\nclass WaypointNavigator:\n    """GPS waypoint navigation with PID control"""\n    def __init__(self, kp=1.0, ki=0.1, kd=0.05):\n        self.pid_lat = PIDController(kp, ki, kd)\n        self.pid_lon = PIDController(kp, ki, kd)\n        self.pid_alt = PIDController(kp, ki, kd)\n        self.waypoint_threshold = 2.0  # meters\n\n    def navigate_to_waypoint(self, current_pos, target_pos):\n        """Generate velocity commands to reach waypoint"""\n        lat_error = target_pos.lat - current_pos.lat\n        lon_error = target_pos.lon - current_pos.lon\n        alt_error = target_pos.alt - current_pos.alt\n\n        return {\n            \'north\': self.pid_lat.update(lat_error),\n            \'east\': self.pid_lon.update(lon_error),\n            \'up\': self.pid_alt.update(alt_error)\n        }\n\n    def is_waypoint_reached(self, current_pos, target_pos) -> bool:\n        """Check if within threshold of waypoint"""\n        import math\n        distance = math.sqrt(\n            (current_pos.lat - target_pos.lat)**2 +\n            (current_pos.lon - target_pos.lon)**2\n        ) * 111000  # Rough meters conversion\n        return distance < self.waypoint_threshold\n'})}),"\n",(0,s.jsx)(n.h2,{id:"visual-slam-pipeline",children:"Visual SLAM Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\nfrom typing import List, Tuple, Optional\n\nclass VisualSLAM:\n    """ORB-SLAM style visual SLAM for GPS-denied navigation"""\n    def __init__(self, camera_matrix: np.ndarray = None):\n        self.orb = cv2.ORB_create(nfeatures=2000)\n        self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n        self.map_points: List[np.ndarray] = []\n        self.camera_poses: List[np.ndarray] = []\n        self.prev_frame = None\n        self.prev_keypoints = None\n        self.prev_descriptors = None\n\n        # Camera intrinsics (default for 640x480)\n        self.K = camera_matrix if camera_matrix is not None else np.array([\n            [500, 0, 320],\n            [0, 500, 240],\n            [0, 0, 1]\n        ], dtype=np.float32)\n\n    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List]:\n        """Process frame and return estimated pose"""\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame\n\n        # Feature detection\n        keypoints, descriptors = self.orb.detectAndCompute(gray, None)\n\n        if self.prev_frame is None:\n            # Initialize with first frame\n            self.prev_frame = gray\n            self.prev_keypoints = keypoints\n            self.prev_descriptors = descriptors\n            pose = np.eye(4)\n            self.camera_poses.append(pose)\n            return pose, []\n\n        # Match features\n        matches = self.matcher.match(self.prev_descriptors, descriptors)\n        matches = sorted(matches, key=lambda x: x.distance)[:100]\n\n        if len(matches) < 10:\n            return self.camera_poses[-1], self.map_points\n\n        # Extract matched points\n        pts1 = np.float32([self.prev_keypoints[m.queryIdx].pt for m in matches])\n        pts2 = np.float32([keypoints[m.trainIdx].pt for m in matches])\n\n        # Estimate pose\n        E, mask = cv2.findEssentialMat(pts1, pts2, self.K, method=cv2.RANSAC)\n        _, R, t, mask = cv2.recoverPose(E, pts1, pts2, self.K)\n\n        # Build pose matrix\n        pose = np.eye(4)\n        pose[:3, :3] = R\n        pose[:3, 3] = t.flatten()\n\n        # Chain with previous pose\n        if self.camera_poses:\n            pose = self.camera_poses[-1] @ pose\n\n        self.camera_poses.append(pose)\n\n        # Update state\n        self.prev_frame = gray\n        self.prev_keypoints = keypoints\n        self.prev_descriptors = descriptors\n\n        return pose, self.map_points\n\n\nclass VisualInertialOdometry:\n    """VIO combining camera and IMU for robust tracking"""\n    def __init__(self):\n        self.visual_slam = VisualSLAM()\n        self.imu_buffer = []\n        self.gravity = np.array([0, 0, -9.81])\n\n    def process_imu(self, accel: np.ndarray, gyro: np.ndarray, dt: float):\n        """Buffer IMU measurements for fusion"""\n        self.imu_buffer.append({\n            \'accel\': accel,\n            \'gyro\': gyro,\n            \'dt\': dt\n        })\n\n    def process_frame(self, frame: np.ndarray):\n        """Fuse visual with IMU for robust pose"""\n        visual_pose, _ = self.visual_slam.process_frame(frame)\n\n        # Integrate IMU between frames\n        imu_delta = self._integrate_imu()\n\n        # Simple fusion (production would use EKF/UKF)\n        fused_pose = visual_pose.copy()\n        if imu_delta is not None:\n            # Weight visual more when feature tracking is good\n            fused_pose[:3, 3] = 0.8 * visual_pose[:3, 3] + 0.2 * imu_delta\n\n        self.imu_buffer = []\n        return fused_pose\n\n    def _integrate_imu(self) -> Optional[np.ndarray]:\n        if not self.imu_buffer:\n            return None\n\n        position = np.zeros(3)\n        velocity = np.zeros(3)\n\n        for meas in self.imu_buffer:\n            accel = meas[\'accel\'] - self.gravity\n            dt = meas[\'dt\']\n            velocity += accel * dt\n            position += velocity * dt\n\n        return position\n'})}),"\n",(0,s.jsx)(n.h2,{id:"path-planning-algorithms",children:"Path Planning Algorithms"}),"\n",(0,s.jsx)(n.h3,{id:"a-3d-path-planning",children:"A* 3D Path Planning"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import heapq\nimport numpy as np\nfrom typing import List, Tuple, Set, Optional\n\nclass Drone3DPathPlanner:\n    """A* path planning with 3D obstacle avoidance"""\n    def __init__(self, grid_resolution: float = 0.5, safety_margin: float = 1.0):\n        self.resolution = grid_resolution\n        self.safety_margin = safety_margin\n        self.obstacle_map: Set[Tuple[int, int, int]] = set()\n\n    def add_obstacles(self, point_cloud: np.ndarray):\n        """Add obstacles from 3D point cloud"""\n        for point in point_cloud:\n            grid_cell = self._to_grid(point)\n            self.obstacle_map.add(grid_cell)\n            # Add safety margin\n            for dx in range(-2, 3):\n                for dy in range(-2, 3):\n                    for dz in range(-2, 3):\n                        self.obstacle_map.add((\n                            grid_cell[0] + dx,\n                            grid_cell[1] + dy,\n                            grid_cell[2] + dz\n                        ))\n\n    def _to_grid(self, pos: Tuple[float, float, float]) -> Tuple[int, int, int]:\n        return (\n            int(pos[0] / self.resolution),\n            int(pos[1] / self.resolution),\n            int(pos[2] / self.resolution)\n        )\n\n    def _from_grid(self, cell: Tuple[int, int, int]) -> Tuple[float, float, float]:\n        return (\n            cell[0] * self.resolution,\n            cell[1] * self.resolution,\n            cell[2] * self.resolution\n        )\n\n    def a_star(self, start: Tuple[float, float, float],\n               goal: Tuple[float, float, float]) -> Optional[List[Tuple[float, float, float]]]:\n        """Find optimal path avoiding obstacles"""\n        start_cell = self._to_grid(start)\n        goal_cell = self._to_grid(goal)\n\n        open_set = [(0, start_cell)]\n        came_from = {}\n        g_score = {start_cell: 0}\n        f_score = {start_cell: self._heuristic(start_cell, goal_cell)}\n\n        while open_set:\n            current = heapq.heappop(open_set)[1]\n\n            if self._is_goal_reached(current, goal_cell):\n                return self._reconstruct_path(came_from, current)\n\n            for neighbor in self._get_neighbors(current):\n                if neighbor in self.obstacle_map:\n                    continue\n\n                tentative_g = g_score[current] + self._distance(current, neighbor)\n\n                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g\n                    f_score[neighbor] = tentative_g + self._heuristic(neighbor, goal_cell)\n                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def _heuristic(self, pos1: Tuple, pos2: Tuple) -> float:\n        """Euclidean distance heuristic"""\n        return np.sqrt(sum((a - b) ** 2 for a, b in zip(pos1, pos2)))\n\n    def _distance(self, pos1: Tuple, pos2: Tuple) -> float:\n        return self._heuristic(pos1, pos2)\n\n    def _is_goal_reached(self, current: Tuple, goal: Tuple, threshold: int = 2) -> bool:\n        return all(abs(a - b) <= threshold for a, b in zip(current, goal))\n\n    def _get_neighbors(self, cell: Tuple[int, int, int]) -> List[Tuple[int, int, int]]:\n        """26-connected neighbors in 3D grid"""\n        neighbors = []\n        for dx in [-1, 0, 1]:\n            for dy in [-1, 0, 1]:\n                for dz in [-1, 0, 1]:\n                    if dx == 0 and dy == 0 and dz == 0:\n                        continue\n                    neighbors.append((cell[0] + dx, cell[1] + dy, cell[2] + dz))\n        return neighbors\n\n    def _reconstruct_path(self, came_from: dict, current: Tuple) -> List[Tuple[float, float, float]]:\n        path = [self._from_grid(current)]\n        while current in came_from:\n            current = came_from[current]\n            path.append(self._from_grid(current))\n        return list(reversed(path))\n'})}),"\n",(0,s.jsx)(n.h3,{id:"rrt-rapidly-exploring-random-tree",children:"RRT (Rapidly-exploring Random Tree)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import random\nimport numpy as np\nfrom typing import List, Tuple, Optional\n\nclass RRTPlanner:\n    \"\"\"RRT for dynamic obstacle avoidance\"\"\"\n    def __init__(self, bounds: Tuple[Tuple, Tuple], step_size: float = 1.0):\n        self.bounds = bounds  # ((xmin, ymin, zmin), (xmax, ymax, zmax))\n        self.step_size = step_size\n        self.tree = []\n        self.obstacle_check_fn = None\n\n    def plan(self, start: Tuple, goal: Tuple,\n             obstacle_check: callable, max_iterations: int = 1000) -> Optional[List[Tuple]]:\n        \"\"\"Plan path using RRT\"\"\"\n        self.obstacle_check_fn = obstacle_check\n        self.tree = [{'pos': start, 'parent': None}]\n\n        for _ in range(max_iterations):\n            # Sample random point (bias toward goal)\n            if random.random() < 0.1:\n                sample = goal\n            else:\n                sample = self._random_sample()\n\n            # Find nearest node\n            nearest_idx = self._nearest_node(sample)\n            nearest = self.tree[nearest_idx]\n\n            # Extend toward sample\n            new_pos = self._steer(nearest['pos'], sample)\n\n            # Check collision\n            if self._collision_free(nearest['pos'], new_pos):\n                self.tree.append({'pos': new_pos, 'parent': nearest_idx})\n\n                # Check if we reached goal\n                if self._distance(new_pos, goal) < self.step_size:\n                    self.tree.append({'pos': goal, 'parent': len(self.tree) - 1})\n                    return self._extract_path()\n\n        return None\n\n    def _random_sample(self) -> Tuple:\n        return tuple(\n            random.uniform(self.bounds[0][i], self.bounds[1][i])\n            for i in range(3)\n        )\n\n    def _nearest_node(self, sample: Tuple) -> int:\n        distances = [self._distance(node['pos'], sample) for node in self.tree]\n        return int(np.argmin(distances))\n\n    def _steer(self, from_pos: Tuple, to_pos: Tuple) -> Tuple:\n        direction = np.array(to_pos) - np.array(from_pos)\n        distance = np.linalg.norm(direction)\n        if distance <= self.step_size:\n            return to_pos\n        return tuple(np.array(from_pos) + direction / distance * self.step_size)\n\n    def _collision_free(self, from_pos: Tuple, to_pos: Tuple, steps: int = 10) -> bool:\n        for i in range(steps + 1):\n            t = i / steps\n            point = tuple(\n                from_pos[j] + t * (to_pos[j] - from_pos[j])\n                for j in range(3)\n            )\n            if self.obstacle_check_fn(point):\n                return False\n        return True\n\n    def _distance(self, p1: Tuple, p2: Tuple) -> float:\n        return np.sqrt(sum((a - b) ** 2 for a, b in zip(p1, p2)))\n\n    def _extract_path(self) -> List[Tuple]:\n        path = []\n        idx = len(self.tree) - 1\n        while idx is not None:\n            path.append(self.tree[idx]['pos'])\n            idx = self.tree[idx]['parent']\n        return list(reversed(path))\n"})}),"\n",(0,s.jsx)(n.h2,{id:"apriltag-localization",children:"AprilTag Localization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\nfrom typing import Dict, List, Optional\n\n# Requires: pip install pupil-apriltags\nfrom pupil_apriltags import Detector\n\nclass AprilTagLocalizer:\n    """Localization using AprilTag markers for GPS-denied environments"""\n    def __init__(self, tag_size: float = 0.16, camera_matrix: np.ndarray = None):\n        self.detector = Detector(\n            families=\'tag36h11\',\n            nthreads=4,\n            quad_decimate=1.0,\n            quad_sigma=0.0,\n            refine_edges=True,\n            decode_sharpening=0.25\n        )\n        self.tag_size = tag_size\n        self.K = camera_matrix\n\n        # Known tag positions in world frame\n        self.tag_world_positions: Dict[int, np.ndarray] = {}\n\n    def register_tag(self, tag_id: int, world_position: np.ndarray):\n        """Register known tag position for localization"""\n        self.tag_world_positions[tag_id] = world_position\n\n    def localize(self, frame: np.ndarray) -> Optional[np.ndarray]:\n        """Estimate drone position from visible tags"""\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame\n\n        # Detect tags\n        detections = self.detector.detect(\n            gray,\n            estimate_tag_pose=True,\n            camera_params=(self.K[0, 0], self.K[1, 1], self.K[0, 2], self.K[1, 2]),\n            tag_size=self.tag_size\n        )\n\n        poses = []\n        for det in detections:\n            if det.tag_id in self.tag_world_positions:\n                # Get tag-to-camera transform\n                R = det.pose_R\n                t = det.pose_t\n\n                # Invert to get camera-in-tag frame\n                R_inv = R.T\n                t_inv = -R_inv @ t\n\n                # Transform to world frame\n                tag_world = self.tag_world_positions[det.tag_id]\n                camera_world = tag_world + t_inv.flatten()\n\n                poses.append(camera_world)\n\n        if not poses:\n            return None\n\n        # Average multiple tag observations\n        return np.mean(poses, axis=0)\n'})})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(f,{...e})}):f(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var r=t(96540);const s={},a=r.createContext(s);function o(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);