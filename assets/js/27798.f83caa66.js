"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[5417,27798],{27798:e=>{e.exports=JSON.parse("{\"name\":\"background-job-orchestrator\",\"type\":\"folder\",\"path\":\"background-job-orchestrator\",\"children\":[{\"name\":\"references\",\"type\":\"folder\",\"path\":\"background-job-orchestrator/references\",\"children\":[{\"name\":\"bullmq-patterns.md\",\"type\":\"file\",\"path\":\"background-job-orchestrator/references/bullmq-patterns.md\",\"size\":7621,\"content\":\"# Advanced BullMQ Patterns\\n\\nProduction patterns for complex job orchestration with BullMQ.\\n\\n## Pattern 1: Job Chaining (Sequential Workflows)\\n\\nExecute jobs in sequence, passing results between steps.\\n\\n```typescript\\n// Parent job spawns child jobs\\nawait queue.add('process-order', {\\n  orderId: 123\\n}, {\\n  attempts: 3\\n});\\n\\nworker.process('process-order', async (job) => {\\n  const { orderId } = job.data;\\n\\n  // Step 1: Validate inventory\\n  const inventoryJob = await queue.add('check-inventory', {\\n    orderId\\n  }, {\\n    parent: {\\n      id: job.id,\\n      queue: job.queueName\\n    }\\n  });\\n\\n  await inventoryJob.waitUntilFinished(queueEvents);\\n\\n  // Step 2: Charge payment\\n  const paymentJob = await queue.add('charge-payment', {\\n    orderId\\n  }, {\\n    parent: {\\n      id: job.id,\\n      queue: job.queueName\\n    }\\n  });\\n\\n  await paymentJob.waitUntilFinished(queueEvents);\\n\\n  // Step 3: Ship order\\n  return await queue.add('ship-order', {\\n    orderId\\n  }, {\\n    parent: {\\n      id: job.id,\\n      queue: job.queueName\\n    }\\n  });\\n});\\n```\\n\\n## Pattern 2: Fan-Out/Fan-In\\n\\nProcess multiple jobs in parallel, then aggregate results.\\n\\n```typescript\\n// Fan-out: Create parallel jobs\\nconst userIds = [1, 2, 3, 4, 5];\\n\\nconst jobs = await Promise.all(\\n  userIds.map(userId =>\\n    queue.add('send-notification', {\\n      userId\\n    }, {\\n      parent: { id: 'batch-123', queue: 'aggregator' }\\n    })\\n  )\\n);\\n\\n// Fan-in: Aggregate when all complete\\nconst aggregatorWorker = new Worker('aggregator', async (job) => {\\n  const children = await job.getChildrenValues();\\n\\n  const successCount = Object.values(children).filter(\\n    r => r.status === 'sent'\\n  ).length;\\n\\n  console.log(`Sent ${successCount}/${userIds.length} notifications`);\\n});\\n```\\n\\n## Pattern 3: Rate-Limited API Calls\\n\\nRespect third-party API rate limits.\\n\\n```typescript\\n// Configure rate limiter\\nconst apiQueue = new Queue('external-api', {\\n  connection,\\n  limiter: {\\n    max: 100,        // Max 100 requests\\n    duration: 60000, // Per 60 seconds\\n    groupKey: 'apiKey' // Rate limit per API key\\n  }\\n});\\n\\n// Group jobs by API key\\nawait apiQueue.add('fetch-data', {\\n  endpoint: '/users',\\n  apiKey: 'key123'\\n}, {\\n  rateLimiter: {\\n    groupKey: 'key123' // This key gets 100 req/min\\n  }\\n});\\n```\\n\\n## Pattern 4: Priority Queues\\n\\nProcess high-priority jobs first.\\n\\n```typescript\\n// Add jobs with priority (lower number = higher priority)\\nawait queue.add('send-email', {\\n  to: 'premium@user.com'\\n}, {\\n  priority: 1  // Premium users\\n});\\n\\nawait queue.add('send-email', {\\n  to: 'free@user.com'\\n}, {\\n  priority: 10  // Free users\\n});\\n\\n// Worker processes priority 1 jobs before priority 10\\nconst worker = new Worker('email-queue', processEmail, {\\n  connection,\\n  concurrency: 5\\n});\\n```\\n\\n## Pattern 5: Delayed Jobs\\n\\nSchedule jobs for future execution.\\n\\n```typescript\\n// Send reminder email in 24 hours\\nawait queue.add('send-reminder', {\\n  userId: 123\\n}, {\\n  delay: 24 * 60 * 60 * 1000 // 24 hours in ms\\n});\\n\\n// Or: Specific timestamp\\nconst scheduledTime = new Date('2026-01-15T09:00:00Z');\\nawait queue.add('daily-report', {\\n  type: 'sales'\\n}, {\\n  delay: scheduledTime.getTime() - Date.now()\\n});\\n```\\n\\n## Pattern 6: Repeatable Jobs (Cron)\\n\\nSchedule recurring jobs with cron syntax.\\n\\n```typescript\\n// Daily at 9 AM\\nawait queue.add('daily-digest', {\\n  recipients: ['admin@company.com']\\n}, {\\n  repeat: {\\n    pattern: '0 9 * * *',  // Cron syntax\\n    tz: 'America/New_York'\\n  }\\n});\\n\\n// Every 15 minutes\\nawait queue.add('health-check', {\\n  service: 'api'\\n}, {\\n  repeat: {\\n    every: 15 * 60 * 1000 // 15 minutes in ms\\n  }\\n});\\n```\\n\\n## Pattern 7: Job Progress Tracking\\n\\nUpdate progress for long-running jobs.\\n\\n```typescript\\nworker.process('video-transcode', async (job) => {\\n  const { videoId, formats } = job.data;\\n\\n  for (let i = 0; i < formats.length; i++) {\\n    const progress = ((i + 1) / formats.length) * 100;\\n\\n    // Update progress\\n    await job.updateProgress(progress);\\n\\n    // Log current step\\n    await job.log(`Transcoding ${formats[i]}...`);\\n\\n    await transcodeVideo(videoId, formats[i]);\\n  }\\n\\n  return { completed: formats.length };\\n});\\n\\n// Client polls progress\\nconst job = await queue.getJob(jobId);\\nconsole.log(`Progress: ${job.progress}%`);\\n\\n// Or: Listen to progress events\\nqueueEvents.on('progress', ({ jobId, data }) => {\\n  console.log(`Job ${jobId}: ${data}%`);\\n});\\n```\\n\\n## Pattern 8: Conditional Job Execution\\n\\nExecute jobs based on previous results.\\n\\n```typescript\\nworker.process('process-upload', async (job) => {\\n  const { fileUrl } = job.data;\\n\\n  // Download file\\n  const file = await downloadFile(fileUrl);\\n\\n  // Conditional: Only process if valid\\n  if (!isValidFile(file)) {\\n    await job.log('Invalid file, skipping processing');\\n    return { skipped: true };\\n  }\\n\\n  // Process valid files\\n  const result = await processFile(file);\\n\\n  // Add follow-up job only if needed\\n  if (result.needsTranscoding) {\\n    await queue.add('transcode', {\\n      fileId: result.fileId\\n    }, {\\n      parent: { id: job.id, queue: job.queueName }\\n    });\\n  }\\n\\n  return result;\\n});\\n```\\n\\n## Pattern 9: Graceful Shutdown\\n\\nHandle in-flight jobs during shutdown.\\n\\n```typescript\\nlet isShuttingDown = false;\\n\\nconst worker = new Worker('email-queue', async (job) => {\\n  if (isShuttingDown) {\\n    throw new Error('Shutting down, job will be requeued');\\n  }\\n\\n  await processEmail(job.data);\\n}, {\\n  connection\\n});\\n\\n// Graceful shutdown handler\\nprocess.on('SIGTERM', async () => {\\n  console.log('Received SIGTERM, shutting down gracefully...');\\n\\n  isShuttingDown = true;\\n\\n  // Stop accepting new jobs\\n  await worker.pause();\\n\\n  // Wait for active jobs to complete (max 30 seconds)\\n  await worker.close();\\n\\n  console.log('All jobs completed, exiting');\\n  process.exit(0);\\n});\\n```\\n\\n## Pattern 10: Dead Letter Queue Recovery\\n\\nRetry failed jobs with modified data.\\n\\n```typescript\\n// Get all failed jobs\\nconst failedJobs = await queue.getFailed();\\n\\n// Analyze and retry with fixes\\nfor (const job of failedJobs) {\\n  const { failedReason } = job;\\n\\n  if (failedReason.includes('Invalid email')) {\\n    // Fix email and retry\\n    const fixedEmail = sanitizeEmail(job.data.email);\\n\\n    await queue.add('send-email', {\\n      ...job.data,\\n      email: fixedEmail\\n    }, {\\n      attempts: 1 // Only 1 more attempt\\n    });\\n\\n    // Remove original failed job\\n    await job.remove();\\n  }\\n}\\n```\\n\\n## Production Checklist\\n\\n```\\n\u25a1 Dead letter queue monitoring\\n\u25a1 Exponential backoff configured\\n\u25a1 Job timeouts set appropriately\\n\u25a1 Rate limiting for external APIs\\n\u25a1 Idempotency keys for critical jobs\\n\u25a1 Worker concurrency tuned\\n\u25a1 Graceful shutdown implemented\\n\u25a1 Queue depth alerts configured\\n\u25a1 Failed job inspection workflow\\n\u25a1 Redis persistence enabled\\n\u25a1 Job data sanitized (no PII in logs)\\n\u25a1 Progress tracking for long jobs\\n```\\n\\n## Performance Tips\\n\\n1. **Use bulk operations**: `queue.addBulk()` is 10x faster than individual `add()` calls\\n2. **Tune concurrency**: Start with `CPU cores * 2`, adjust based on job type\\n3. **Remove completed jobs**: Set `removeOnComplete` to prevent Redis bloat\\n4. **Use priorities sparingly**: Too many priority levels hurt performance\\n5. **Partition queues**: Separate queues for different job types improves isolation\\n6. **Monitor Redis memory**: Set `maxmemory-policy` to `allkeys-lru` for Redis\\n\\n## Common Pitfalls\\n\\n1. **Not handling job failures**: Always have dead letter queue inspection\\n2. **Forgetting idempotency**: Jobs can run twice, design for it\\n3. **Blocking workers**: Don't do synchronous I/O in workers\\n4. **Not monitoring queue depth**: Set up alerts before it's too late\\n5. **Over-using repeatable jobs**: They create Redis bloat, use sparingly\\n\"}]},{\"name\":\"scripts\",\"type\":\"folder\",\"path\":\"background-job-orchestrator/scripts\",\"children\":[{\"name\":\"queue_health_check.ts\",\"type\":\"file\",\"path\":\"background-job-orchestrator/scripts/queue_health_check.ts\",\"size\":4366,\"content\":\"#!/usr/bin/env node\\n/**\\n * Queue Health Check Dashboard\\n *\\n * Monitors BullMQ queue metrics and provides health status.\\n *\\n * Usage: npx ts-node queue_health_check.ts [queue-name]\\n *\\n * Dependencies: npm install bullmq ioredis chalk\\n */\\n\\nimport { Queue } from 'bullmq';\\nimport Redis from 'ioredis';\\nimport chalk from 'chalk';\\n\\ninterface QueueMetrics {\\n  waiting: number;\\n  active: number;\\n  completed: number;\\n  failed: number;\\n  delayed: number;\\n  paused: boolean;\\n}\\n\\ninterface HealthStatus {\\n  status: 'healthy' | 'degraded' | 'critical';\\n  metrics: QueueMetrics;\\n  warnings: string[];\\n}\\n\\nasync function getQueueHealth(queueName: string): Promise<HealthStatus> {\\n  const connection = new Redis({\\n    host: process.env.REDIS_HOST || 'localhost',\\n    port: parseInt(process.env.REDIS_PORT || '6379'),\\n    maxRetriesPerRequest: null\\n  });\\n\\n  const queue = new Queue(queueName, { connection });\\n\\n  try {\\n    const [waiting, active, completed, failed, delayed, paused] = await Promise.all([\\n      queue.getWaitingCount(),\\n      queue.getActiveCount(),\\n      queue.getCompletedCount(),\\n      queue.getFailedCount(),\\n      queue.getDelayedCount(),\\n      queue.isPaused()\\n    ]);\\n\\n    const metrics: QueueMetrics = {\\n      waiting,\\n      active,\\n      completed,\\n      failed,\\n      delayed,\\n      paused\\n    };\\n\\n    const warnings: string[] = [];\\n    let status: 'healthy' | 'degraded' | 'critical' = 'healthy';\\n\\n    // Health checks\\n    if (waiting > 1000) {\\n      warnings.push(`High queue depth: ${waiting} jobs waiting`);\\n      status = 'degraded';\\n    }\\n\\n    if (failed > 100) {\\n      warnings.push(`High failure rate: ${failed} failed jobs`);\\n      status = 'degraded';\\n    }\\n\\n    if (waiting > 5000 || failed > 500) {\\n      status = 'critical';\\n    }\\n\\n    if (paused) {\\n      warnings.push('Queue is paused!');\\n      status = 'critical';\\n    }\\n\\n    return { status, metrics, warnings };\\n  } finally {\\n    await queue.close();\\n    await connection.quit();\\n  }\\n}\\n\\nasync function displayDashboard(queueName: string) {\\n  console.clear();\\n  console.log(chalk.bold.cyan(`\\\\n\ud83d\udcca Queue Health Dashboard: ${queueName}\\\\n`));\\n\\n  const health = await getQueueHealth(queueName);\\n\\n  // Status badge\\n  const statusColor = {\\n    healthy: chalk.green,\\n    degraded: chalk.yellow,\\n    critical: chalk.red\\n  }[health.status];\\n\\n  console.log(statusColor(`Status: ${health.status.toUpperCase()}\\\\n`));\\n\\n  // Metrics\\n  console.log(chalk.bold('Metrics:'));\\n  console.log(`  Waiting:   ${chalk.cyan(health.metrics.waiting.toString().padStart(8))}`);\\n  console.log(`  Active:    ${chalk.blue(health.metrics.active.toString().padStart(8))}`);\\n  console.log(`  Completed: ${chalk.green(health.metrics.completed.toString().padStart(8))}`);\\n  console.log(`  Failed:    ${chalk.red(health.metrics.failed.toString().padStart(8))}`);\\n  console.log(`  Delayed:   ${chalk.magenta(health.metrics.delayed.toString().padStart(8))}`);\\n  console.log(`  Paused:    ${health.metrics.paused ? chalk.red('YES') : chalk.green('NO')}\\\\n`);\\n\\n  // Warnings\\n  if (health.warnings.length > 0) {\\n    console.log(chalk.bold.yellow('\u26a0\ufe0f  Warnings:'));\\n    health.warnings.forEach(warning => {\\n      console.log(chalk.yellow(`  \u2022 ${warning}`));\\n    });\\n    console.log('');\\n  }\\n\\n  // Recommendations\\n  if (health.status === 'degraded') {\\n    console.log(chalk.bold.yellow('\ud83d\udca1 Recommendations:'));\\n    if (health.metrics.waiting > 1000) {\\n      console.log(chalk.yellow('  \u2022 Scale up workers to process backlog'));\\n    }\\n    if (health.metrics.failed > 100) {\\n      console.log(chalk.yellow('  \u2022 Investigate failed jobs: await queue.getFailed()'));\\n    }\\n    console.log('');\\n  }\\n\\n  if (health.status === 'critical') {\\n    console.log(chalk.bold.red('\ud83d\udea8 CRITICAL - IMMEDIATE ACTION REQUIRED'));\\n    console.log(chalk.red('  \u2022 Queue is severely degraded'));\\n    console.log(chalk.red('  \u2022 Check worker processes are running'));\\n    console.log(chalk.red('  \u2022 Review logs for errors'));\\n    console.log('');\\n  }\\n\\n  console.log(chalk.dim(`Last updated: ${new Date().toLocaleTimeString()}`));\\n}\\n\\n// Main\\nconst queueName = process.argv[2] || 'email-queue';\\n\\nconsole.log(chalk.dim('Starting queue health monitor...'));\\nconsole.log(chalk.dim('Press Ctrl+C to exit\\\\n'));\\n\\n// Initial display\\ndisplayDashboard(queueName);\\n\\n// Refresh every 5 seconds\\nsetInterval(() => {\\n  displayDashboard(queueName);\\n}, 5000);\\n\"},{\"name\":\"setup_bullmq.sh\",\"type\":\"file\",\"path\":\"background-job-orchestrator/scripts/setup_bullmq.sh\",\"size\":2752,\"content\":\"#!/bin/bash\\n# Setup BullMQ with Redis for background job processing\\n# Usage: ./setup_bullmq.sh\\n\\nset -e\\n\\necho \\\"\ud83d\ude80 Setting up BullMQ with Redis...\\\"\\n\\n# Check if npm is installed\\nif ! command -v npm &> /dev/null; then\\n    echo \\\"\u274c npm not found. Install Node.js first.\\\"\\n    exit 1\\nfi\\n\\n# Install BullMQ dependencies\\necho \\\"\ud83d\udce6 Installing BullMQ and dependencies...\\\"\\nnpm install --save bullmq ioredis\\nnpm install --save-dev @types/node\\n\\n# Check if Redis is running\\necho \\\"\ud83d\udd0d Checking Redis connection...\\\"\\nif command -v redis-cli &> /dev/null; then\\n    if redis-cli ping &> /dev/null; then\\n        echo \\\"\u2705 Redis is running\\\"\\n    else\\n        echo \\\"\u26a0\ufe0f  Redis is installed but not running\\\"\\n        echo \\\"Start Redis with: redis-server\\\"\\n    fi\\nelse\\n    echo \\\"\u26a0\ufe0f  Redis not found. Install with:\\\"\\n    echo \\\"  macOS: brew install redis\\\"\\n    echo \\\"  Ubuntu: sudo apt-get install redis-server\\\"\\n    echo \\\"  Docker: docker run -d -p 6379:6379 redis:alpine\\\"\\nfi\\n\\n# Create basic queue setup\\necho \\\"\ud83d\udcdd Creating queue configuration...\\\"\\ncat > queue.config.ts << 'EOF'\\nimport { Queue, Worker, QueueEvents } from 'bullmq';\\nimport Redis from 'ioredis';\\n\\n// Redis connection\\nconst connection = new Redis({\\n  host: process.env.REDIS_HOST || 'localhost',\\n  port: parseInt(process.env.REDIS_PORT || '6379'),\\n  maxRetriesPerRequest: null\\n});\\n\\n// Create queue\\nexport const emailQueue = new Queue('email-queue', {\\n  connection,\\n  defaultJobOptions: {\\n    attempts: 3,\\n    backoff: {\\n      type: 'exponential',\\n      delay: 2000\\n    },\\n    removeOnComplete: 100,\\n    removeOnFail: false\\n  }\\n});\\n\\n// Create worker\\nexport const emailWorker = new Worker('email-queue', async (job) => {\\n  console.log(`Processing job ${job.id}:`, job.data);\\n\\n  // Your job processing logic here\\n  await new Promise(resolve => setTimeout(resolve, 1000));\\n\\n  return { processed: true, timestamp: new Date().toISOString() };\\n}, {\\n  connection,\\n  concurrency: 5\\n});\\n\\n// Queue events for monitoring\\nconst queueEvents = new QueueEvents('email-queue', { connection });\\n\\nqueueEvents.on('completed', ({ jobId }) => {\\n  console.log(`\u2705 Job ${jobId} completed`);\\n});\\n\\nqueueEvents.on('failed', ({ jobId, failedReason }) => {\\n  console.error(`\u274c Job ${jobId} failed:`, failedReason);\\n});\\n\\n// Graceful shutdown\\nprocess.on('SIGTERM', async () => {\\n  console.log('Shutting down gracefully...');\\n  await emailWorker.close();\\n  await emailQueue.close();\\n  await connection.quit();\\n  process.exit(0);\\n});\\nEOF\\n\\necho \\\"\u2705 Setup complete!\\\"\\necho \\\"\\\"\\necho \\\"Next steps:\\\"\\necho \\\"1. Start Redis (if not running)\\\"\\necho \\\"2. Import queue in your code: import { emailQueue } from './queue.config'\\\"\\necho \\\"3. Add jobs: await emailQueue.add('send', { to: 'user@example.com' })\\\"\\necho \\\"4. Worker will process jobs automatically\\\"\\n\"}]},{\"name\":\"SKILL.md\",\"type\":\"file\",\"path\":\"background-job-orchestrator/SKILL.md\",\"size\":12531,\"content\":\"---\\nname: background-job-orchestrator\\ndescription: Expert in background job processing with Bull/BullMQ (Redis), Celery, and cloud queues. Implements retries, scheduling, priority queues, and worker management. Use for async task processing, email campaigns, report generation, batch operations. Activate on \\\"background job\\\", \\\"async task\\\", \\\"queue\\\", \\\"worker\\\", \\\"BullMQ\\\", \\\"Celery\\\". NOT for real-time WebSocket communication, synchronous API calls, or simple setTimeout operations.\\nallowed-tools: Read,Write,Edit,Bash(npm:*,pip:*)\\n---\\n\\n# Background Job Orchestrator\\n\\nExpert in designing and implementing production-grade background job systems that handle long-running tasks without blocking API responses.\\n\\n## When to Use\\n\\n\u2705 **Use for**:\\n- Long-running tasks (email sends, report generation, image processing)\\n- Batch operations (bulk imports, exports, data migrations)\\n- Scheduled tasks (daily digests, cleanup jobs, recurring reports)\\n- Tasks requiring retry logic (external API calls, flaky operations)\\n- Priority-based processing (premium users first, critical alerts)\\n- Rate-limited operations (API quotas, third-party service limits)\\n\\n\u274c **NOT for**:\\n- Real-time bidirectional communication (use WebSockets)\\n- Sub-second latency requirements (use in-memory caching)\\n- Simple delays (setTimeout is fine for &lt;5 seconds)\\n- Synchronous API responses (keep logic in request handler)\\n\\n## Quick Decision Tree\\n\\n```\\nDoes this task:\\n\u251c\u2500\u2500 Take &gt;5 seconds? \u2192 Background job\\n\u251c\u2500\u2500 Need to retry on failure? \u2192 Background job\\n\u251c\u2500\u2500 Run on a schedule? \u2192 Background job (cron pattern)\\n\u251c\u2500\u2500 Block user interaction? \u2192 Background job\\n\u251c\u2500\u2500 Process in batches? \u2192 Background job\\n\u2514\u2500\u2500 Return immediately? \u2192 Keep synchronous\\n```\\n\\n---\\n\\n## Technology Selection\\n\\n### Node.js: BullMQ (Recommended 2024+)\\n\\n**When to use**:\\n- TypeScript project\\n- Redis already in stack\\n- Need advanced features (rate limiting, priorities, repeatable jobs)\\n\\n**Why BullMQ over Bull**:\\n- Bull (v3) \u2192 BullMQ (v4+): Complete rewrite in TypeScript\\n- Better Redis connection handling\\n- Improved concurrency and performance\\n- Active maintenance (Bull is in maintenance mode)\\n\\n### Python: Celery\\n\\n**When to use**:\\n- Python/Django project\\n- Need distributed task execution\\n- Complex workflows (chains, groups, chords)\\n\\n**Alternatives**:\\n- **RQ** (Redis Queue): Simpler, fewer features\\n- **Dramatiq**: Modern, less ecosystem\\n- **Huey**: Lightweight, good for small projects\\n\\n### Cloud-Native: AWS SQS, Google Cloud Tasks\\n\\n**When to use**:\\n- Serverless architecture\\n- Don't want to manage Redis/RabbitMQ\\n- Need guaranteed delivery and dead-letter queues\\n\\n---\\n\\n## Common Anti-Patterns\\n\\n### Anti-Pattern 1: No Dead Letter Queue\\n\\n**Novice thinking**: \\\"Retry 3 times, then fail silently\\\"\\n\\n**Problem**: Failed jobs disappear with no visibility or recovery path.\\n\\n**Correct approach**:\\n```typescript\\n// BullMQ with dead letter queue\\nconst queue = new Queue('email-queue', {\\n  connection: redis,\\n  defaultJobOptions: {\\n    attempts: 3,\\n    backoff: {\\n      type: 'exponential',\\n      delay: 2000\\n    },\\n    removeOnComplete: 100, // Keep last 100 successful\\n    removeOnFail: false     // Keep all failed for inspection\\n  }\\n});\\n\\n// Monitor failed jobs\\nconst failedJobs = await queue.getFailed();\\n```\\n\\n**Timeline**:\\n- Pre-2020: Retry and forget\\n- 2020+: Dead letter queues standard\\n- 2024+: Observability for job failures required\\n\\n---\\n\\n### Anti-Pattern 2: Synchronous Job Processing\\n\\n**Symptom**: API endpoint waits for job completion\\n\\n**Problem**:\\n```typescript\\n// \u274c WRONG - Blocks API response\\napp.post('/send-email', async (req, res) => {\\n  await sendEmail(req.body.to, req.body.subject);\\n  res.json({ success: true });\\n});\\n```\\n\\n**Why wrong**: Timeout, poor UX, wastes server resources\\n\\n**Correct approach**:\\n```typescript\\n// \u2705 RIGHT - Queue and return immediately\\napp.post('/send-email', async (req, res) => {\\n  const job = await emailQueue.add('send', {\\n    to: req.body.to,\\n    subject: req.body.subject\\n  });\\n\\n  res.json({\\n    success: true,\\n    jobId: job.id,\\n    status: 'queued'\\n  });\\n});\\n\\n// Separate worker processes the job\\nworker.process('send', async (job) => {\\n  await sendEmail(job.data.to, job.data.subject);\\n});\\n```\\n\\n---\\n\\n### Anti-Pattern 3: No Idempotency\\n\\n**Problem**: Job runs twice \u2192 duplicate charges, double emails\\n\\n**Why it happens**:\\n- Redis connection drops mid-processing\\n- Worker crashes before job completion\\n- Job timeout triggers retry while still running\\n\\n**Correct approach**:\\n```typescript\\n// \u2705 Idempotent job with deduplication key\\nawait queue.add('charge-payment', {\\n  userId: 123,\\n  amount: 50.00\\n}, {\\n  jobId: `payment-${orderId}`, // Prevents duplicates\\n  attempts: 3\\n});\\n\\n// In worker: Check if already processed\\nworker.process('charge-payment', async (job) => {\\n  const { userId, amount } = job.data;\\n\\n  // Check idempotency\\n  const existing = await db.payments.findOne({\\n    jobId: job.id\\n  });\\n  if (existing) {\\n    return existing; // Already processed\\n  }\\n\\n  // Process payment\\n  const result = await stripe.charges.create({...});\\n\\n  // Store idempotency record\\n  await db.payments.create({\\n    jobId: job.id,\\n    result\\n  });\\n\\n  return result;\\n});\\n```\\n\\n---\\n\\n### Anti-Pattern 4: No Rate Limiting\\n\\n**Problem**: Overwhelm third-party APIs or exhaust quotas\\n\\n**Symptom**: \\\"Rate limit exceeded\\\" errors from Sendgrid, Stripe, etc.\\n\\n**Correct approach**:\\n```typescript\\n// BullMQ rate limiting\\nconst queue = new Queue('api-calls', {\\n  limiter: {\\n    max: 100,        // Max 100 jobs\\n    duration: 60000  // Per 60 seconds\\n  }\\n});\\n\\n// Or: Priority-based rate limits\\nawait queue.add('send-email', data, {\\n  priority: user.isPremium ? 1 : 10,\\n  rateLimiter: {\\n    max: user.isPremium ? 1000 : 100,\\n    duration: 3600000 // Per hour\\n  }\\n});\\n```\\n\\n---\\n\\n### Anti-Pattern 5: Forgetting Worker Scaling\\n\\n**Problem**: Single worker can't keep up with queue depth\\n\\n**Symptom**: Queue backs up, jobs delayed hours/days\\n\\n**Correct approach**:\\n```typescript\\n// Horizontal scaling with multiple workers\\nconst worker = new Worker('email-queue', async (job) => {\\n  await processEmail(job.data);\\n}, {\\n  connection: redis,\\n  concurrency: 5  // Process 5 jobs concurrently per worker\\n});\\n\\n// Run multiple worker processes (PM2, Kubernetes, etc.)\\n// Each worker processes concurrency * num_workers jobs\\n```\\n\\n**Monitoring**:\\n```typescript\\n// Set up alerts for queue depth\\nsetInterval(async () => {\\n  const waiting = await queue.getWaitingCount();\\n  if (waiting > 1000) {\\n    alert('Queue depth exceeds 1000, scale workers!');\\n  }\\n}, 60000);\\n```\\n\\n---\\n\\n## Implementation Patterns\\n\\n### Pattern 1: Email Campaigns\\n\\n```typescript\\n// Queue setup\\nconst emailQueue = new Queue('email-campaign', { connection: redis });\\n\\n// Enqueue batch\\nasync function sendCampaign(userIds: number[], template: string) {\\n  const jobs = userIds.map(userId => ({\\n    name: 'send',\\n    data: { userId, template },\\n    opts: {\\n      attempts: 3,\\n      backoff: { type: 'exponential', delay: 5000 }\\n    }\\n  }));\\n\\n  await emailQueue.addBulk(jobs);\\n}\\n\\n// Worker with retry logic\\nconst worker = new Worker('email-campaign', async (job) => {\\n  const { userId, template } = job.data;\\n\\n  const user = await db.users.findById(userId);\\n  const email = renderTemplate(template, user);\\n\\n  try {\\n    await sendgrid.send({\\n      to: user.email,\\n      subject: email.subject,\\n      html: email.body\\n    });\\n  } catch (error) {\\n    if (error.code === 'ECONNREFUSED') {\\n      throw error; // Retry\\n    }\\n    // Invalid email, don't retry\\n    console.error(`Invalid email for user ${userId}`);\\n  }\\n}, {\\n  connection: redis,\\n  concurrency: 10\\n});\\n```\\n\\n### Pattern 2: Scheduled Reports\\n\\n```typescript\\n// Daily report at 9 AM\\nawait queue.add('daily-report', {\\n  type: 'sales',\\n  recipients: ['admin@company.com']\\n}, {\\n  repeat: {\\n    pattern: '0 9 * * *', // Cron syntax\\n    tz: 'America/New_York'\\n  }\\n});\\n\\n// Worker generates and emails report\\nworker.process('daily-report', async (job) => {\\n  const { type, recipients } = job.data;\\n\\n  const data = await generateReport(type);\\n  const pdf = await createPDF(data);\\n\\n  await emailQueue.add('send', {\\n    to: recipients,\\n    subject: `Daily ${type} Report`,\\n    attachments: [{ filename: 'report.pdf', content: pdf }]\\n  });\\n});\\n```\\n\\n### Pattern 3: Video Transcoding Pipeline\\n\\n```typescript\\n// Multi-stage job with progress tracking\\nawait videoQueue.add('transcode', {\\n  videoId: 123,\\n  formats: ['720p', '1080p', '4k']\\n}, {\\n  attempts: 2,\\n  timeout: 3600000 // 1 hour timeout\\n});\\n\\nworker.process('transcode', async (job) => {\\n  const { videoId, formats } = job.data;\\n\\n  for (let i = 0; i < formats.length; i++) {\\n    const format = formats[i];\\n\\n    // Update progress\\n    await job.updateProgress((i / formats.length) * 100);\\n\\n    // Transcode\\n    await ffmpeg.transcode(videoId, format);\\n  }\\n\\n  await job.updateProgress(100);\\n});\\n\\n// Client polls for progress\\napp.get('/videos/:id/status', async (req, res) => {\\n  const job = await queue.getJob(req.params.jobId);\\n  res.json({\\n    state: await job.getState(),\\n    progress: job.progress\\n  });\\n});\\n```\\n\\n---\\n\\n## Monitoring & Observability\\n\\n### Essential Metrics\\n\\n```typescript\\n// Queue health dashboard\\nasync function getQueueMetrics() {\\n  const [waiting, active, completed, failed, delayed] = await Promise.all([\\n    queue.getWaitingCount(),\\n    queue.getActiveCount(),\\n    queue.getCompletedCount(),\\n    queue.getFailedCount(),\\n    queue.getDelayedCount()\\n  ]);\\n\\n  return {\\n    waiting,    // Jobs waiting to be processed\\n    active,     // Jobs currently processing\\n    completed,  // Successfully completed\\n    failed,     // Failed after retries\\n    delayed,    // Scheduled for future\\n    health: waiting < 1000 && failed < 100 ? 'healthy' : 'degraded'\\n  };\\n}\\n```\\n\\n### BullMQ Board (UI)\\n\\n```typescript\\n// Development: Monitor jobs visually\\nimport { createBullBoard } from '@bull-board/api';\\nimport { BullMQAdapter } from '@bull-board/api/bullMQAdapter';\\nimport { ExpressAdapter } from '@bull-board/express';\\n\\nconst serverAdapter = new ExpressAdapter();\\n\\ncreateBullBoard({\\n  queues: [\\n    new BullMQAdapter(emailQueue),\\n    new BullMQAdapter(videoQueue)\\n  ],\\n  serverAdapter\\n});\\n\\napp.use('/admin/queues', serverAdapter.getRouter());\\n// Visit http://localhost:3000/admin/queues\\n```\\n\\n---\\n\\n## Production Checklist\\n\\n```\\n\u25a1 Dead letter queue configured\\n\u25a1 Retry strategy with exponential backoff\\n\u25a1 Job timeout limits set\\n\u25a1 Rate limiting for third-party APIs\\n\u25a1 Idempotency keys for critical operations\\n\u25a1 Worker concurrency tuned (CPU cores * 2)\\n\u25a1 Horizontal scaling configured (multiple workers)\\n\u25a1 Queue depth monitoring with alerts\\n\u25a1 Failed job inspection workflow\\n\u25a1 Job data doesn't contain PII in logs\\n\u25a1 Redis persistence enabled (AOF or RDB)\\n\u25a1 Graceful shutdown handling (SIGTERM)\\n```\\n\\n---\\n\\n## When to Use vs Avoid\\n\\n| Scenario | Use Background Jobs? |\\n|----------|---------------------|\\n| Send welcome email on signup | \u2705 Yes - can take 2-5 seconds |\\n| Charge credit card | \u26a0\ufe0f Maybe - depends on payment provider latency |\\n| Generate PDF report (30 seconds) | \u2705 Yes - definitely background |\\n| Fetch user profile from DB | \u274c No - milliseconds, keep synchronous |\\n| Process video upload (5 minutes) | \u2705 Yes - always background |\\n| Validate form input | \u274c No - synchronous validation |\\n| Daily cron job | \u2705 Yes - use repeatable jobs |\\n| Real-time chat message | \u274c No - use WebSockets |\\n\\n---\\n\\n## Technology Comparison\\n\\n| Feature | BullMQ | Celery | AWS SQS |\\n|---------|--------|--------|---------|\\n| Language | Node.js | Python | Any (HTTP API) |\\n| Backend | Redis | Redis/RabbitMQ/SQS | Managed |\\n| Priorities | \u2705 | \u2705 | \u2705 |\\n| Rate Limiting | \u2705 | \u274c | \u2705 (via attributes) |\\n| Repeat/Cron | \u2705 | \u2705 (celery-beat) | \u274c (use EventBridge) |\\n| UI Dashboard | Bull Board | Flower | CloudWatch |\\n| Workflows | \u274c | \u2705 (chains, groups) | \u274c |\\n| Learning Curve | Medium | Medium | Low |\\n| Cost | Redis hosting | Redis hosting | $0.40/million requests |\\n\\n---\\n\\n## References\\n\\n- `/references/bullmq-patterns.md` - Advanced BullMQ patterns and examples\\n- `/references/celery-workflows.md` - Celery chains, groups, and chords\\n- `/references/job-observability.md` - Monitoring, alerting, and debugging\\n\\n## Scripts\\n\\n- `scripts/setup_bullmq.sh` - Initialize BullMQ with Redis\\n- `scripts/queue_health_check.ts` - Queue metrics dashboard\\n- `scripts/retry_failed_jobs.ts` - Bulk retry failed jobs\\n\\n---\\n\\n**This skill guides**: Background job implementation | Queue architecture | Retry strategies | Worker scaling | Job observability\\n\"}]}")}}]);