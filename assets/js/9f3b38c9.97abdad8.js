"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[10228],{28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>i});var a=n(96540);const r={},o=a.createContext(r);function s(e){const t=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(o.Provider,{value:t},e.children)}},81451:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"skills/color_theory_palette_harmony_expert/references/arrangement-patterns","title":"Color Arrangement Patterns","description":"Neutral-with-Splash-of-Color Pattern","source":"@site/docs/skills/color_theory_palette_harmony_expert/references/arrangement-patterns.md","sourceDirName":"skills/color_theory_palette_harmony_expert/references","slug":"/skills/color_theory_palette_harmony_expert/references/arrangement-patterns","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/arrangement-patterns","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Color Arrangement Patterns","sidebar_label":"Color Arrangement Patterns","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Color Theory Palette Harmony Expert","permalink":"/docs/skills/color_theory_palette_harmony_expert/"},"next":{"title":"Diversity Algorithms: Preve...","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/diversity-algorithms"}}');var r=n(74848),o=n(28453);const s={title:"Color Arrangement Patterns",sidebar_label:"Color Arrangement Patterns",sidebar_position:1},i="Color Arrangement Patterns",l={},c=[{value:"Neutral-with-Splash-of-Color Pattern",id:"neutral-with-splash-of-color-pattern",level:2},{value:"Metrics",id:"metrics",level:3},{value:"Arrangement Algorithm",id:"arrangement-algorithm",level:3},{value:"Palette Compatibility Scoring",id:"palette-compatibility-scoring",level:2},{value:"Multi-Factor Score",id:"multi-factor-score",level:3},{value:"Hue Harmony Analysis",id:"hue-harmony-analysis",level:2},{value:"Global Color Grading for Collage Cohesion",id:"global-color-grading-for-collage-cohesion",level:2},{value:"Method 1: Histogram Matching",id:"method-1-histogram-matching",level:3},{value:"Method 2: Affine Color Transform",id:"method-2-affine-color-transform",level:3},{value:"Complete Example: Collage Assembly with Color Harmony",id:"complete-example-collage-assembly-with-color-harmony",level:2}];function p(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"color-arrangement-patterns",children:"Color Arrangement Patterns"})}),"\n",(0,r.jsx)(t.h2,{id:"neutral-with-splash-of-color-pattern",children:"Neutral-with-Splash-of-Color Pattern"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Design Principle:"})," Create visual impact by surrounding neutral/muted photos with occasional vibrant accents."]}),"\n",(0,r.jsx)(t.h3,{id:"metrics",children:"Metrics"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Chroma (Colorfulness):"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'def compute_average_chroma(palette_LCH):\n    """Average chroma weighted by pixel abundance."""\n    total_weight = sum(w for L, C, H, w in palette_LCH)\n    avg_chroma = sum(C * w for L, C, H, w in palette_LCH) / total_weight\n    return avg_chroma\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Classification:"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"Chroma < 20: Neutral/Muted\n20 \u2264 Chroma < 50: Moderate\nChroma \u2265 50: Vivid/Saturated\n"})}),"\n",(0,r.jsx)(t.h3,{id:"arrangement-algorithm",children:"Arrangement Algorithm"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'def neutral_with_accents_pattern(photos_with_palettes, accent_ratio=0.15):\n    """\n    Arrange photos with neutral background and vivid accents.\n\n    Args:\n        photos_with_palettes: [(photo_id, palette_LCH), ...]\n        accent_ratio: Target proportion of vivid photos (e.g., 0.15 = 15%)\n\n    Returns:\n        List of photo_ids with accents strategically placed\n    """\n    # Classify by chroma\n    neutral = []  # Chroma < 20\n    moderate = []  # 20 \u2264 Chroma < 50\n    vivid = []  # Chroma \u2265 50\n\n    for photo_id, palette in photos_with_palettes:\n        avg_chroma = compute_average_chroma(palette)\n\n        if avg_chroma < 20:\n            neutral.append((photo_id, avg_chroma))\n        elif avg_chroma < 50:\n            moderate.append((photo_id, avg_chroma))\n        else:\n            vivid.append((photo_id, avg_chroma))\n\n    # Sort vivid by chroma (most saturated first)\n    vivid.sort(key=lambda x: -x[1])\n\n    # Determine number of accents\n    total_photos = len(neutral) + len(moderate) + len(vivid)\n    target_accents = int(total_photos * accent_ratio)\n    accents = [pid for pid, _ in vivid[:target_accents]]\n\n    # Remaining vivid become moderate\n    moderate.extend((pid, c) for pid, c in vivid[target_accents:])\n\n    # Create base arrangement (neutral + moderate)\n    base = [pid for pid, _ in neutral] + [pid for pid, _ in moderate]\n    random.shuffle(base)\n\n    # Insert accents evenly\n    result = []\n    accent_step = len(base) / (len(accents) + 1) if accents else 0\n\n    base_idx = 0\n    accent_idx = 0\n\n    for i in range(total_photos):\n        if accent_idx < len(accents) and i >= (accent_idx + 1) * accent_step:\n            result.append(accents[accent_idx])\n            accent_idx += 1\n        elif base_idx < len(base):\n            result.append(base[base_idx])\n            base_idx += 1\n\n    return result\n'})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Visual Effect:"}),' Neutral photos form calm baseline, vivid photos create "pops" of visual interest at regular intervals.']}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"palette-compatibility-scoring",children:"Palette Compatibility Scoring"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Goal:"})," Given two photos, compute how well their palettes work together in a collage."]}),"\n",(0,r.jsx)(t.h3,{id:"multi-factor-score",children:"Multi-Factor Score"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"def palette_compatibility(palette1_LAB, palette2_LAB):\n    \"\"\"\n    Comprehensive palette compatibility score.\n\n    Returns:\n        float: 0-1 score (higher = more compatible)\n        dict: Breakdown of sub-scores\n    \"\"\"\n    # Convert to LCH for hue analysis\n    palette1_LCH = lab_to_lch(palette1_LAB)\n    palette2_LCH = lab_to_lch(palette2_LAB)\n\n    scores = {}\n\n    # 1. EMD (Wasserstein) distance in LAB space\n    emd = sinkhorn_emd(palette1_LAB, palette2_LAB, epsilon=0.1)\n    scores['emd_similarity'] = np.exp(-emd / 50)  # Convert to similarity\n\n    # 2. Hue harmony (complementary, analogous, etc.)\n    scores['hue_harmony'] = compute_hue_harmony(palette1_LCH, palette2_LCH)\n\n    # 3. Lightness balance\n    avg_L1 = np.mean([L for L, C, H, w in palette1_LCH])\n    avg_L2 = np.mean([L for L, C, H, w in palette2_LCH])\n    scores['lightness_balance'] = 1 - abs(avg_L1 - avg_L2) / 100\n\n    # 4. Chroma balance\n    avg_C1 = np.mean([C for L, C, H, w in palette1_LCH])\n    avg_C2 = np.mean([C for L, C, H, w in palette2_LCH])\n    scores['chroma_balance'] = 1 - abs(avg_C1 - avg_C2) / 100\n\n    # 5. Temperature compatibility (prefer contrast)\n    temp1 = temperature_score_LAB(palette1_LAB)\n    temp2 = temperature_score_LAB(palette2_LAB)\n    temp_diff = abs(temp1 - temp2)\n    scores['temperature_contrast'] = temp_diff  # Higher contrast = better\n\n    # 6. Overall compatibility (weighted sum)\n    compatibility = (\n        scores['emd_similarity'] * 0.35 +\n        scores['hue_harmony'] * 0.25 +\n        scores['lightness_balance'] * 0.15 +\n        scores['chroma_balance'] * 0.10 +\n        scores['temperature_contrast'] * 0.15\n    )\n\n    return compatibility, scores\n"})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"hue-harmony-analysis",children:"Hue Harmony Analysis"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'def compute_hue_harmony(palette1_LCH, palette2_LCH):\n    """\n    Score hue relationships (complementary, analogous, triadic).\n    """\n    # Extract dominant hues (weight by chroma)\n    hues1 = [H for L, C, H, w in palette1_LCH if C > 10]\n    hues2 = [H for L, C, H, w in palette2_LCH if C > 10]\n\n    if not hues1 or not hues2:\n        return 0.5  # Neutral score for near-grayscale\n\n    best_harmony = 0\n\n    for h1 in hues1[:3]:  # Check top 3 hues\n        for h2 in hues2[:3]:\n            diff = abs(h1 - h2)\n            if diff > 180:\n                diff = 360 - diff\n\n            # Complementary (180\xb0 \xb1 30\xb0)\n            if 150 < diff < 210:\n                harmony = 1.0 - abs(diff - 180) / 30\n                best_harmony = max(best_harmony, harmony)\n\n            # Analogous (0-60\xb0)\n            elif diff < 60:\n                harmony = 1.0 - diff / 60\n                best_harmony = max(best_harmony, harmony * 0.8)  # Slightly lower score\n\n            # Triadic (120\xb0 \xb1 20\xb0)\n            elif 100 < diff < 140:\n                harmony = 1.0 - abs(diff - 120) / 20\n                best_harmony = max(best_harmony, harmony * 0.9)\n\n    return best_harmony\n'})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"global-color-grading-for-collage-cohesion",children:"Global Color Grading for Collage Cohesion"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Problem:"})," Even with good local matches, collages can feel disjointed due to different white balance, exposure, saturation across photos."]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Solution:"})," Apply global color grading pass."]}),"\n",(0,r.jsx)(t.h3,{id:"method-1-histogram-matching",children:"Method 1: Histogram Matching"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"def match_histogram_LAB(source_image, target_palette):\n    \"\"\"\n    Adjust source image to match target color distribution.\n\n    Uses cumulative histogram matching in LAB space.\n    \"\"\"\n    # Convert source to LAB\n    source_LAB = rgb_to_lab(source_image)\n\n    # Extract LAB channels\n    L, a, b = cv2.split(source_LAB)\n\n    # Compute CDFs\n    source_L_cdf = compute_cdf(L)\n    source_a_cdf = compute_cdf(a)\n    source_b_cdf = compute_cdf(b)\n\n    # Target CDFs (from target palette)\n    target_L_cdf = palette_to_cdf(target_palette, channel='L')\n    target_a_cdf = palette_to_cdf(target_palette, channel='a')\n    target_b_cdf = palette_to_cdf(target_palette, channel='b')\n\n    # Match histograms\n    L_matched = match_cdf(L, source_L_cdf, target_L_cdf)\n    a_matched = match_cdf(a, source_a_cdf, target_a_cdf)\n    b_matched = match_cdf(b, source_b_cdf, target_b_cdf)\n\n    # Merge and convert back to RGB\n    matched_LAB = cv2.merge([L_matched, a_matched, b_matched])\n    matched_RGB = lab_to_rgb(matched_LAB)\n\n    return matched_RGB\n"})}),"\n",(0,r.jsx)(t.h3,{id:"method-2-affine-color-transform",children:"Method 2: Affine Color Transform"}),"\n",(0,r.jsx)(t.p,{children:"Using optimal transport, find affine transform T(x) = Mx + b that maps source palette to target:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'def compute_affine_color_transform(source_palette, target_palette):\n    """\n    Find affine transform in LAB space using Wasserstein regression.\n    """\n    # Extract colors and weights\n    source_colors = np.array([c for c, w in source_palette])  # (N, 3)\n    target_colors = np.array([c for c, w in target_palette])  # (M, 3)\n    source_weights = np.array([w for c, w in source_palette])\n    target_weights = np.array([w for c, w in target_palette])\n\n    # Compute transport plan via Sinkhorn\n    gamma = sinkhorn_transport_plan(source_palette, target_palette)\n\n    # Compute centroids\n    source_centroid = np.average(source_colors, weights=source_weights, axis=0)\n    target_centroid = np.average(target_colors, weights=target_weights, axis=0)\n\n    # Center data\n    X = source_colors - source_centroid  # (N, 3)\n    Y = target_colors - target_centroid  # (M, 3)\n\n    # Weighted covariance\n    C = Y.T @ gamma @ X  # (3, 3)\n\n    # Solve for M: M = C (\u03a3\u1d62\u2c7c \u03b3\u1d62\u2c7c x\u1d62 x\u1d62\u1d40)\u207b\xb9\n    X_cov = X.T @ np.diag(source_weights) @ X  # (3, 3)\n    M = C @ np.linalg.inv(X_cov)\n\n    # Solve for b\n    b = target_centroid - M @ source_centroid\n\n    return M, b\n\n\ndef apply_affine_color_transform(image, M, b):\n    """Apply affine transform to all pixels in LAB space."""\n    # Convert to LAB\n    image_LAB = rgb_to_lab(image)\n    h, w, _ = image_LAB.shape\n    pixels = image_LAB.reshape(-1, 3)  # (H*W, 3)\n\n    # Apply transform\n    transformed = (M @ pixels.T).T + b  # (H*W, 3)\n\n    # Clip to valid LAB range\n    transformed[:, 0] = np.clip(transformed[:, 0], 0, 100)      # L\n    transformed[:, 1] = np.clip(transformed[:, 1], -128, 127)   # a\n    transformed[:, 2] = np.clip(transformed[:, 2], -128, 127)   # b\n\n    # Reshape and convert back\n    transformed_LAB = transformed.reshape(h, w, 3)\n    transformed_RGB = lab_to_rgb(transformed_LAB)\n\n    return transformed_RGB\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Regularization (Preserve Local Structure):"})}),"\n",(0,r.jsx)(t.p,{children:"Add penalty to keep M close to identity:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"minimize:   W\u2082(T#\u03bc, \u03bd)\xb2 + \u03bb \u2016M - I\u2016\xb2_F\n"})}),"\n",(0,r.jsx)(t.p,{children:"This prevents extreme color shifts that destroy local structure."}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"complete-example-collage-assembly-with-color-harmony",children:"Complete Example: Collage Assembly with Color Harmony"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"def assemble_collage_with_color_harmony(\n    photo_database,\n    seed_photo_id,\n    target_size=(10, 10),\n    diversity_lambda=0.7,\n    temperature_pattern='alternating'  # 'alternating', 'wave', 'neutral-accent'\n):\n    \"\"\"\n    Complete collage assembly with advanced color harmony.\n    \"\"\"\n    # 1. Extract global target palette from seed\n    seed_palette = photo_database.get_palette(seed_photo_id)\n    global_palette = seed_palette.copy()\n\n    # 2. Select photos using MMR for diversity\n    all_photos = photo_database.get_all_photos()\n\n    # Filter by basic compatibility\n    compatible = []\n    for photo_id, palette in all_photos:\n        if photo_id == seed_photo_id:\n            continue\n\n        compat, _ = palette_compatibility(seed_palette, palette)\n        if compat > 0.4:\n            compatible.append((photo_id, palette, compat))\n\n    # Select using MMR\n    n_photos = target_size[0] * target_size[1] - 1\n    selected = select_photos_with_mmr(\n        compatible,\n        global_palette,\n        k=n_photos,\n        lambda_param=diversity_lambda\n    )\n\n    # 3. Arrange according to temperature pattern\n    all_photos_with_palettes = [(seed_photo_id, seed_palette)] + [\n        (pid, photo_database.get_palette(pid)) for pid in selected\n    ]\n\n    if temperature_pattern == 'alternating':\n        ordered = arrange_warm_cool_alternation(all_photos_with_palettes)\n    elif temperature_pattern == 'wave':\n        ordered = temperature_wave_pattern(all_photos_with_palettes, wave_length=5)\n    elif temperature_pattern == 'neutral-accent':\n        ordered = neutral_with_accents_pattern(all_photos_with_palettes, accent_ratio=0.15)\n    elif temperature_pattern == 'hue-sorted':\n        ordered = sort_photos_by_hue(all_photos_with_palettes)\n    else:\n        ordered = [pid for pid, _ in all_photos_with_palettes]\n\n    # 4. Place in grid\n    canvas = Canvas(target_size)\n    for idx, photo_id in enumerate(ordered):\n        row = idx // target_size[1]\n        col = idx % target_size[1]\n        canvas.place_photo(photo_id, position=(row, col))\n\n    # 5. Global color grading pass\n    global_palette = aggregate_palettes([\n        photo_database.get_palette(pid) for pid in ordered\n    ])\n\n    for photo_id in ordered:\n        image = photo_database.get_image(photo_id)\n        palette = photo_database.get_palette(photo_id)\n\n        M, b = compute_affine_color_transform(palette, global_palette)\n        graded = apply_affine_color_transform(image, M, b)\n        blended = 0.7 * image + 0.3 * graded  # 30% correction\n\n        canvas.update_photo(photo_id, blended)\n\n    # 6. Refine boundaries (Poisson blending)\n    canvas.refine_boundaries()\n\n    return canvas.render()\n"})})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);