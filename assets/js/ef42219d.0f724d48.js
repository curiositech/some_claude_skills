"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[72896],{7336:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"skills/voice_audio_engineer/index","title":"\ud83c\udfa8 Voice Audio Engineer","description":"Expert in voice synthesis, TTS, voice cloning, podcast production, speech processing, and voice UI design via ElevenLabs integration. Specializes in vocal clarity, loudness standards (LUFS), de-essing, dialogue mixing, and voice transformation. Activate on \'TTS\', \'text-to-speech\', \'voice clone\', \'voice synthesis\', \'ElevenLabs\', \'podcast\', \'voice recording\', \'speech-to-speech\', \'voice UI\', \'audiobook\', \'dialogue\'. NOT for spatial audio (use sound-engineer), music production (use DAW tools), game audio middleware (use sound-engineer), sound effects generation (use sound-engineer with ElevenLabs SFX), or live concert audio.","source":"@site/docs/skills/voice_audio_engineer/index.md","sourceDirName":"skills/voice_audio_engineer","slug":"/skills/voice_audio_engineer/","permalink":"/docs/skills/voice_audio_engineer/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Voice Audio Engineer","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Sound Engineering Implement...","permalink":"/docs/skills/sound_engineer/references/implementations"},"next":{"title":"Voice Audio Engineer","permalink":"/docs/skills/voice_audio_engineer/"}}');var r=i(74848),t=i(28453);const l={sidebar_label:"Voice Audio Engineer",sidebar_position:1},o="\ud83c\udfa8 Voice Audio Engineer",c={},d=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"References",id:"references",level:2},{value:"When to Use This Skill",id:"when-to-use-this-skill",level:2},{value:"MCP Integrations",id:"mcp-integrations",level:2},{value:"Expert vs Novice Shibboleths",id:"expert-vs-novice-shibboleths",level:2},{value:"Common Anti-Patterns",id:"common-anti-patterns",level:2},{value:"Anti-Pattern: Uploading Noisy Audio for Voice Cloning",id:"anti-pattern-uploading-noisy-audio-for-voice-cloning",level:3},{value:"Anti-Pattern: Ignoring Loudness Standards",id:"anti-pattern-ignoring-loudness-standards",level:3},{value:"Anti-Pattern: TTS Without Voice Matching",id:"anti-pattern-tts-without-voice-matching",level:3},{value:"Anti-Pattern: No De-essing on Processed Voice",id:"anti-pattern-no-de-essing-on-processed-voice",level:3},{value:"Anti-Pattern: Single Take, No Editing",id:"anti-pattern-single-take-no-editing",level:3},{value:"Evolution Timeline",id:"evolution-timeline",level:2},{value:"Pre-2020: Robotic TTS",id:"pre-2020-robotic-tts",level:3},{value:"2020-2022: Neural TTS Emerges",id:"2020-2022-neural-tts-emerges",level:3},{value:"2023-2024: AI Voice Revolution",id:"2023-2024-ai-voice-revolution",level:3},{value:"2025+: Current Best Practices",id:"2025-current-best-practices",level:3},{value:"Core Concepts",id:"core-concepts",level:2},{value:"ElevenLabs Voice Selection",id:"elevenlabs-voice-selection",level:3},{value:"Voice Cloning Best Practices",id:"voice-cloning-best-practices",level:3},{value:"Voice Processing Chain",id:"voice-processing-chain",level:3},{value:"Loudness Standards",id:"loudness-standards",level:3},{value:"Conversational AI Agents",id:"conversational-ai-agents",level:3},{value:"Quick Reference",id:"quick-reference",level:2},{value:"Voice Selection Decision Tree",id:"voice-selection-decision-tree",level:3},{value:"Processing Decision Tree",id:"processing-decision-tree",level:3},{value:"Common Settings",id:"common-settings",level:3},{value:"Working With Speech Disfluencies",id:"working-with-speech-disfluencies",level:2},{value:"Cluttering vs Stuttering",id:"cluttering-vs-stuttering",level:3},{value:"ASR Challenges with Disfluent Speech",id:"asr-challenges-with-disfluent-speech",level:3},{value:"Solutions &amp; Workarounds",id:"solutions--workarounds",level:3},{value:"Accessibility Considerations",id:"accessibility-considerations",level:3},{value:"Performance Targets",id:"performance-targets",level:2},{value:"Integrates With",id:"integrates-with",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"-voice-audio-engineer",children:"\ud83c\udfa8 Voice Audio Engineer"})}),"\n",(0,r.jsx)(n.p,{children:"Expert in voice synthesis, TTS, voice cloning, podcast production, speech processing, and voice UI design via ElevenLabs integration. Specializes in vocal clarity, loudness standards (LUFS), de-essing, dialogue mixing, and voice transformation. Activate on 'TTS', 'text-to-speech', 'voice clone', 'voice synthesis', 'ElevenLabs', 'podcast', 'voice recording', 'speech-to-speech', 'voice UI', 'audiobook', 'dialogue'. NOT for spatial audio (use sound-engineer), music production (use DAW tools), game audio middleware (use sound-engineer), sound effects generation (use sound-engineer with ElevenLabs SFX), or live concert audio."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Read, Write, Edit, Bash, mcp__firecrawl__firecrawl_search, WebFetch, mcp__ElevenLabs__text_to_speech, mcp__ElevenLabs__speech_to_speech, mcp__ElevenLabs__voice_clone, mcp__ElevenLabs__search_voices, mcp__ElevenLabs__speech_to_text, mcp__ElevenLabs__isolate_audio, mcp__ElevenLabs__create_agent\n"})}),"\n",(0,r.jsx)(n.h2,{id:"tags",children:"Tags"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"voice"})," ",(0,r.jsx)(n.code,{children:"tts"})," ",(0,r.jsx)(n.code,{children:"elevenlabs"})," ",(0,r.jsx)(n.code,{children:"podcast"})," ",(0,r.jsx)(n.code,{children:"synthesis"})]}),"\n",(0,r.jsx)(n.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/skills/sound_engineer",children:"Sound Engineer"})}),": Full audio production pipeline"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/skills/speech_pathology_ai",children:"Speech Pathology Ai"})}),": Clinical voice applications"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./references/implementations",children:"Voice Audio Implementation Reference"})}),"\n"]}),"\n",(0,r.jsx)(n.h1,{id:"voice--audio-engineer-voice-synthesis-tts--speech-processing",children:"Voice & Audio Engineer: Voice Synthesis, TTS & Speech Processing"}),"\n",(0,r.jsx)(n.p,{children:"Expert in voice synthesis, speech processing, and vocal production using ElevenLabs and professional audio techniques. Specializes in TTS, voice cloning, podcast production, and voice UI design."}),"\n",(0,r.jsx)(n.h2,{id:"when-to-use-this-skill",children:"When to Use This Skill"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Use for:"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Text-to-speech (TTS) generation"}),"\n",(0,r.jsx)(n.li,{children:"Voice cloning and voice design"}),"\n",(0,r.jsx)(n.li,{children:"Speech-to-speech voice transformation"}),"\n",(0,r.jsx)(n.li,{children:"Podcast production and editing"}),"\n",(0,r.jsx)(n.li,{children:"Audiobook production"}),"\n",(0,r.jsx)(n.li,{children:"Voice UI/conversational AI audio"}),"\n",(0,r.jsx)(n.li,{children:"Dialogue mixing and processing"}),"\n",(0,r.jsx)(n.li,{children:"Loudness normalization (LUFS)"}),"\n",(0,r.jsx)(n.li,{children:"Voice quality enhancement (de-essing, compression)"}),"\n",(0,r.jsx)(n.li,{children:"Transcription and speech-to-text"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Do NOT use for:"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Spatial audio (HRTF, Ambisonics) \u2192 ",(0,r.jsx)(n.strong,{children:"sound-engineer"})]}),"\n",(0,r.jsxs)(n.li,{children:["Sound effects generation \u2192 ",(0,r.jsx)(n.strong,{children:"sound-engineer"})," (ElevenLabs SFX)"]}),"\n",(0,r.jsxs)(n.li,{children:["Game audio middleware (Wwise, FMOD) \u2192 ",(0,r.jsx)(n.strong,{children:"sound-engineer"})]}),"\n",(0,r.jsx)(n.li,{children:"Music composition/production \u2192 DAW tools"}),"\n",(0,r.jsx)(n.li,{children:"Live concert/event audio \u2192 specialized domain"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"mcp-integrations",children:"MCP Integrations"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"MCP Tool"}),(0,r.jsx)(n.th,{children:"Purpose"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"text_to_speech"})}),(0,r.jsx)(n.td,{children:"Generate speech from text with voice selection"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"speech_to_speech"})}),(0,r.jsx)(n.td,{children:"Transform voice recordings to different voices"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"voice_clone"})}),(0,r.jsx)(n.td,{children:"Create instant voice clones from audio samples"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"search_voices"})}),(0,r.jsx)(n.td,{children:"Find voices in ElevenLabs library"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"speech_to_text"})}),(0,r.jsx)(n.td,{children:"Transcribe audio with speaker diarization"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"isolate_audio"})}),(0,r.jsx)(n.td,{children:"Separate voice from background noise"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"create_agent"})}),(0,r.jsx)(n.td,{children:"Build conversational AI agents with voice"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"expert-vs-novice-shibboleths",children:"Expert vs Novice Shibboleths"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Topic"}),(0,r.jsx)(n.th,{children:"Novice"}),(0,r.jsx)(n.th,{children:"Expert"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"TTS quality"})}),(0,r.jsx)(n.td,{children:'"Any voice works"'}),(0,r.jsx)(n.td,{children:"Matches voice to brand; considers emotion, pace, style"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Voice cloning"})}),(0,r.jsx)(n.td,{children:'"Upload any audio"'}),(0,r.jsx)(n.td,{children:"Knows 30s-3min of clean, varied speech needed; single speaker"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Loudness"})}),(0,r.jsx)(n.td,{children:'"Make it loud"'}),(0,r.jsx)(n.td,{children:"Targets -16 to -19 LUFS for podcasts; -14 for streaming"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"De-essing"})}),(0,r.jsx)(n.td,{children:'"Doesn\'t matter"'}),(0,r.jsx)(n.td,{children:"Knows sibilance lives at 5-8kHz; frequency-selective compression"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Compression"})}),(0,r.jsx)(n.td,{children:'"Squash it"'}),(0,r.jsx)(n.td,{children:"Uses 3:1-4:1 for dialogue; slow attack (10-20ms) to preserve transients"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"High-pass"})}),(0,r.jsx)(n.td,{children:'"Never use it"'}),(0,r.jsx)(n.td,{children:"Always HPF at 80-100Hz for voice; removes rumble, plosives"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"True peak"})}),(0,r.jsx)(n.td,{children:'"Peak is peak"'}),(0,r.jsx)(n.td,{children:"Knows intersample peaks exceed 0dBFS; targets -1 dBTP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"ElevenLabs models"})}),(0,r.jsx)(n.td,{children:'"Use default"'}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"eleven_multilingual_v2"})," for quality; ",(0,r.jsx)(n.code,{children:"eleven_flash_v2_5"})," for speed"]})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"common-anti-patterns",children:"Common Anti-Patterns"}),"\n",(0,r.jsx)(n.h3,{id:"anti-pattern-uploading-noisy-audio-for-voice-cloning",children:"Anti-Pattern: Uploading Noisy Audio for Voice Cloning"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it looks like"}),": Voice clone from phone recording with background noise, echo\n",(0,r.jsx)(n.strong,{children:"Why it's wrong"}),": Clone learns the noise; output has artifacts\n",(0,r.jsx)(n.strong,{children:"What to do instead"}),": Use ",(0,r.jsx)(n.code,{children:"isolate_audio"})," first; record in quiet space; provide 1-3 min of varied speech"]}),"\n",(0,r.jsx)(n.h3,{id:"anti-pattern-ignoring-loudness-standards",children:"Anti-Pattern: Ignoring Loudness Standards"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it looks like"}),": Podcast at -6 LUFS, then normalized by platform \u2192 crushed dynamics\n",(0,r.jsx)(n.strong,{children:"Why it's wrong"}),": Each platform normalizes differently; too loud = distortion, too quiet = inaudible\n",(0,r.jsx)(n.strong,{children:"What to do instead"}),": Master to -16 LUFS for podcasts; -14 LUFS for streaming; always check true peak < -1 dBTP"]}),"\n",(0,r.jsx)(n.h3,{id:"anti-pattern-tts-without-voice-matching",children:"Anti-Pattern: TTS Without Voice Matching"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it looks like"}),": Using default robotic voice for premium product\n",(0,r.jsx)(n.strong,{children:"Why it's wrong"}),": Voice IS brand; wrong voice = wrong emotional connection\n",(0,r.jsx)(n.strong,{children:"What to do instead"}),": ",(0,r.jsx)(n.code,{children:"search_voices"})," to find matching tone; consider custom clone for brand consistency"]}),"\n",(0,r.jsx)(n.h3,{id:"anti-pattern-no-de-essing-on-processed-voice",children:"Anti-Pattern: No De-essing on Processed Voice"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it looks like"}),': "SSSSibilant" speech after compression and EQ boost\n',(0,r.jsx)(n.strong,{children:"Why it's wrong"}),": Compression brings up sibilance; EQ boost at 3-5kHz makes it worse\n",(0,r.jsx)(n.strong,{children:"What to do instead"}),": De-ess at 5-8kHz before compression; use frequency-selective compression"]}),"\n",(0,r.jsx)(n.h3,{id:"anti-pattern-single-take-no-editing",children:"Anti-Pattern: Single Take, No Editing"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it looks like"}),': Podcast with 20 "ums", breath sounds, long pauses\n',(0,r.jsx)(n.strong,{children:"Why it's wrong"}),": Listeners fatigue; unprofessional; reduces engagement\n",(0,r.jsx)(n.strong,{children:"What to do instead"}),": Edit out filler words; gate or manually cut breaths; tighten pacing"]}),"\n",(0,r.jsx)(n.h2,{id:"evolution-timeline",children:"Evolution Timeline"}),"\n",(0,r.jsx)(n.h3,{id:"pre-2020-robotic-tts",children:"Pre-2020: Robotic TTS"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Concatenative synthesis (spliced recordings)"}),"\n",(0,r.jsx)(n.li,{children:"Obvious robotic quality"}),"\n",(0,r.jsx)(n.li,{children:"Limited voice options"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2020-2022-neural-tts-emerges",children:"2020-2022: Neural TTS Emerges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Tacotron, WaveNet improve naturalness"}),"\n",(0,r.jsx)(n.li,{children:"Still detectable as synthetic"}),"\n",(0,r.jsx)(n.li,{children:"Voice cloning requires hours of data"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2023-2024-ai-voice-revolution",children:"2023-2024: AI Voice Revolution"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"ElevenLabs instant voice cloning (30 seconds)"}),"\n",(0,r.jsx)(n.li,{children:"Near-human quality in TTS"}),"\n",(0,r.jsx)(n.li,{children:"Real-time voice transformation"}),"\n",(0,r.jsx)(n.li,{children:"Voice agents for customer service"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2025-current-best-practices",children:"2025+: Current Best Practices"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Emotional TTS (control tone, pace, emotion)"}),"\n",(0,r.jsx)(n.li,{children:"Cross-lingual voice cloning"}),"\n",(0,r.jsx)(n.li,{children:"Real-time voice transformation in apps"}),"\n",(0,r.jsx)(n.li,{children:"Personalized voice agents"}),"\n",(0,r.jsx)(n.li,{children:"Voice authentication integration"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,r.jsx)(n.h3,{id:"elevenlabs-voice-selection",children:"ElevenLabs Voice Selection"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Model comparison:"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Model"}),(0,r.jsx)(n.th,{children:"Quality"}),(0,r.jsx)(n.th,{children:"Latency"}),(0,r.jsx)(n.th,{children:"Languages"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"eleven_multilingual_v2"})}),(0,r.jsx)(n.td,{children:"Best"}),(0,r.jsx)(n.td,{children:"Higher"}),(0,r.jsx)(n.td,{children:"29"}),(0,r.jsx)(n.td,{children:"Production, quality-critical"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"eleven_flash_v2_5"})}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"Lowest"}),(0,r.jsx)(n.td,{children:"32"}),(0,r.jsx)(n.td,{children:"Real-time, voice UI"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"eleven_turbo_v2_5"})}),(0,r.jsx)(n.td,{children:"Better"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"32"}),(0,r.jsx)(n.td,{children:"Balanced"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Voice parameters:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Stability: 0-1 (lower = more expressive, higher = more consistent)\n# Similarity boost: 0-1 (higher = closer to original voice)\n# Style: 0-1 (higher = more exaggerated style)\n\n# For natural speech:\nstability = 0.5       # Balanced expression\nsimilarity = 0.75     # Close to voice but natural\nstyle = 0.0           # Neutral (increase for dramatic)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"voice-cloning-best-practices",children:"Voice Cloning Best Practices"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Audio requirements:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Duration: 1-3 minutes (more = better, diminishing returns after 3min)"}),"\n",(0,r.jsx)(n.li,{children:"Quality: Clean, no background noise, no reverb"}),"\n",(0,r.jsx)(n.li,{children:"Content: Varied speech (questions, statements, emotions)"}),"\n",(0,r.jsx)(n.li,{children:"Format: WAV/MP3, 44.1kHz or higher"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Cloning workflow:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"isolate_audio"})," to clean source material"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"voice_clone"})," with cleaned audio"]}),"\n",(0,r.jsx)(n.li,{children:"Test with varied prompts"}),"\n",(0,r.jsx)(n.li,{children:"Adjust stability/similarity for output quality"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"voice-processing-chain",children:"Voice Processing Chain"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Standard voice chain (order matters!):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[Raw Recording]\n    \u2193\n[High-Pass Filter @ 80Hz]  \u2190 Remove rumble, plosives\n    \u2193\n[De-esser @ 5-8kHz]        \u2190 Before compression!\n    \u2193\n[Compressor 3:1, 10ms/100ms] \u2190 Smooth dynamics\n    \u2193\n[EQ: +2dB @ 3kHz presence] \u2190 Clarity boost\n    \u2193\n[Limiter -1 dBTP]          \u2190 Prevent clipping\n    \u2193\n[Loudness Norm -16 LUFS]   \u2190 Target loudness\n"})}),"\n",(0,r.jsx)(n.h3,{id:"loudness-standards",children:"Loudness Standards"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform/Format"}),(0,r.jsx)(n.th,{children:"Target LUFS"}),(0,r.jsx)(n.th,{children:"True Peak"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Podcast"}),(0,r.jsx)(n.td,{children:"-16 to -19"}),(0,r.jsx)(n.td,{children:"-1 dBTP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Audiobook (ACX)"}),(0,r.jsx)(n.td,{children:"-18 to -23 RMS"}),(0,r.jsx)(n.td,{children:"-3 dBFS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"YouTube"}),(0,r.jsx)(n.td,{children:"-14"}),(0,r.jsx)(n.td,{children:"-1 dBTP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Spotify/Apple Music"}),(0,r.jsx)(n.td,{children:"-14"}),(0,r.jsx)(n.td,{children:"-1 dBTP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Broadcast (EBU R128)"}),(0,r.jsx)(n.td,{children:"-23 \xb11"}),(0,r.jsx)(n.td,{children:"-1 dBTP"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Measurement:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"LUFS = Loudness Units Full Scale (integrated)"}),"\n",(0,r.jsx)(n.li,{children:"True Peak = Maximum level including intersample peaks"}),"\n",(0,r.jsx)(n.li,{children:"Always measure with K-weighting (ITU-R BS.1770)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"conversational-ai-agents",children:"Conversational AI Agents"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"ElevenLabs agent configuration:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'create_agent(\n    name="Support Agent",\n    first_message="Hi, how can I help you today?",\n    system_prompt="You are a helpful customer support agent...",\n    voice_id="your_voice_id",\n    language="en",\n    llm="gemini-2.0-flash-001",  # Fast for conversation\n    temperature=0.5,\n    asr_quality="high",          # Speech recognition quality\n    turn_timeout=7,              # Seconds before agent responds\n    max_duration_seconds=300     # 5 minute call limit\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Voice UI considerations:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use fast model (",(0,r.jsx)(n.code,{children:"eleven_flash_v2_5"}),") for real-time"]}),"\n",(0,r.jsx)(n.li,{children:"Keep responses concise (< 30 seconds)"}),"\n",(0,r.jsx)(n.li,{children:"Add pauses for natural conversation flow"}),"\n",(0,r.jsx)(n.li,{children:"Handle interruptions gracefully"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"quick-reference",children:"Quick Reference"}),"\n",(0,r.jsx)(n.h3,{id:"voice-selection-decision-tree",children:"Voice Selection Decision Tree"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Brand/professional content?"})," \u2192 Custom clone or curated voice"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time/interactive?"})," \u2192 ",(0,r.jsx)(n.code,{children:"eleven_flash_v2_5"})," model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quality-critical?"})," \u2192 ",(0,r.jsx)(n.code,{children:"eleven_multilingual_v2"})," model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple languages?"})," \u2192 Check language support per voice"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"processing-decision-tree",children:"Processing Decision Tree"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Voice sounds muddy?"})," \u2192 HPF at 80Hz, boost 3kHz"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sibilance harsh?"})," \u2192 De-ess at 5-8kHz"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inconsistent volume?"})," \u2192 Compress 3:1, then limit"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Too quiet?"})," \u2192 Normalize to target LUFS"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Background noise?"})," \u2192 Use ",(0,r.jsx)(n.code,{children:"isolate_audio"})," first"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"common-settings",children:"Common Settings"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"De-esser: 5-8kHz, -6dB reduction, Q=2\nCompressor: 3:1 ratio, -20dB threshold, 10ms attack, 100ms release\nEQ presence: +2-3dB shelf at 3kHz\nHPF: 80-100Hz, 12dB/oct\nLimiter: -1 dBTP ceiling\n"})}),"\n",(0,r.jsx)(n.h2,{id:"working-with-speech-disfluencies",children:"Working With Speech Disfluencies"}),"\n",(0,r.jsx)(n.h3,{id:"cluttering-vs-stuttering",children:"Cluttering vs Stuttering"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Characteristics"}),(0,r.jsx)(n.th,{children:"ASR Impact"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Stuttering"})}),(0,r.jsx)(n.td,{children:'Repetitions ("I-I-I"), prolongations ("wwwant"), blocks (silent pauses)'}),(0,r.jsx)(n.td,{children:"Word boundaries confused; repetitions misrecognized"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cluttering"})}),(0,r.jsx)(n.td,{children:"Irregular rate, collapsed syllables, filler overload, tangential speech"}),(0,r.jsx)(n.td,{children:"Words merged; rate changes confuse timing"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"asr-challenges-with-disfluent-speech",children:"ASR Challenges with Disfluent Speech"}),"\n",(0,r.jsx)(n.p,{children:"Most ASR models trained on fluent speech. Disfluencies cause:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Word boundary detection errors"}),"\n",(0,r.jsx)(n.li,{children:'Repetitions transcribed literally ("I I I want" vs "I want")'}),"\n",(0,r.jsx)(n.li,{children:"Collapsed syllables missed entirely"}),"\n",(0,r.jsx)(n.li,{children:"Timing models confused by irregular pace"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"solutions--workarounds",children:"Solutions & Workarounds"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Model selection (best to worst for disfluencies):"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Whisper large-v3"})," - Most robust to disfluencies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ElevenLabs speech_to_text"})," - Good with varied speech"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Google Speech-to-Text"})," - Decent with enhanced models"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fast/lightweight models"})," - Usually worst"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2. Pre-processing:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Normalize speech rate before ASR\n# Use librosa to stretch irregular segments toward target rate\nimport librosa\ny, sr = librosa.load("disfluent.wav")\ny_stretched = librosa.effects.time_stretch(y, rate=0.9)  # Slow down\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Post-processing:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'Remove duplicate words: "I I I want" \u2192 "I want"'}),"\n",(0,r.jsx)(n.li,{children:'Filter common fillers: "um", "uh", "like", "you know"'}),"\n",(0,r.jsx)(n.li,{children:"Use LLM to clean transcripts while preserving meaning"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"4. Fine-tuning Whisper (advanced):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Fine-tune on disfluent speech dataset\n# Datasets: FluencyBank, UCLASS, SEP-28k (stuttering)\nfrom transformers import WhisperForConditionalGeneration, WhisperProcessor\n\nmodel = WhisperForConditionalGeneration.from_pretrained("openai/whisper-large-v3")\n# Fine-tune on your speech samples with corrected transcripts\n# Training loop with disfluent audio \u2192 fluent transcript pairs\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"5. ElevenLabs voice cloning approach:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Clone your voice from fluent segments"}),"\n",(0,r.jsx)(n.li,{children:"Use TTS for fluent output with your voice"}),"\n",(0,r.jsx)(n.li,{children:"Great for pre-recorded content, not live"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"accessibility-considerations",children:"Accessibility Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Always provide manual transcript correction option"}),"\n",(0,r.jsx)(n.li,{children:"Consider hybrid: ASR + human review"}),"\n",(0,r.jsx)(n.li,{children:"For voice UI: longer timeout, confirmation prompts"}),"\n",(0,r.jsx)(n.li,{children:"Test with actual users from target population"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Operation"}),(0,r.jsx)(n.th,{children:"Typical Time"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TTS (100 words)"}),(0,r.jsx)(n.td,{children:"2-5 seconds"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Voice clone creation"}),(0,r.jsx)(n.td,{children:"10-30 seconds"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Speech-to-speech"}),(0,r.jsx)(n.td,{children:"3-8 seconds"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Transcription (1 min audio)"}),(0,r.jsx)(n.td,{children:"5-15 seconds"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Audio isolation"}),(0,r.jsx)(n.td,{children:"5-20 seconds"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"integrates-with",children:"Integrates With"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"sound-engineer"})," - For spatial audio, game audio, procedural SFX"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"native-app-designer"})," - Voice UI implementation in apps"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"vr-avatar-engineer"})," - Avatar voice integration"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For detailed implementations"}),": See ",(0,r.jsx)(n.code,{children:"/references/implementations.md"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Remember"}),": Voice is intimate\u2014it speaks directly to the listener's brain. Match voice to brand, process for clarity not loudness, and always respect the platform's loudness standards. With ElevenLabs, you have instant access to professional voice synthesis; use it thoughtfully."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(96540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);