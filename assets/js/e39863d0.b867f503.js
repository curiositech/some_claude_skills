"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[96309],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(96540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},79866:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"skills/event_detection_temporal_intelligence_expert/references/event-scoring-shareability","title":"Event Significance Scoring & Shareability Prediction","description":"Event Significance Scoring","source":"@site/docs/skills/event_detection_temporal_intelligence_expert/references/event-scoring-shareability.md","sourceDirName":"skills/event_detection_temporal_intelligence_expert/references","slug":"/skills/event_detection_temporal_intelligence_expert/references/event-scoring-shareability","permalink":"/docs/skills/event_detection_temporal_intelligence_expert/references/event-scoring-shareability","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Event Significance Scoring & Shareability Prediction","sidebar_label":"Event Significance Scoring ...","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Event Detection Temporal Intelligence Expert","permalink":"/docs/skills/event_detection_temporal_intelligence_expert/"},"next":{"title":"Place Recognition & Life Ev...","permalink":"/docs/skills/event_detection_temporal_intelligence_expert/references/place-recognition-life-events"}}');var r=t(74848),s=t(28453);const o={title:"Event Significance Scoring & Shareability Prediction",sidebar_label:"Event Significance Scoring ...",sidebar_position:1},a="Event Significance Scoring & Shareability Prediction",c={},l=[{value:"Event Significance Scoring",id:"event-significance-scoring",level:2},{value:"Multi-Factor Scoring Model",id:"multi-factor-scoring-model",level:3},{value:"Weight Customization",id:"weight-customization",level:3},{value:"Shareability Prediction",id:"shareability-prediction",level:2},{value:"Feature Categories",id:"feature-categories",level:3},{value:"Model Implementation",id:"model-implementation",level:3},{value:"Training the Model",id:"training-the-model",level:3},{value:"Shareability Decision Tree",id:"shareability-decision-tree",level:3},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"event-significance-scoring--shareability-prediction",children:"Event Significance Scoring & Shareability Prediction"})}),"\n",(0,r.jsx)(n.h2,{id:"event-significance-scoring",children:"Event Significance Scoring"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Goal:"})," Not all events are equal. Birthday party > Daily commute photos."]}),"\n",(0,r.jsx)(n.h3,{id:"multi-factor-scoring-model",children:"Multi-Factor Scoring Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class EventSignificanceScorer:\n    \"\"\"\n    Score how significant/memorable an event is.\n    \"\"\"\n\n    def score_event(self, event_photos, global_corpus):\n        \"\"\"\n        Compute event significance (0-1 scale).\n\n        Args:\n            event_photos: Photos in this event\n            global_corpus: All photos (for rarity comparison)\n\n        Returns:\n            float: Significance score\n            dict: Breakdown of factors\n        \"\"\"\n        factors = {}\n\n        # 1. DURATION: Longer events are more significant\n        duration_hours = self.compute_duration(event_photos)\n        factors['duration'] = min(1.0, duration_hours / 24)  # Cap at 1 day\n\n        # 2. PHOTO DENSITY: More photos = more memorable\n        photos_per_hour = len(event_photos) / max(1, duration_hours)\n        factors['density'] = min(1.0, photos_per_hour / 10)  # Cap at 10/hour\n\n        # 3. VISUAL DIVERSITY: Special events have varied shots\n        visual_diversity = self.compute_visual_diversity(event_photos)\n        factors['diversity'] = visual_diversity\n\n        # 4. PEOPLE PRESENCE: Events with people > landscapes\n        people_ratio = self.count_people_photos(event_photos) / len(event_photos)\n        factors['people'] = people_ratio\n\n        # 5. LOCATION RARITY: Exotic locations > home\n        location_rarity = self.compute_location_rarity(event_photos, global_corpus)\n        factors['location_rarity'] = location_rarity\n\n        # 6. CONTENT RARITY: Landmarks, weddings, celebrations\n        content_rarity = self.detect_special_content(event_photos)\n        factors['content'] = content_rarity\n\n        # 7. USER ENGAGEMENT: Shared/edited photos matter more\n        engagement = self.compute_engagement(event_photos)\n        factors['engagement'] = engagement\n\n        # 8. TEMPORAL RARITY: Annual events (birthdays, holidays)\n        temporal_rarity = self.detect_annual_patterns(event_photos, global_corpus)\n        factors['temporal'] = temporal_rarity\n\n        # Weighted combination\n        significance = (\n            factors['duration'] * 0.10 +\n            factors['density'] * 0.15 +\n            factors['diversity'] * 0.10 +\n            factors['people'] * 0.15 +\n            factors['location_rarity'] * 0.20 +\n            factors['content'] * 0.15 +\n            factors['engagement'] * 0.10 +\n            factors['temporal'] * 0.05\n        )\n\n        return significance, factors\n\n    def compute_visual_diversity(self, event_photos):\n        \"\"\"\n        Measure visual diversity using CLIP embeddings.\n\n        High diversity = special event (many different scenes)\n        Low diversity = mundane (all photos look similar)\n        \"\"\"\n        if len(event_photos) < 2:\n            return 0.0\n\n        embeddings = np.array([p.clip_embedding for p in event_photos])\n\n        # Compute pairwise cosine distances\n        from scipy.spatial.distance import pdist\n        distances = pdist(embeddings, metric='cosine')\n\n        # Mean distance = diversity\n        diversity = np.mean(distances)\n\n        return min(1.0, diversity / 0.5)  # Normalize (0.5 = highly diverse)\n\n    def compute_location_rarity(self, event_photos, global_corpus):\n        \"\"\"\n        How rare is this location in user's photo history?\n\n        Exotic travel locations are rare, home is common.\n        \"\"\"\n        # Get location cluster of event\n        event_location = self.get_median_location(event_photos)\n\n        # Count photos within 10km of this location in entire corpus\n        nearby_count = sum(\n            1 for p in global_corpus\n            if haversine_distance(p.lat, p.lon,\n                                 event_location[0], event_location[1]) < 10000\n        )\n\n        # Rarity = inverse frequency\n        rarity = 1.0 - min(1.0, nearby_count / len(global_corpus))\n\n        return rarity\n\n    def detect_special_content(self, event_photos):\n        \"\"\"\n        Detect special content using CLIP zero-shot classification.\n\n        Special categories: landmarks, weddings, birthdays, concerts, etc.\n        \"\"\"\n        special_categories = {\n            'famous landmark': 0.9,\n            'wedding ceremony': 0.95,\n            'birthday party': 0.85,\n            'concert performance': 0.8,\n            'graduation ceremony': 0.9,\n            'fireworks display': 0.85,\n            'rainbow': 0.8,\n            'northern lights': 0.95,\n            'wildlife': 0.75,\n            'sports event': 0.7,\n        }\n\n        max_score = 0\n        for photo in event_photos[:10]:  # Sample first 10\n            # CLIP zero-shot classification\n            probs = clip_classify(photo.image, list(special_categories.keys()))\n\n            for category, prob in probs.items():\n                if prob > 0.3:  # Confidence threshold\n                    score = special_categories[category] * prob\n                    max_score = max(max_score, score)\n\n        return max_score\n"})}),"\n",(0,r.jsx)(n.h3,{id:"weight-customization",children:"Weight Customization"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Factor"}),(0,r.jsx)(n.th,{children:"Default Weight"}),(0,r.jsx)(n.th,{children:"Increase If"}),(0,r.jsx)(n.th,{children:"Decrease If"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"duration"}),(0,r.jsx)(n.td,{children:"0.10"}),(0,r.jsx)(n.td,{children:"User prefers longer trips"}),(0,r.jsx)(n.td,{children:"Quick events matter more"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"density"}),(0,r.jsx)(n.td,{children:"0.15"}),(0,r.jsx)(n.td,{children:"High-activity events"}),(0,r.jsx)(n.td,{children:"Sparse documentation OK"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"diversity"}),(0,r.jsx)(n.td,{children:"0.10"}),(0,r.jsx)(n.td,{children:"Visual variety important"}),(0,r.jsx)(n.td,{children:"Consistent themes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"people"}),(0,r.jsx)(n.td,{children:"0.15"}),(0,r.jsx)(n.td,{children:"Social photos prioritized"}),(0,r.jsx)(n.td,{children:"Solo/landscape focus"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"location_rarity"}),(0,r.jsx)(n.td,{children:"0.20"}),(0,r.jsx)(n.td,{children:"Travel photos important"}),(0,r.jsx)(n.td,{children:"Local events matter"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"content"}),(0,r.jsx)(n.td,{children:"0.15"}),(0,r.jsx)(n.td,{children:"Special occasions"}),(0,r.jsx)(n.td,{children:"Everyday moments"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"engagement"}),(0,r.jsx)(n.td,{children:"0.10"}),(0,r.jsx)(n.td,{children:"Social media signals"}),(0,r.jsx)(n.td,{children:"Raw photos only"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"temporal"}),(0,r.jsx)(n.td,{children:"0.05"}),(0,r.jsx)(n.td,{children:"Annual patterns important"}),(0,r.jsx)(n.td,{children:"Random events"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"shareability-prediction",children:"Shareability Prediction"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Goal:"})," Predict which photos are likely to be shared on social media."]}),"\n",(0,r.jsx)(n.h3,{id:"feature-categories",children:"Feature Categories"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visual Features"}),": Aesthetic quality, composition, vibrancy, sharpness"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Emotional Features"}),": Facial expressions, emotion recognition"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Content Features"}),": People count, landmarks, food, pets"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal Features"}),": Recency, special dates"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Complexity Features"}),": Moderate complexity most shareable (2025 research)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"model-implementation",children:"Model Implementation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class ShareabilityPredictor:\n    \"\"\"\n    Predict likelihood of photo being shared on social media.\n\n    Based on: \"Predicting Social Media Engagement from Emotional and\n              Temporal Features\" (arXiv 2025)\n    \"\"\"\n\n    def predict(self, photo, event_context=None):\n        \"\"\"\n        Predict shareability score (0-1).\n\n        Args:\n            photo: PhotoPoint with metadata\n            event_context: Optional Event object for context\n\n        Returns:\n            float: Shareability score\n            dict: Feature contributions\n        \"\"\"\n        features = {}\n\n        # VISUAL FEATURES\n        features['aesthetic'] = photo.aesthetic_score\n        features['composition'] = photo.composition_score\n        features['vibrancy'] = self.compute_vibrancy(photo.image)\n        features['sharpness'] = self.compute_sharpness(photo.image)\n\n        # EMOTIONAL FEATURES\n        if photo.has_faces:\n            features['emotion_positive'] = self.detect_positive_emotion(photo)\n        else:\n            features['emotion_positive'] = 0.5  # Neutral\n\n        # CONTENT FEATURES\n        features['people_count'] = min(photo.face_count / 5, 1.0)\n        features['has_landmark'] = 1.0 if photo.has_landmark else 0.0\n        features['has_food'] = 1.0 if self.detect_food(photo) else 0.0\n        features['has_pet'] = 1.0 if photo.has_pet else 0.0\n\n        # TEMPORAL FEATURES\n        days_old = (datetime.now() - photo.timestamp).days\n        features['recency'] = max(0, 1 - days_old / 30)  # Decay over 30 days\n\n        if event_context:\n            features['event_significance'] = event_context.significance_score\n            features['is_special_date'] = 1.0 if self.is_special_date(photo.timestamp) else 0.0\n        else:\n            features['event_significance'] = 0.5\n            features['is_special_date'] = 0.0\n\n        # COMPLEXITY (2025 research finding)\n        complexity = self.compute_visual_complexity(photo.image)\n        # Moderate complexity most shareable (inverted U-curve)\n        features['optimal_complexity'] = 1.0 - abs(complexity - 0.5) * 2\n\n        # Convert to feature vector\n        feature_vector = np.array(list(features.values()))\n\n        # Predict using trained model\n        shareability = self.model.predict(feature_vector.reshape(1, -1))[0]\n\n        return shareability, features\n\n    def compute_visual_complexity(self, image):\n        \"\"\"\n        Compute visual complexity using edge density.\n\n        Research finding: Moderate complexity (0.4-0.6) most shareable.\n        \"\"\"\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        edges = cv2.Canny(gray, 50, 150)\n        complexity = edges.mean() / 255\n        return complexity\n"})}),"\n",(0,r.jsx)(n.h3,{id:"training-the-model",children:"Training the Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def create_shareability_dataset(user_photos):\n    """\n    Create training dataset from user\'s sharing history.\n\n    Positive examples: Photos user actually shared\n    Negative examples: Photos from same events that weren\'t shared\n    """\n    X = []  # Feature vectors\n    y = []  # 1 = shared, 0 = not shared\n\n    for photo in user_photos:\n        features = extract_features(photo)\n        X.append(features)\n        y.append(1 if photo.was_shared else 0)\n\n    return np.array(X), np.array(y)\n\n\ndef train_shareability_model(X, y):\n    """\n    Train gradient boosting model for shareability prediction.\n\n    Uses XGBoost for interpretability and performance.\n    """\n    from xgboost import XGBClassifier\n\n    model = XGBClassifier(\n        n_estimators=100,\n        max_depth=5,\n        learning_rate=0.1,\n        objective=\'binary:logistic\'\n    )\n\n    model.fit(X, y)\n    return model\n'})}),"\n",(0,r.jsx)(n.h3,{id:"shareability-decision-tree",children:"Shareability Decision Tree"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'Photo Shareability Assessment:\n\u2502\n\u251c\u2500 Has smiling faces? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.3 base score\n\u2502   \u2514\u2500 Group photo (3+ people)? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.2 bonus\n\u2502\n\u251c\u2500 Famous landmark detected? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.25\n\u2502\n\u251c\u2500 Food/dining scene? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.15\n\u2502\n\u251c\u2500 Aesthetic quality > 7/10? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.2\n\u2502\n\u251c\u2500 Taken within last 7 days? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.1 recency\n\u2502\n\u251c\u2500 Part of significant event? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 +0.15\n\u2502\n\u2514\u2500 Moderate visual complexity (0.4-0.6)? \u2500\u2500\u2500\u2500 +0.1\n\nThreshold: > 0.6 = "Highly Shareable"\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:'"Predicting Social Media Engagement from Emotional and Temporal Features" (arXiv, August 2025)'}),"\n",(0,r.jsx)(n.li,{children:"Pinterest engagement prediction research (2025)"}),"\n",(0,r.jsx)(n.li,{children:"Meta intent modeling (2025)"}),"\n",(0,r.jsx)(n.li,{children:"Visual content persuasiveness features (2024)"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);