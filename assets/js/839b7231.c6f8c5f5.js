"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[64158],{28453:(e,n,s)=>{s.d(n,{R:()=>c,x:()=>l});var i=s(96540);const t={},r=i.createContext(t);function c(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),i.createElement(r.Provider,{value:n},e.children)}},94622:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>c,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"skills/photo_content_recognition_curation_expert/references/face-clustering","title":"Face Recognition & Clustering Reference","description":"Overview","source":"@site/docs/skills/photo_content_recognition_curation_expert/references/face-clustering.md","sourceDirName":"skills/photo_content_recognition_curation_expert/references","slug":"/skills/photo_content_recognition_curation_expert/references/face-clustering","permalink":"/docs/skills/photo_content_recognition_curation_expert/references/face-clustering","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Face Recognition & Clustering Reference","sidebar_label":"Face Recognition & Clusteri...","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Content Detection Reference","permalink":"/docs/skills/photo_content_recognition_curation_expert/references/content-detection"},"next":{"title":"Perceptual Hashing Implemen...","permalink":"/docs/skills/photo_content_recognition_curation_expert/references/perceptual-hashing"}}');var t=s(74848),r=s(28453);const c={title:"Face Recognition & Clustering Reference",sidebar_label:"Face Recognition & Clusteri...",sidebar_position:2},l="Face Recognition & Clustering Reference",a={},o=[{value:"Overview",id:"overview",level:2},{value:"Face Detection &amp; Embedding Extraction",id:"face-detection--embedding-extraction",level:2},{value:"Apple-Style Two-Pass Agglomerative Clustering",id:"apple-style-two-pass-agglomerative-clustering",level:2},{value:"HDBSCAN Alternative (More Robust to Noise)",id:"hdbscan-alternative-more-robust-to-noise",level:2},{value:"Method Comparison",id:"method-comparison",level:2},{value:"Parameters",id:"parameters",level:2},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"face-recognition--clustering-reference",children:"Face Recognition & Clustering Reference"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Group photos by person without user labeling using face detection, embedding extraction, and clustering."}),"\n",(0,t.jsx)(n.h2,{id:"face-detection--embedding-extraction",children:"Face Detection & Embedding Extraction"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from facenet_pytorch import MTCNN, InceptionResnetV1\nimport torch\n\nclass FaceEmbeddingExtractor:\n    \"\"\"Extract face embeddings using FaceNet (512-dim vectors).\"\"\"\n\n    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n\n        # MTCNN for face detection\n        self.mtcnn = MTCNN(\n            image_size=160,\n            margin=0,\n            min_face_size=20,\n            device=self.device\n        )\n\n        # InceptionResnetV1 for embeddings\n        self.resnet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n\n    def extract_faces(self, image):\n        \"\"\"\n        Detect and extract face embeddings.\n        Returns: List of (face_crop, embedding, bounding_box) tuples\n        \"\"\"\n        boxes, probs = self.mtcnn.detect(image)\n\n        if boxes is None:\n            return []\n\n        faces = []\n        for box, prob in zip(boxes, probs):\n            if prob < 0.9:\n                continue\n\n            face_crop = self.mtcnn.extract(image, [box], save_path=None)[0]\n            face_tensor = face_crop.unsqueeze(0).to(self.device)\n\n            with torch.no_grad():\n                embedding = self.resnet(face_tensor).cpu().numpy().flatten()\n\n            faces.append({\n                'crop': face_crop,\n                'embedding': embedding,\n                'bbox': box,\n                'confidence': prob\n            })\n\n        return faces\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"apple-style-two-pass-agglomerative-clustering",children:"Apple-Style Two-Pass Agglomerative Clustering"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Strategy (Apple Photos 2021-2025):"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Extract face + upper body embeddings"}),"\n",(0,t.jsx)(n.li,{children:"Two-pass agglomerative clustering"}),"\n",(0,t.jsx)(n.li,{children:"Conservative first pass (high precision)"}),"\n",(0,t.jsx)(n.li,{children:"HAC second pass (increase recall)"}),"\n",(0,t.jsx)(n.li,{children:"Incremental updates for new photos"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from sklearn.cluster import AgglomerativeClustering\nfrom scipy.spatial.distance import cosine\nimport numpy as np\n\nclass ApplePhotosFaceClustering:\n    """\n    Two-pass agglomerative clustering inspired by Apple Photos.\n    Based on: "Recognizing People in Photos Through Private On-Device ML" (Apple ML, 2021)\n    """\n\n    def __init__(self):\n        self.distance_threshold_pass1 = 0.4  # Conservative (high precision)\n        self.distance_threshold_pass2 = 0.6  # Relaxed (increase recall)\n\n    def cluster_faces(self, face_embeddings, photo_ids):\n        """Cluster face embeddings into person clusters."""\n        if len(face_embeddings) < 2:\n            return {0: list(range(len(face_embeddings)))}\n\n        embeddings = np.array(face_embeddings)\n\n        # PASS 1: Conservative clustering\n        clustering_pass1 = AgglomerativeClustering(\n            n_clusters=None,\n            distance_threshold=self.distance_threshold_pass1,\n            linkage=\'average\',\n            metric=\'cosine\'\n        )\n        labels_pass1 = clustering_pass1.fit_predict(embeddings)\n\n        # Compute cluster centroids from pass 1\n        unique_labels = np.unique(labels_pass1)\n        cluster_centroids = []\n        cluster_members = {}\n\n        for label in unique_labels:\n            mask = labels_pass1 == label\n            cluster_emb = embeddings[mask]\n            centroid = np.median(cluster_emb, axis=0)\n            cluster_centroids.append(centroid)\n            cluster_members[label] = np.where(mask)[0].tolist()\n\n        # PASS 2: Merge similar clusters\n        if len(cluster_centroids) > 1:\n            clustering_pass2 = AgglomerativeClustering(\n                n_clusters=None,\n                distance_threshold=self.distance_threshold_pass2,\n                linkage=\'average\',\n                metric=\'cosine\'\n            )\n            centroid_labels = clustering_pass2.fit_predict(np.array(cluster_centroids))\n\n            final_clusters = {}\n            for old_label, new_label in enumerate(centroid_labels):\n                if new_label not in final_clusters:\n                    final_clusters[new_label] = []\n                final_clusters[new_label].extend(cluster_members[old_label])\n        else:\n            final_clusters = cluster_members\n\n        return final_clusters\n\n    def incremental_update(self, existing_clusters, new_faces, new_embeddings):\n        """Incrementally add new faces to existing clusters."""\n        updated_clusters = existing_clusters.copy()\n        unassigned_faces = []\n\n        for face_idx, embedding in enumerate(new_embeddings):\n            min_distance = float(\'inf\')\n            closest_cluster = None\n\n            for cluster_id, face_indices in existing_clusters.items():\n                cluster_embeddings = [face_embeddings[i] for i in face_indices]\n                cluster_median = np.median(cluster_embeddings, axis=0)\n                distance = cosine(embedding, cluster_median)\n\n                if distance < min_distance:\n                    min_distance = distance\n                    closest_cluster = cluster_id\n\n            if min_distance < self.distance_threshold_pass2:\n                updated_clusters[closest_cluster].append(face_idx)\n            else:\n                unassigned_faces.append(face_idx)\n\n        # Create new clusters for unassigned\n        if unassigned_faces:\n            next_cluster_id = max(updated_clusters.keys()) + 1\n            for face_idx in unassigned_faces:\n                updated_clusters[next_cluster_id] = [face_idx]\n                next_cluster_id += 1\n\n        return updated_clusters\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"hdbscan-alternative-more-robust-to-noise",children:"HDBSCAN Alternative (More Robust to Noise)"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Advantage:"})," Doesn't require distance threshold, automatically finds optimal clustering."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import hdbscan\n\nclass HDBSCANFaceClustering:\n    """\n    HDBSCAN for face clustering.\n    More robust than agglomerative, doesn\'t need threshold tuning.\n    """\n\n    def __init__(self, min_cluster_size=3, min_samples=1):\n        self.min_cluster_size = min_cluster_size\n        self.min_samples = min_samples\n\n    def cluster_faces(self, face_embeddings):\n        """Cluster faces using HDBSCAN."""\n        if len(face_embeddings) < self.min_cluster_size:\n            return np.zeros(len(face_embeddings), dtype=int)\n\n        embeddings = np.array(face_embeddings)\n\n        clusterer = hdbscan.HDBSCAN(\n            min_cluster_size=self.min_cluster_size,\n            min_samples=self.min_samples,\n            metric=\'cosine\',\n            cluster_selection_method=\'eom\'\n        )\n\n        return clusterer.fit_predict(embeddings)\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"method-comparison",children:"Method Comparison"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Method"}),(0,t.jsx)(n.th,{children:"Pros"}),(0,t.jsx)(n.th,{children:"Cons"}),(0,t.jsx)(n.th,{children:"Use When"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Agglomerative"})}),(0,t.jsx)(n.td,{children:"Fast, deterministic, Apple-proven"}),(0,t.jsx)(n.td,{children:"Needs threshold tuning"}),(0,t.jsx)(n.td,{children:"Have tuned thresholds"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"HDBSCAN"})}),(0,t.jsx)(n.td,{children:"Automatic, robust to noise"}),(0,t.jsx)(n.td,{children:"Slower, non-deterministic"}),(0,t.jsx)(n.td,{children:"Unknown data distribution"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Face Detection:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"min_face_size"}),": 20px (detect small faces)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"confidence_threshold"}),": 0.9 (high confidence only)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Clustering:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"distance_threshold_pass1"}),": 0.4 (conservative)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"distance_threshold_pass2"}),": 0.6 (relaxed for recall)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"min_cluster_size"}),": 3 (minimum photos of same person)"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:'"Recognizing People in Photos Through Private On-Device Machine Learning" (Apple ML Research, 2021)'}),"\n",(0,t.jsx)(n.li,{children:"FaceNet: A Unified Embedding for Face Recognition and Clustering"}),"\n",(0,t.jsx)(n.li,{children:"HDBSCAN: Hierarchical Density-Based Spatial Clustering (2013-2025)"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);