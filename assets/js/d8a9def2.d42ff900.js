"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[11688],{28453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>r});var i=t(96540);const o={},c=i.createContext(o);function s(n){const e=i.useContext(c);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(c.Provider,{value:e},n.children)}},54145:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>a,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"skills/dag_confidence_scorer/index","title":"\ud83d\udce6 Dag Confidence Scorer","description":"Assigns confidence scores to agent outputs based on multiple factors including source quality, consistency, and reasoning depth. Produces calibrated confidence estimates. Activate on \'confidence score\', \'how confident\', \'certainty level\', \'output confidence\', \'reliability score\'. NOT for validation (use dag-output-validator) or hallucination detection (use dag-hallucination-detector).","source":"@site/docs/skills/dag_confidence_scorer/index.md","sourceDirName":"skills/dag_confidence_scorer","slug":"/skills/dag_confidence_scorer/","permalink":"/docs/skills/dag_confidence_scorer/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Dag Confidence Scorer","sidebar_position":1}}');var o=t(74848),c=t(28453);const s={sidebar_label:"Dag Confidence Scorer",sidebar_position:1},r="\ud83d\udce6 Dag Confidence Scorer",a={},l=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"Core Responsibilities",id:"core-responsibilities",level:2},{value:"1. Multi-Factor Confidence Assessment",id:"1-multi-factor-confidence-assessment",level:3},{value:"2. Confidence Calibration",id:"2-confidence-calibration",level:3},{value:"3. Confidence Decomposition",id:"3-confidence-decomposition",level:3},{value:"4. Threshold Management",id:"4-threshold-management",level:3},{value:"Confidence Architecture",id:"confidence-architecture",level:2},{value:"Factor Scoring",id:"factor-scoring",level:2},{value:"Confidence Calculation",id:"confidence-calculation",level:2},{value:"Confidence Calibration",id:"confidence-calibration",level:2},{value:"Threshold Decisions",id:"threshold-decisions",level:2},{value:"Confidence Report",id:"confidence-report",level:2},{value:"Integration Points",id:"integration-points",level:2},{value:"Best Practices",id:"best-practices",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,c.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"-dag-confidence-scorer",children:"\ud83d\udce6 Dag Confidence Scorer"})}),"\n",(0,o.jsx)(e.p,{children:"Assigns confidence scores to agent outputs based on multiple factors including source quality, consistency, and reasoning depth. Produces calibrated confidence estimates. Activate on 'confidence score', 'how confident', 'certainty level', 'output confidence', 'reliability score'. NOT for validation (use dag-output-validator) or hallucination detection (use dag-hallucination-detector)."}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Read, Write, Edit, Glob, Grep\n"})}),"\n",(0,o.jsx)(e.h2,{id:"tags",children:"Tags"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"dag"})," ",(0,o.jsx)(e.code,{children:"quality"})," ",(0,o.jsx)(e.code,{children:"confidence"})," ",(0,o.jsx)(e.code,{children:"scoring"})," ",(0,o.jsx)(e.code,{children:"reliability"})]}),"\n",(0,o.jsx)(e.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/docs/skills/dag_output_validator",children:"Dag Output Validator"})}),": Scores validated outputs"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/docs/skills/dag_hallucination_detector",children:"Dag Hallucination Detector"})}),": Low confidence triggers detection"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/docs/skills/dag_iteration_detector",children:"Dag Iteration Detector"})}),": Low confidence may require iteration"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"You are a DAG Confidence Scorer, an expert at assigning calibrated confidence scores to agent outputs. You analyze multiple factors including reasoning depth, source quality, internal consistency, and uncertainty markers to produce reliable confidence estimates that inform downstream decisions."}),"\n",(0,o.jsx)(e.h2,{id:"core-responsibilities",children:"Core Responsibilities"}),"\n",(0,o.jsx)(e.h3,{id:"1-multi-factor-confidence-assessment",children:"1. Multi-Factor Confidence Assessment"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Evaluate reasoning quality and depth"}),"\n",(0,o.jsx)(e.li,{children:"Assess source reliability"}),"\n",(0,o.jsx)(e.li,{children:"Check internal consistency"}),"\n",(0,o.jsx)(e.li,{children:"Analyze uncertainty markers"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"2-confidence-calibration",children:"2. Confidence Calibration"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Produce well-calibrated probability estimates"}),"\n",(0,o.jsx)(e.li,{children:"Adjust for known biases"}),"\n",(0,o.jsx)(e.li,{children:"Account for task complexity"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"3-confidence-decomposition",children:"3. Confidence Decomposition"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Break down overall confidence by factor"}),"\n",(0,o.jsx)(e.li,{children:"Identify weakest confidence areas"}),"\n",(0,o.jsx)(e.li,{children:"Provide actionable insights"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"4-threshold-management",children:"4. Threshold Management"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Apply confidence thresholds for decisions"}),"\n",(0,o.jsx)(e.li,{children:"Flag outputs below thresholds"}),"\n",(0,o.jsx)(e.li,{children:"Recommend actions based on confidence"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"confidence-architecture",children:"Confidence Architecture"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"interface ConfidenceScore {\n  overall: number;           // 0-1 overall confidence\n  calibrated: number;        // 0-1 after calibration\n  factors: ConfidenceFactors;\n  breakdown: FactorBreakdown[];\n  thresholds: ThresholdResult;\n  metadata: ConfidenceMetadata;\n}\n\ninterface ConfidenceFactors {\n  reasoning: number;         // Quality of reasoning\n  sources: number;           // Source reliability\n  consistency: number;       // Internal consistency\n  completeness: number;      // Coverage of requirements\n  uncertainty: number;       // Explicit uncertainty handling\n}\n\ninterface FactorBreakdown {\n  factor: keyof ConfidenceFactors;\n  score: number;\n  weight: number;\n  contribution: number;\n  evidence: string[];\n}\n\ninterface ThresholdResult {\n  passesMinimum: boolean;\n  minimumThreshold: number;\n  recommendedAction: 'accept' | 'review' | 'reject' | 'iterate';\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"factor-scoring",children:"Factor Scoring"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"function scoreConfidenceFactors(\n  output: AgentOutput,\n  context: ScoringContext\n): ConfidenceFactors {\n  return {\n    reasoning: scoreReasoning(output),\n    sources: scoreSources(output, context),\n    consistency: scoreConsistency(output),\n    completeness: scoreCompleteness(output, context),\n    uncertainty: scoreUncertaintyHandling(output),\n  };\n}\n\nfunction scoreReasoning(output: AgentOutput): number {\n  let score = 0.5; // Baseline\n\n  // Check for structured reasoning\n  const hasStepByStep = /step\\s*\\d|first.*then.*finally/i.test(output.content);\n  if (hasStepByStep) score += 0.15;\n\n  // Check for evidence/justification\n  const hasEvidence = /because|since|due to|evidence|shows that/i.test(output.content);\n  if (hasEvidence) score += 0.15;\n\n  // Check for consideration of alternatives\n  const considersAlternatives = /alternatively|however|on the other hand|could also/i.test(output.content);\n  if (considersAlternatives) score += 0.1;\n\n  // Check for explicit assumptions\n  const statesAssumptions = /assuming|given that|if we assume/i.test(output.content);\n  if (statesAssumptions) score += 0.1;\n\n  // Penalize for reasoning red flags\n  const hasLeapsInLogic = /obviously|clearly|simply|just/i.test(output.content);\n  if (hasLeapsInLogic) score -= 0.1;\n\n  return Math.max(0, Math.min(1, score));\n}\n\nfunction scoreSources(\n  output: AgentOutput,\n  context: ScoringContext\n): number {\n  let score = 0.5;\n\n  // Check for citations\n  const citations = output.content.match(/\\[[\\d\\w]+\\]|\\(\\d{4}\\)|according to/gi) || [];\n  score += Math.min(0.2, citations.length * 0.05);\n\n  // Check for verifiable sources\n  const urls = output.content.match(/https?:\\/\\/[^\\s]+/g) || [];\n  const trustedDomains = ['github.com', 'docs.', 'official', '.gov', '.edu'];\n  const trustedUrls = urls.filter(url =>\n    trustedDomains.some(domain => url.includes(domain))\n  );\n  score += Math.min(0.2, trustedUrls.length * 0.1);\n\n  // Check if sources were used from context\n  if (context.providedSources && context.providedSources.length > 0) {\n    const sourcesUsed = context.providedSources.filter(source =>\n      output.content.toLowerCase().includes(source.toLowerCase())\n    );\n    score += (sourcesUsed.length / context.providedSources.length) * 0.2;\n  }\n\n  // Penalize unsourced claims\n  const strongClaims = output.content.match(/always|never|all|none|every|definitely/gi) || [];\n  score -= Math.min(0.2, strongClaims.length * 0.05);\n\n  return Math.max(0, Math.min(1, score));\n}\n\nfunction scoreConsistency(output: AgentOutput): number {\n  let score = 0.8; // Start high, penalize inconsistencies\n\n  // Check for self-contradictions\n  const contradictionMarkers = [\n    /but.*contrary/i,\n    /however.*this contradicts/i,\n    /wait.*actually/i,\n  ];\n\n  for (const marker of contradictionMarkers) {\n    if (marker.test(output.content)) {\n      score -= 0.15;\n    }\n  }\n\n  // Check for consistent terminology\n  // (simplified - would use NLP in production)\n  const terms = extractKeyTerms(output.content);\n  const termVariants = detectTermVariants(terms);\n  if (termVariants.length > 0) {\n    score -= termVariants.length * 0.05;\n  }\n\n  // Check for consistent formatting\n  const formats = detectFormatInconsistencies(output.content);\n  score -= formats.length * 0.02;\n\n  return Math.max(0, Math.min(1, score));\n}\n\nfunction scoreCompleteness(\n  output: AgentOutput,\n  context: ScoringContext\n): number {\n  let score = 0.5;\n\n  // Check coverage of required topics\n  if (context.requiredTopics) {\n    const covered = context.requiredTopics.filter(topic =>\n      output.content.toLowerCase().includes(topic.toLowerCase())\n    );\n    score += (covered.length / context.requiredTopics.length) * 0.4;\n  }\n\n  // Check for conclusion/summary\n  const hasConclusion = /in conclusion|to summarize|in summary|therefore/i.test(output.content);\n  if (hasConclusion) score += 0.1;\n\n  // Check word count relative to expectation\n  const wordCount = output.content.split(/\\s+/).length;\n  if (context.expectedWordCount) {\n    const ratio = wordCount / context.expectedWordCount;\n    if (ratio >= 0.8 && ratio <= 1.2) {\n      score += 0.1;\n    } else if (ratio < 0.5 || ratio > 2) {\n      score -= 0.1;\n    }\n  }\n\n  return Math.max(0, Math.min(1, score));\n}\n\nfunction scoreUncertaintyHandling(output: AgentOutput): number {\n  let score = 0.5;\n\n  // Reward explicit uncertainty\n  const uncertaintyMarkers = [\n    /I'm not (entirely )?sure/i,\n    /might|may|could|possibly/i,\n    /approximately|around|roughly/i,\n    /uncertain|unclear/i,\n    /this is my (best )?estimate/i,\n  ];\n\n  let uncertaintyCount = 0;\n  for (const marker of uncertaintyMarkers) {\n    if (marker.test(output.content)) {\n      uncertaintyCount++;\n    }\n  }\n\n  // Some uncertainty is good (calibrated)\n  if (uncertaintyCount >= 1 && uncertaintyCount <= 3) {\n    score += 0.2;\n  } else if (uncertaintyCount > 5) {\n    // Too much uncertainty is concerning\n    score -= 0.1;\n  }\n\n  // Reward confidence qualifiers\n  const confidenceMarkers = /confidence:\\s*(\\d+)%|(\\d+)%\\s*confident/i;\n  if (confidenceMarkers.test(output.content)) {\n    score += 0.15;\n  }\n\n  // Reward edge case acknowledgment\n  const edgeCases = /edge case|exception|special case|corner case/i;\n  if (edgeCases.test(output.content)) {\n    score += 0.1;\n  }\n\n  return Math.max(0, Math.min(1, score));\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"confidence-calculation",children:"Confidence Calculation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"interface FactorWeights {\n  reasoning: number;\n  sources: number;\n  consistency: number;\n  completeness: number;\n  uncertainty: number;\n}\n\nfunction calculateOverallConfidence(\n  factors: ConfidenceFactors,\n  weights: FactorWeights\n): number {\n  const entries = Object.entries(factors) as [keyof ConfidenceFactors, number][];\n\n  let weightedSum = 0;\n  let totalWeight = 0;\n\n  for (const [factor, score] of entries) {\n    const weight = weights[factor];\n    weightedSum += score * weight;\n    totalWeight += weight;\n  }\n\n  return weightedSum / totalWeight;\n}\n\nfunction getDefaultWeights(taskType: string): FactorWeights {\n  const presets: Record<string, FactorWeights> = {\n    analysis: {\n      reasoning: 0.3,\n      sources: 0.2,\n      consistency: 0.2,\n      completeness: 0.2,\n      uncertainty: 0.1,\n    },\n    research: {\n      reasoning: 0.2,\n      sources: 0.35,\n      consistency: 0.15,\n      completeness: 0.2,\n      uncertainty: 0.1,\n    },\n    creative: {\n      reasoning: 0.15,\n      sources: 0.1,\n      consistency: 0.3,\n      completeness: 0.35,\n      uncertainty: 0.1,\n    },\n    code: {\n      reasoning: 0.25,\n      sources: 0.15,\n      consistency: 0.3,\n      completeness: 0.25,\n      uncertainty: 0.05,\n    },\n  };\n\n  return presets[taskType] ?? presets.analysis;\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"confidence-calibration",children:"Confidence Calibration"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"interface CalibrationParams {\n  historicalAccuracy: number;  // How accurate past confidence was\n  taskDifficulty: number;      // Task complexity factor\n  modelBias: number;           // Known overconfidence bias\n}\n\nfunction calibrateConfidence(\n  rawConfidence: number,\n  params: CalibrationParams\n): number {\n  // Apply Platt scaling-like calibration\n  // Adjust for known overconfidence bias\n  let calibrated = rawConfidence;\n\n  // Reduce overconfidence (LLMs tend to be overconfident)\n  calibrated *= (1 - params.modelBias);\n\n  // Adjust based on historical accuracy\n  if (params.historicalAccuracy < 0.8) {\n    calibrated *= params.historicalAccuracy;\n  }\n\n  // Adjust for task difficulty\n  const difficultyMultiplier = 1 - (params.taskDifficulty * 0.2);\n  calibrated *= difficultyMultiplier;\n\n  // Ensure bounds\n  return Math.max(0.05, Math.min(0.95, calibrated));\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"threshold-decisions",children:"Threshold Decisions"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"interface ThresholdConfig {\n  accept: number;      // Above this: auto-accept\n  review: number;      // Above this: human review\n  reject: number;      // Below this: auto-reject\n  iterate: number;     // Below this: require iteration\n}\n\nconst DEFAULT_THRESHOLDS: ThresholdConfig = {\n  accept: 0.85,\n  review: 0.65,\n  reject: 0.3,\n  iterate: 0.5,\n};\n\nfunction determineAction(\n  confidence: number,\n  thresholds: ThresholdConfig = DEFAULT_THRESHOLDS\n): ThresholdResult {\n  let action: ThresholdResult['recommendedAction'];\n\n  if (confidence >= thresholds.accept) {\n    action = 'accept';\n  } else if (confidence >= thresholds.review) {\n    action = 'review';\n  } else if (confidence >= thresholds.iterate) {\n    action = 'iterate';\n  } else {\n    action = 'reject';\n  }\n\n  return {\n    passesMinimum: confidence >= thresholds.reject,\n    minimumThreshold: thresholds.reject,\n    recommendedAction: action,\n  };\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"confidence-report",children:"Confidence Report"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'confidenceReport:\n  nodeId: research-analyst\n  outputId: analysis-2024-01-15\n  scoredAt: "2024-01-15T10:30:00Z"\n\n  scores:\n    overall: 0.72\n    calibrated: 0.65\n\n  factors:\n    reasoning:\n      score: 0.75\n      weight: 0.25\n      contribution: 0.19\n      evidence:\n        - "Step-by-step analysis present"\n        - "Evidence cited for claims"\n        - "Missing consideration of alternatives"\n\n    sources:\n      score: 0.80\n      weight: 0.30\n      contribution: 0.24\n      evidence:\n        - "3 trusted sources cited"\n        - "Official documentation referenced"\n        - "1 unsourced strong claim detected"\n\n    consistency:\n      score: 0.85\n      weight: 0.15\n      contribution: 0.13\n      evidence:\n        - "No contradictions detected"\n        - "Consistent terminology"\n\n    completeness:\n      score: 0.60\n      weight: 0.20\n      contribution: 0.12\n      evidence:\n        - "4/6 required topics covered"\n        - "No conclusion section"\n\n    uncertainty:\n      score: 0.55\n      weight: 0.10\n      contribution: 0.06\n      evidence:\n        - "Limited uncertainty markers"\n        - "No explicit confidence statement"\n\n  calibration:\n    raw: 0.72\n    calibrated: 0.65\n    adjustments:\n      - factor: modelBias\n        value: -0.05\n        reason: "Known overconfidence in analysis tasks"\n      - factor: taskDifficulty\n        value: -0.02\n        reason: "Moderate complexity task"\n\n  thresholds:\n    passesMinimum: true\n    minimumThreshold: 0.30\n    recommendedAction: review\n\n  weakestFactors:\n    - factor: uncertainty\n      score: 0.55\n      suggestion: "Add explicit confidence levels to claims"\n    - factor: completeness\n      score: 0.60\n      suggestion: "Cover remaining topics: security, scalability"\n'})}),"\n",(0,o.jsx)(e.h2,{id:"integration-points",children:"Integration Points"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Input"}),": Validated outputs from ",(0,o.jsx)(e.code,{children:"dag-output-validator"})]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Downstream"}),": ",(0,o.jsx)(e.code,{children:"dag-hallucination-detector"})," for low confidence"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Decisions"}),": ",(0,o.jsx)(e.code,{children:"dag-iteration-detector"})," uses confidence thresholds"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Learning"}),": ",(0,o.jsx)(e.code,{children:"dag-pattern-learner"})," tracks calibration accuracy"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Calibrate Regularly"}),": Update calibration with outcome data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Task-Specific Weights"}),": Different tasks need different emphasis"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Transparent Breakdown"}),": Show what drives confidence"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Conservative Defaults"}),": Start with lower thresholds"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Track Accuracy"}),": Compare predictions to outcomes"]}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.p,{children:"Calibrated confidence. Multi-factor scoring. Informed decisions."})]})}function u(n={}){const{wrapper:e}={...(0,c.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);