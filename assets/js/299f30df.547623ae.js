"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[73978],{8858:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"skills/ai_engineer/index","title":"\ud83e\udd16 Ai Engineer","description":"Build production-ready LLM applications, advanced RAG systems, and intelligent agents. Implements vector search, multimodal AI, agent orchestration, and enterprise AI integrations. Use PROACTIVELY for LLM features, chatbots, AI agents, or AI-powered applications.","source":"@site/docs/skills/ai_engineer/index.md","sourceDirName":"skills/ai_engineer","slug":"/skills/ai_engineer/","permalink":"/docs/skills/ai_engineer/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Ai Engineer","sidebar_position":1}}');var i=t(74848),r=t(28453);const l={sidebar_label:"Ai Engineer",sidebar_position:1},a="\ud83e\udd16 Ai Engineer",d={},c=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Core Competencies",id:"core-competencies",level:2},{value:"1. RAG System Design",id:"1-rag-system-design",level:3},{value:"2. LLM Application Patterns",id:"2-llm-application-patterns",level:3},{value:"3. Production Operations",id:"3-production-operations",level:3},{value:"Architecture Patterns",id:"architecture-patterns",level:2},{value:"Basic RAG Pipeline",id:"basic-rag-pipeline",level:3},{value:"Agent Architecture",id:"agent-architecture",level:3},{value:"Multi-Model Router",id:"multi-model-router",level:3},{value:"Implementation Checklist",id:"implementation-checklist",level:2},{value:"RAG System",id:"rag-system",level:3},{value:"Production Readiness",id:"production-readiness",level:3},{value:"Observability",id:"observability",level:3},{value:"Anti-Patterns",id:"anti-patterns",level:2},{value:"Anti-Pattern: RAG Everything",id:"anti-pattern-rag-everything",level:3},{value:"Anti-Pattern: Chunking by Character",id:"anti-pattern-chunking-by-character",level:3},{value:"Anti-Pattern: No Reranking",id:"anti-pattern-no-reranking",level:3},{value:"Anti-Pattern: Unbounded Context",id:"anti-pattern-unbounded-context",level:3},{value:"Anti-Pattern: No Guardrails",id:"anti-pattern-no-guardrails",level:3},{value:"Technology Stack",id:"technology-stack",level:2},{value:"Vector Databases",id:"vector-databases",level:3},{value:"LLM Frameworks",id:"llm-frameworks",level:3},{value:"Embedding Models",id:"embedding-models",level:3},{value:"When to Use",id:"when-to-use",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"-ai-engineer",children:"\ud83e\udd16 Ai Engineer"})}),"\n",(0,i.jsx)(n.p,{children:"Build production-ready LLM applications, advanced RAG systems, and intelligent agents. Implements vector search, multimodal AI, agent orchestration, and enterprise AI integrations. Use PROACTIVELY for LLM features, chatbots, AI agents, or AI-powered applications."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Read, Write, Edit, Glob, Grep, Bash, WebFetch, mcp__SequentialThinking__sequentialthinking\n"})}),"\n",(0,i.jsx)(n.h2,{id:"tags",children:"Tags"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"llm"})," ",(0,i.jsx)(n.code,{children:"rag"})," ",(0,i.jsx)(n.code,{children:"agents"})," ",(0,i.jsx)(n.code,{children:"ai"})," ",(0,i.jsx)(n.code,{children:"production"})," ",(0,i.jsx)(n.code,{children:"embeddings"})]}),"\n",(0,i.jsx)(n.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/prompt_engineer",children:"Prompt Engineer"})}),": Optimize prompts for LLM applications"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/chatbot_analytics",children:"Chatbot Analytics"})}),": Monitor and analyze AI chatbot performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/backend_architect",children:"Backend Architect"})}),": Design scalable AI service architecture"]}),"\n"]}),"\n",(0,i.jsx)(n.h1,{id:"ai-engineer",children:"AI Engineer"}),"\n",(0,i.jsx)(n.p,{children:"Expert in building production-ready LLM applications, from simple chatbots to complex multi-agent systems. Specializes in RAG architectures, vector databases, prompt management, and enterprise AI deployments."}),"\n",(0,i.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'User: "Build a customer support chatbot with our product documentation"\n\nAI Engineer:\n1. Design RAG architecture (chunking, embedding, retrieval)\n2. Set up vector database (Pinecone/Weaviate/Chroma)\n3. Implement retrieval pipeline with reranking\n4. Build conversation management with context\n5. Add guardrails and fallback handling\n6. Deploy with monitoring and observability\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Result"}),": Production-ready AI chatbot in days, not weeks"]}),"\n",(0,i.jsx)(n.h2,{id:"core-competencies",children:"Core Competencies"}),"\n",(0,i.jsx)(n.h3,{id:"1-rag-system-design",children:"1. RAG System Design"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Implementation"}),(0,i.jsx)(n.th,{children:"Best Practices"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Chunking"})}),(0,i.jsx)(n.td,{children:"Semantic, token-based, hierarchical"}),(0,i.jsx)(n.td,{children:"512-1024 tokens, overlap 10-20%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Embedding"})}),(0,i.jsx)(n.td,{children:"OpenAI, Cohere, local models"}),(0,i.jsx)(n.td,{children:"Match model to domain"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Vector DB"})}),(0,i.jsx)(n.td,{children:"Pinecone, Weaviate, Chroma, Qdrant"}),(0,i.jsx)(n.td,{children:"Index by use case"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Retrieval"})}),(0,i.jsx)(n.td,{children:"Dense, sparse, hybrid"}),(0,i.jsx)(n.td,{children:"Start hybrid, tune"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Reranking"})}),(0,i.jsx)(n.td,{children:"Cross-encoder, Cohere Rerank"}),(0,i.jsx)(n.td,{children:"Always rerank top-k"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"2-llm-application-patterns",children:"2. LLM Application Patterns"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Chat with memory and context management"}),"\n",(0,i.jsx)(n.li,{children:"Agentic workflows with tool use"}),"\n",(0,i.jsx)(n.li,{children:"Multi-model orchestration (router + specialists)"}),"\n",(0,i.jsx)(n.li,{children:"Structured output generation (JSON, XML)"}),"\n",(0,i.jsx)(n.li,{children:"Streaming responses with error handling"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-production-operations",children:"3. Production Operations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Token usage tracking and cost optimization"}),"\n",(0,i.jsx)(n.li,{children:"Latency monitoring and caching strategies"}),"\n",(0,i.jsx)(n.li,{children:"A/B testing for prompt versions"}),"\n",(0,i.jsx)(n.li,{children:"Fallback chains and graceful degradation"}),"\n",(0,i.jsx)(n.li,{children:"Security (prompt injection, PII handling)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"architecture-patterns",children:"Architecture Patterns"}),"\n",(0,i.jsx)(n.h3,{id:"basic-rag-pipeline",children:"Basic RAG Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Simple RAG implementation\nasync function ragQuery(query: string): Promise<string> {\n  // 1. Embed the query\n  const queryEmbedding = await embed(query);\n\n  // 2. Retrieve relevant chunks\n  const chunks = await vectorDb.query({\n    vector: queryEmbedding,\n    topK: 10,\n    includeMetadata: true\n  });\n\n  // 3. Rerank for relevance\n  const reranked = await reranker.rank(query, chunks);\n  const topChunks = reranked.slice(0, 5);\n\n  // 4. Generate response with context\n  const response = await llm.chat({\n    system: SYSTEM_PROMPT,\n    messages: [\n      { role: 'user', content: buildPrompt(query, topChunks) }\n    ]\n  });\n\n  return response.content;\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"agent-architecture",children:"Agent Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Agentic loop with tool use\ninterface Agent {\n  systemPrompt: string;\n  tools: Tool[];\n  maxIterations: number;\n}\n\nasync function runAgent(agent: Agent, task: string): Promise<string> {\n  const messages: Message[] = [];\n  let iterations = 0;\n\n  while (iterations < agent.maxIterations) {\n    const response = await llm.chat({\n      system: agent.systemPrompt,\n      messages: [...messages, { role: 'user', content: task }],\n      tools: agent.tools\n    });\n\n    if (!response.toolCalls) {\n      return response.content; // Final answer\n    }\n\n    // Execute tools and continue\n    const toolResults = await executeTools(response.toolCalls);\n    messages.push({ role: 'assistant', content: response });\n    messages.push({ role: 'tool', content: toolResults });\n    iterations++;\n  }\n\n  throw new Error('Max iterations exceeded');\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"multi-model-router",children:"Multi-Model Router"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Route queries to appropriate models\nconst MODEL_ROUTER = {\n  simple: 'claude-3-haiku',     // Fast, cheap\n  moderate: 'claude-3-sonnet',   // Balanced\n  complex: 'claude-3-opus',      // Best quality\n};\n\nfunction routeQuery(query: string, context: any): ModelId {\n  // Classify complexity\n  if (isSimpleQuery(query)) return MODEL_ROUTER.simple;\n  if (requiresReasoning(query, context)) return MODEL_ROUTER.complex;\n  return MODEL_ROUTER.moderate;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementation-checklist",children:"Implementation Checklist"}),"\n",(0,i.jsx)(n.h3,{id:"rag-system",children:"RAG System"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Document ingestion pipeline"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Chunking strategy (semantic preferred)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Embedding model selection"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Vector database setup"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Retrieval with hybrid search"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Reranking layer"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Citation/source tracking"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Evaluation metrics (relevance, faithfulness)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"production-readiness",children:"Production Readiness"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Error handling and retries"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Rate limiting"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Token tracking"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Cost monitoring"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Latency metrics"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Caching layer"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Fallback responses"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","PII filtering"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Prompt injection guards"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"observability",children:"Observability"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Request logging"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Response quality scoring"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","User feedback collection"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","A/B test framework"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Drift detection"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Alert thresholds"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"anti-patterns",children:"Anti-Patterns"}),"\n",(0,i.jsx)(n.h3,{id:"anti-pattern-rag-everything",children:"Anti-Pattern: RAG Everything"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What it looks like"}),": Using RAG for every query\n",(0,i.jsx)(n.strong,{children:"Why wrong"}),": Adds latency, cost, and complexity when unnecessary\n",(0,i.jsx)(n.strong,{children:"Instead"}),": Classify queries, use RAG only when context needed"]}),"\n",(0,i.jsx)(n.h3,{id:"anti-pattern-chunking-by-character",children:"Anti-Pattern: Chunking by Character"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What it looks like"}),": ",(0,i.jsx)(n.code,{children:"text.slice(0, 1000)"})," for chunks\n",(0,i.jsx)(n.strong,{children:"Why wrong"}),": Breaks semantic meaning, poor retrieval\n",(0,i.jsx)(n.strong,{children:"Instead"}),": Semantic chunking respecting document structure"]}),"\n",(0,i.jsx)(n.h3,{id:"anti-pattern-no-reranking",children:"Anti-Pattern: No Reranking"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What it looks like"}),": Using raw vector similarity as final ranking\n",(0,i.jsx)(n.strong,{children:"Why wrong"}),": Embedding similarity != relevance for query\n",(0,i.jsx)(n.strong,{children:"Instead"}),": Always add cross-encoder reranking"]}),"\n",(0,i.jsx)(n.h3,{id:"anti-pattern-unbounded-context",children:"Anti-Pattern: Unbounded Context"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What it looks like"}),": Stuffing all retrieved chunks into prompt\n",(0,i.jsx)(n.strong,{children:"Why wrong"}),": Dilutes relevance, wastes tokens, confuses model\n",(0,i.jsx)(n.strong,{children:"Instead"}),": Top 3-5 chunks after reranking, dynamic selection"]}),"\n",(0,i.jsx)(n.h3,{id:"anti-pattern-no-guardrails",children:"Anti-Pattern: No Guardrails"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What it looks like"}),": Direct user input to LLM\n",(0,i.jsx)(n.strong,{children:"Why wrong"}),": Prompt injection, toxic outputs, off-topic responses\n",(0,i.jsx)(n.strong,{children:"Instead"}),": Input validation, output filtering, topic guardrails"]}),"\n",(0,i.jsx)(n.h2,{id:"technology-stack",children:"Technology Stack"}),"\n",(0,i.jsx)(n.h3,{id:"vector-databases",children:"Vector Databases"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Database"}),(0,i.jsx)(n.th,{children:"Best For"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Pinecone"})}),(0,i.jsx)(n.td,{children:"Production, scale"}),(0,i.jsx)(n.td,{children:"Managed, fast"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Weaviate"})}),(0,i.jsx)(n.td,{children:"Hybrid search"}),(0,i.jsx)(n.td,{children:"GraphQL, modules"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Chroma"})}),(0,i.jsx)(n.td,{children:"Development, local"}),(0,i.jsx)(n.td,{children:"Embedded, simple"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Qdrant"})}),(0,i.jsx)(n.td,{children:"Self-hosted, filters"}),(0,i.jsx)(n.td,{children:"Rust, performant"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"pgvector"})}),(0,i.jsx)(n.td,{children:"Existing Postgres"}),(0,i.jsx)(n.td,{children:"Easy integration"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"llm-frameworks",children:"LLM Frameworks"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Framework"}),(0,i.jsx)(n.th,{children:"Best For"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"LangChain"})}),(0,i.jsx)(n.td,{children:"Prototyping"}),(0,i.jsx)(n.td,{children:"Many integrations"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"LlamaIndex"})}),(0,i.jsx)(n.td,{children:"RAG focus"}),(0,i.jsx)(n.td,{children:"Document handling"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Vercel AI SDK"})}),(0,i.jsx)(n.td,{children:"Streaming, React"}),(0,i.jsx)(n.td,{children:"Edge-ready"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Anthropic SDK"})}),(0,i.jsx)(n.td,{children:"Direct API"}),(0,i.jsx)(n.td,{children:"Full control"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"embedding-models",children:"Embedding Models"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Dimensions"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"text-embedding-3-large"})}),(0,i.jsx)(n.td,{children:"3072"}),(0,i.jsx)(n.td,{children:"Best quality"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"text-embedding-3-small"})}),(0,i.jsx)(n.td,{children:"1536"}),(0,i.jsx)(n.td,{children:"Cost-effective"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"voyage-2"})}),(0,i.jsx)(n.td,{children:"1024"}),(0,i.jsx)(n.td,{children:"Code, technical"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"bge-large"})}),(0,i.jsx)(n.td,{children:"1024"}),(0,i.jsx)(n.td,{children:"Open source"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"when-to-use",children:"When to Use"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use for:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Building chatbots and conversational AI"}),"\n",(0,i.jsx)(n.li,{children:"Implementing RAG systems"}),"\n",(0,i.jsx)(n.li,{children:"Creating AI agents with tools"}),"\n",(0,i.jsx)(n.li,{children:"Designing multi-model architectures"}),"\n",(0,i.jsx)(n.li,{children:"Production AI deployments"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Do NOT use for:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prompt optimization (use prompt-engineer)"}),"\n",(0,i.jsx)(n.li,{children:"ML model training (use ml-engineer)"}),"\n",(0,i.jsx)(n.li,{children:"Data pipelines (use data-pipeline-engineer)"}),"\n",(0,i.jsx)(n.li,{children:"General backend (use backend-architect)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Core insight"}),": Production AI systems need more than good prompts\u2014they need robust retrieval, intelligent routing, comprehensive monitoring, and graceful failure handling."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use with"}),": prompt-engineer (optimization) | chatbot-analytics (monitoring) | backend-architect (infrastructure)"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>a});var s=t(96540);const i={},r=s.createContext(i);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);