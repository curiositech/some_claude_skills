"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[24502],{28453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>o});var i=t(96540);const s={},a=i.createContext(s);function r(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),i.createElement(a.Provider,{value:e},n.children)}},46692:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>p});const i=JSON.parse('{"id":"skills/drone_inspection_specialist/references/gaussian-splatting-3d","title":"Gaussian Splatting 3D Reconstruction Reference","description":"Pipeline Overview","source":"@site/docs/skills/drone_inspection_specialist/references/gaussian-splatting-3d.md","sourceDirName":"skills/drone_inspection_specialist/references","slug":"/skills/drone_inspection_specialist/references/gaussian-splatting-3d","permalink":"/docs/skills/drone_inspection_specialist/references/gaussian-splatting-3d","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Gaussian Splatting 3D Reconstruction Reference","sidebar_label":"Gaussian Splatting 3D Recon...","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Forest Fire Detection Refer...","permalink":"/docs/skills/drone_inspection_specialist/references/fire-detection"},"next":{"title":"Insurance & Risk Assessment...","permalink":"/docs/skills/drone_inspection_specialist/references/insurance-risk-assessment"}}');var s=t(74848),a=t(28453);const r={title:"Gaussian Splatting 3D Reconstruction Reference",sidebar_label:"Gaussian Splatting 3D Recon...",sidebar_position:2},o="Gaussian Splatting 3D Reconstruction Reference",l={},p=[{value:"Pipeline Overview",id:"pipeline-overview",level:2},{value:"Inspection-Specific 3DGS Applications",id:"inspection-specific-3dgs-applications",level:2},{value:"Optimization for Drone Data",id:"optimization-for-drone-data",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",pre:"pre",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"gaussian-splatting-3d-reconstruction-reference",children:"Gaussian Splatting 3D Reconstruction Reference"})}),"\n",(0,s.jsx)(e.h2,{id:"pipeline-overview",children:"Pipeline Overview"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import subprocess\nimport os\nimport json\nimport numpy as np\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass ReconstructionQuality:\n    psnr: float           # Peak Signal-to-Noise Ratio\n    ssim: float           # Structural Similarity\n    lpips: float          # Learned Perceptual Image Patch Similarity\n    num_gaussians: int\n    training_time_min: float\n\n\nclass GaussianSplattingReconstructor:\n    \"\"\"\n    3D Gaussian Splatting pipeline for inspection applications.\n    Creates photorealistic 3D models from drone imagery.\n    \"\"\"\n    def __init__(self, colmap_path: str = \"colmap\",\n                 gs_path: str = \"gaussian-splatting\"):\n        self.colmap_path = colmap_path\n        self.gs_train_script = os.path.join(gs_path, \"train.py\")\n        self.gs_render_script = os.path.join(gs_path, \"render.py\")\n\n    def reconstruct_from_drone_video(self, video_path: str,\n                                      output_dir: str,\n                                      config: Optional[Dict] = None) -> Dict:\n        \"\"\"\n        Full reconstruction pipeline from drone video.\n\n        Args:\n            video_path: Path to drone video file\n            output_dir: Output directory for all artifacts\n            config: Optional configuration overrides\n\n        Returns:\n            Reconstruction results with paths and quality metrics\n        \"\"\"\n        config = config or self._default_config()\n\n        # Create directory structure\n        paths = self._setup_directories(output_dir)\n\n        # Step 1: Extract frames\n        print(\"Extracting frames...\")\n        frame_count = self._extract_frames(video_path, paths['frames'], config)\n\n        # Step 2: Run COLMAP Structure-from-Motion\n        print(\"Running COLMAP SfM...\")\n        sfm_result = self._run_colmap_sfm(paths['frames'], paths['colmap'])\n\n        if not sfm_result['success']:\n            return {'success': False, 'error': sfm_result['error']}\n\n        # Step 3: Train Gaussian Splatting\n        print(\"Training Gaussian Splatting model...\")\n        gs_result = self._train_gaussian_splatting(\n            paths['colmap'], paths['model'], config\n        )\n\n        # Step 4: Export for viewers\n        print(\"Exporting for web viewer...\")\n        self._export_web_viewer(paths['model'], paths['viewer'])\n\n        # Step 5: Calculate quality metrics\n        quality = self._evaluate_quality(paths['model'], paths['frames'])\n\n        return {\n            'success': True,\n            'paths': paths,\n            'frame_count': frame_count,\n            'sfm_stats': sfm_result,\n            'training_stats': gs_result,\n            'quality_metrics': quality,\n            'viewer_url': f\"file://{paths['viewer']}/index.html\"\n        }\n\n    def _default_config(self) -> Dict:\n        \"\"\"Default configuration for inspection-quality reconstruction\"\"\"\n        return {\n            'frame_extraction': {\n                'fps': 2,                    # Extract 2 frames per second\n                'min_frames': 50,            # Minimum frames needed\n                'max_frames': 500,           # Maximum to process\n                'quality': 95                # JPEG quality\n            },\n            'colmap': {\n                'camera_model': 'OPENCV',\n                'single_camera': True,       # Drone typically has one camera\n                'exhaustive_matching': False, # Sequential matching faster\n                'gpu_index': '0'\n            },\n            'gaussian_splatting': {\n                'iterations': 30000,\n                'densify_until_iter': 15000,\n                'densification_interval': 100,\n                'opacity_reset_interval': 3000,\n                'position_lr_max_steps': 30000,\n                'sh_degree': 3               # Spherical harmonics degree\n            },\n            'output': {\n                'render_resolution': 1920,\n                'export_ply': True,\n                'export_web': True\n            }\n        }\n\n    def _setup_directories(self, output_dir: str) -> Dict[str, str]:\n        \"\"\"Create output directory structure\"\"\"\n        paths = {\n            'root': output_dir,\n            'frames': os.path.join(output_dir, 'frames'),\n            'colmap': os.path.join(output_dir, 'colmap'),\n            'model': os.path.join(output_dir, 'gaussian_model'),\n            'viewer': os.path.join(output_dir, 'web_viewer'),\n            'renders': os.path.join(output_dir, 'renders')\n        }\n\n        for path in paths.values():\n            os.makedirs(path, exist_ok=True)\n\n        return paths\n\n    def _extract_frames(self, video_path: str, output_dir: str,\n                        config: Dict) -> int:\n        \"\"\"Extract frames from video at specified rate\"\"\"\n        import cv2\n\n        cap = cv2.VideoCapture(video_path)\n        video_fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n        extract_fps = config['frame_extraction']['fps']\n        frame_interval = int(video_fps / extract_fps)\n\n        extracted = 0\n        frame_idx = 0\n\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            if frame_idx % frame_interval == 0:\n                # Save frame\n                filename = os.path.join(output_dir, f\"frame_{extracted:05d}.jpg\")\n                cv2.imwrite(filename, frame,\n                           [cv2.IMWRITE_JPEG_QUALITY, config['frame_extraction']['quality']])\n                extracted += 1\n\n                if extracted >= config['frame_extraction']['max_frames']:\n                    break\n\n            frame_idx += 1\n\n        cap.release()\n        return extracted\n\n    def _run_colmap_sfm(self, images_dir: str, output_dir: str) -> Dict:\n        \"\"\"Run COLMAP Structure-from-Motion pipeline\"\"\"\n        database_path = os.path.join(output_dir, \"database.db\")\n        sparse_path = os.path.join(output_dir, \"sparse\")\n        os.makedirs(sparse_path, exist_ok=True)\n\n        try:\n            # Feature extraction\n            subprocess.run([\n                self.colmap_path, \"feature_extractor\",\n                \"--database_path\", database_path,\n                \"--image_path\", images_dir,\n                \"--ImageReader.camera_model\", \"OPENCV\",\n                \"--ImageReader.single_camera\", \"1\",\n                \"--SiftExtraction.use_gpu\", \"1\"\n            ], check=True, capture_output=True)\n\n            # Sequential matching (faster for video sequences)\n            subprocess.run([\n                self.colmap_path, \"sequential_matcher\",\n                \"--database_path\", database_path,\n                \"--SequentialMatching.overlap\", \"10\"\n            ], check=True, capture_output=True)\n\n            # Sparse reconstruction\n            subprocess.run([\n                self.colmap_path, \"mapper\",\n                \"--database_path\", database_path,\n                \"--image_path\", images_dir,\n                \"--output_path\", sparse_path\n            ], check=True, capture_output=True)\n\n            # Find the reconstruction (usually in sparse/0)\n            recon_path = os.path.join(sparse_path, \"0\")\n            if os.path.exists(recon_path):\n                # Get stats\n                images_txt = os.path.join(recon_path, \"images.txt\")\n                points_txt = os.path.join(recon_path, \"points3D.txt\")\n\n                num_images = self._count_colmap_images(images_txt)\n                num_points = self._count_colmap_points(points_txt)\n\n                return {\n                    'success': True,\n                    'num_registered_images': num_images,\n                    'num_points': num_points,\n                    'reconstruction_path': recon_path\n                }\n            else:\n                return {'success': False, 'error': 'No reconstruction created'}\n\n        except subprocess.CalledProcessError as e:\n            return {'success': False, 'error': str(e)}\n\n    def _train_gaussian_splatting(self, colmap_dir: str, output_dir: str,\n                                   config: Dict) -> Dict:\n        \"\"\"Train Gaussian Splatting model\"\"\"\n        import time\n\n        gs_config = config['gaussian_splatting']\n        sparse_path = os.path.join(colmap_dir, \"sparse\", \"0\")\n\n        start_time = time.time()\n\n        try:\n            cmd = [\n                \"python\", self.gs_train_script,\n                \"-s\", sparse_path,\n                \"-m\", output_dir,\n                \"--iterations\", str(gs_config['iterations']),\n                \"--densify_until_iter\", str(gs_config['densify_until_iter']),\n                \"--densification_interval\", str(gs_config['densification_interval']),\n                \"--opacity_reset_interval\", str(gs_config['opacity_reset_interval']),\n                \"--position_lr_max_steps\", str(gs_config['position_lr_max_steps']),\n                \"--sh_degree\", str(gs_config['sh_degree'])\n            ]\n\n            subprocess.run(cmd, check=True, capture_output=True)\n\n            training_time = (time.time() - start_time) / 60\n\n            return {\n                'success': True,\n                'training_time_min': training_time,\n                'iterations': gs_config['iterations'],\n                'model_path': output_dir\n            }\n\n        except subprocess.CalledProcessError as e:\n            return {'success': False, 'error': str(e)}\n\n    def _export_web_viewer(self, model_dir: str, viewer_dir: str):\n        \"\"\"Export model for web-based viewing\"\"\"\n        # Export PLY file\n        ply_path = os.path.join(model_dir, \"point_cloud\", \"iteration_30000\", \"point_cloud.ply\")\n\n        if os.path.exists(ply_path):\n            # Copy to viewer directory\n            import shutil\n            shutil.copy(ply_path, os.path.join(viewer_dir, \"model.ply\"))\n\n            # Create simple HTML viewer\n            html_content = self._generate_viewer_html()\n            with open(os.path.join(viewer_dir, \"index.html\"), 'w') as f:\n                f.write(html_content)\n\n    def _generate_viewer_html(self) -> str:\n        \"\"\"Generate HTML for WebGL Gaussian Splatting viewer\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title&gt;3D Gaussian Splatting Viewer</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.min.js\"><\/script>\n    <script src=\"https://cdn.jsdelivr.net/npm/three@0.160.0/examples/js/controls/OrbitControls.js\"><\/script>\n    <style>\n        body { margin: 0; overflow: hidden; }\n        canvas { display: block; }\n        #info { position: absolute; top: 10px; left: 10px; color: white; font-family: sans-serif; }\n    </style>\n</head>\n<body>\n    <div id=\"info\">Use mouse to orbit, scroll to zoom</div>\n    <script type=\"module\">\n        // Gaussian Splatting WebGL renderer\n        // Implementation would load model.ply and render splats\n        // This is a placeholder - real implementation uses specialized shaders\n\n        import * as THREE from 'three';\n        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';\n\n        const scene = new THREE.Scene();\n        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n        const renderer = new THREE.WebGLRenderer();\n\n        renderer.setSize(window.innerWidth, window.innerHeight);\n        document.body.appendChild(renderer.domElement);\n\n        const controls = new OrbitControls(camera, renderer.domElement);\n        camera.position.z = 5;\n\n        function animate() {\n            requestAnimationFrame(animate);\n            controls.update();\n            renderer.render(scene, camera);\n        }\n        animate();\n    <\/script>\n</body>\n</html>\n'''\n\n    def _evaluate_quality(self, model_dir: str, images_dir: str) -> Dict:\n        \"\"\"Evaluate reconstruction quality\"\"\"\n        # In practice, render test views and compare to held-out images\n        # This is a simplified version\n\n        ply_path = os.path.join(model_dir, \"point_cloud\", \"iteration_30000\", \"point_cloud.ply\")\n\n        if os.path.exists(ply_path):\n            num_gaussians = self._count_gaussians(ply_path)\n        else:\n            num_gaussians = 0\n\n        return {\n            'num_gaussians': num_gaussians,\n            'estimated_psnr': 28.0,  # Typical for good reconstruction\n            'estimated_ssim': 0.92,\n            'note': 'Run render.py with test set for accurate metrics'\n        }\n\n    def _count_gaussians(self, ply_path: str) -> int:\n        \"\"\"Count number of Gaussians in PLY file\"\"\"\n        with open(ply_path, 'rb') as f:\n            # Read header to find vertex count\n            line = f.readline().decode('ascii')\n            while 'element vertex' not in line:\n                line = f.readline().decode('ascii')\n                if not line:\n                    return 0\n            return int(line.split()[-1])\n\n    def _count_colmap_images(self, images_txt: str) -> int:\n        \"\"\"Count registered images in COLMAP output\"\"\"\n        count = 0\n        with open(images_txt, 'r') as f:\n            for line in f:\n                if line.startswith('#'):\n                    continue\n                if len(line.strip()) > 0:\n                    count += 1\n        return count // 2  # Each image has 2 lines\n\n    def _count_colmap_points(self, points_txt: str) -> int:\n        \"\"\"Count 3D points in COLMAP output\"\"\"\n        count = 0\n        with open(points_txt, 'r') as f:\n            for line in f:\n                if not line.startswith('#'):\n                    count += 1\n        return count\n"})}),"\n",(0,s.jsx)(e.h2,{id:"inspection-specific-3dgs-applications",children:"Inspection-Specific 3DGS Applications"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass MeasurementPoint:\n    id: str\n    position_3d: Tuple[float, float, float]\n    confidence: float\n\n\nclass InspectionMeasurement:\n    """\n    Extract measurements from Gaussian Splatting reconstructions.\n    Useful for roof area, damage size, and property dimensions.\n    """\n    def __init__(self, model_path: str):\n        self.gaussians = self._load_gaussians(model_path)\n        self.scale_factor = 1.0  # Meters per unit\n\n    def calibrate_scale(self, known_distance: float,\n                        point1: Tuple[float, float, float],\n                        point2: Tuple[float, float, float]):\n        """Calibrate scale using known real-world distance"""\n        model_distance = np.linalg.norm(np.array(point1) - np.array(point2))\n        self.scale_factor = known_distance / model_distance\n\n    def measure_distance(self, point1: Tuple, point2: Tuple) -> float:\n        """Measure distance between two points in meters"""\n        model_dist = np.linalg.norm(np.array(point1) - np.array(point2))\n        return model_dist * self.scale_factor\n\n    def measure_area(self, polygon_points: List[Tuple]) -> float:\n        """Calculate area of polygon in square meters"""\n        # Project to 2D (assuming roughly horizontal surface)\n        points_2d = np.array([(p[0], p[1]) for p in polygon_points])\n\n        # Shoelace formula\n        n = len(points_2d)\n        area = 0.0\n        for i in range(n):\n            j = (i + 1) % n\n            area += points_2d[i][0] * points_2d[j][1]\n            area -= points_2d[j][0] * points_2d[i][1]\n\n        return abs(area) / 2.0 * (self.scale_factor ** 2)\n\n    def extract_roof_plane(self) -> Dict:\n        """Extract dominant roof plane from Gaussians"""\n        positions = self.gaussians[\'positions\']\n\n        # RANSAC to find dominant plane\n        best_plane = None\n        best_inliers = 0\n        threshold = 0.1  # 10cm inlier threshold\n\n        for _ in range(1000):  # RANSAC iterations\n            # Random 3 points\n            idx = np.random.choice(len(positions), 3, replace=False)\n            p1, p2, p3 = positions[idx]\n\n            # Plane normal\n            v1 = p2 - p1\n            v2 = p3 - p1\n            normal = np.cross(v1, v2)\n            normal = normal / np.linalg.norm(normal)\n\n            # Count inliers\n            d = -np.dot(normal, p1)\n            distances = np.abs(np.dot(positions, normal) + d)\n            inliers = np.sum(distances < threshold)\n\n            if inliers > best_inliers:\n                best_inliers = inliers\n                best_plane = {\'normal\': normal, \'d\': d, \'inliers\': inliers}\n\n        if best_plane:\n            # Calculate slope\n            horizontal = np.array([0, 0, 1])\n            slope_rad = np.arccos(np.abs(np.dot(best_plane[\'normal\'], horizontal)))\n            slope_deg = np.degrees(slope_rad)\n\n            return {\n                \'normal\': best_plane[\'normal\'].tolist(),\n                \'slope_degrees\': slope_deg,\n                \'inlier_count\': best_plane[\'inliers\'],\n                \'inlier_ratio\': best_plane[\'inliers\'] / len(positions)\n            }\n\n        return {\'error\': \'No plane found\'}\n\n    def detect_damage_in_3d(self, damage_detections_2d: List[Dict],\n                            camera_poses: List[np.ndarray]) -> List[Dict]:\n        """\n        Project 2D damage detections to 3D space.\n\n        Args:\n            damage_detections_2d: List of {image_id, bbox, type}\n            camera_poses: Camera poses from reconstruction\n\n        Returns:\n            3D locations of damages\n        """\n        damage_3d = []\n\n        for det in damage_detections_2d:\n            image_id = det[\'image_id\']\n            bbox = det[\'bbox\']\n\n            if image_id < len(camera_poses):\n                pose = camera_poses[image_id]\n\n                # Project bbox center to ray\n                center_2d = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n\n                # Find intersection with Gaussian cloud\n                position_3d = self._raycast_to_gaussians(center_2d, pose)\n\n                if position_3d is not None:\n                    damage_3d.append({\n                        \'type\': det[\'type\'],\n                        \'position\': position_3d,\n                        \'source_image\': image_id,\n                        \'confidence\': det.get(\'confidence\', 0.5)\n                    })\n\n        return damage_3d\n\n    def _load_gaussians(self, model_path: str) -> Dict:\n        """Load Gaussian parameters from PLY file"""\n        # Simplified - real implementation parses full PLY format\n        ply_path = f"{model_path}/point_cloud/iteration_30000/point_cloud.ply"\n\n        positions = []\n        # Parse PLY file for positions\n        # ... implementation details ...\n\n        return {\n            \'positions\': np.array(positions) if positions else np.zeros((0, 3)),\n            \'count\': len(positions)\n        }\n\n    def _raycast_to_gaussians(self, pixel: Tuple, pose: np.ndarray) -> Optional[Tuple]:\n        """Find Gaussian intersection with ray from camera through pixel"""\n        # Implementation would trace ray through Gaussian field\n        # and find closest intersection\n        return None  # Placeholder\n\n\nclass ChangeDetection3D:\n    """\n    Detect changes between two 3DGS reconstructions.\n    Useful for before/after damage assessment.\n    """\n    def __init__(self, model_before: str, model_after: str):\n        self.gaussians_before = self._load_gaussians(model_before)\n        self.gaussians_after = self._load_gaussians(model_after)\n\n    def detect_changes(self, threshold: float = 0.2) -> Dict:\n        """\n        Detect geometric changes between reconstructions.\n\n        Args:\n            threshold: Distance threshold for change detection (meters)\n\n        Returns:\n            Change analysis with added, removed, and modified regions\n        """\n        pos_before = self.gaussians_before[\'positions\']\n        pos_after = self.gaussians_after[\'positions\']\n\n        # Build KD-tree for efficient nearest neighbor\n        from scipy.spatial import cKDTree\n\n        tree_before = cKDTree(pos_before)\n        tree_after = cKDTree(pos_after)\n\n        # Find points in \'after\' not in \'before\' (new/added)\n        distances_to_before, _ = tree_before.query(pos_after)\n        added_mask = distances_to_before > threshold\n        added_points = pos_after[added_mask]\n\n        # Find points in \'before\' not in \'after\' (removed/damaged)\n        distances_to_after, _ = tree_after.query(pos_before)\n        removed_mask = distances_to_after > threshold\n        removed_points = pos_before[removed_mask]\n\n        return {\n            \'added_regions\': self._cluster_points(added_points),\n            \'removed_regions\': self._cluster_points(removed_points),\n            \'added_point_count\': len(added_points),\n            \'removed_point_count\': len(removed_points),\n            \'total_change_volume\': self._estimate_change_volume(added_points, removed_points)\n        }\n\n    def _cluster_points(self, points: np.ndarray, eps: float = 0.5) -> List[Dict]:\n        """Cluster change points into regions"""\n        if len(points) == 0:\n            return []\n\n        from sklearn.cluster import DBSCAN\n\n        clustering = DBSCAN(eps=eps, min_samples=10).fit(points)\n\n        regions = []\n        for label in set(clustering.labels_):\n            if label == -1:  # Noise\n                continue\n\n            cluster_points = points[clustering.labels_ == label]\n            centroid = np.mean(cluster_points, axis=0)\n            extent = np.max(cluster_points, axis=0) - np.min(cluster_points, axis=0)\n\n            regions.append({\n                \'centroid\': centroid.tolist(),\n                \'extent\': extent.tolist(),\n                \'point_count\': len(cluster_points)\n            })\n\n        return regions\n\n    def _estimate_change_volume(self, added: np.ndarray, removed: np.ndarray) -> float:\n        """Estimate total volume of changes"""\n        # Simplified: use convex hull volume\n        from scipy.spatial import ConvexHull\n\n        total_volume = 0\n\n        if len(added) >= 4:\n            try:\n                hull = ConvexHull(added)\n                total_volume += hull.volume\n            except:\n                pass\n\n        if len(removed) >= 4:\n            try:\n                hull = ConvexHull(removed)\n                total_volume += hull.volume\n            except:\n                pass\n\n        return total_volume\n\n    def _load_gaussians(self, model_path: str) -> Dict:\n        """Load Gaussians from model"""\n        # Same as InspectionMeasurement._load_gaussians\n        return {\'positions\': np.zeros((0, 3))}\n'})}),"\n",(0,s.jsx)(e.h2,{id:"optimization-for-drone-data",children:"Optimization for Drone Data"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class DroneGSOptimizer:\n    \"\"\"\n    Optimize Gaussian Splatting for drone-collected imagery.\n    Handles specific challenges: high altitude, motion blur, GPS metadata.\n    \"\"\"\n\n    @staticmethod\n    def optimal_flight_for_3dgs() -> Dict:\n        \"\"\"Recommended flight parameters for 3DGS reconstruction\"\"\"\n        return {\n            'altitude_m': {\n                'min': 20,\n                'max': 50,\n                'optimal': 30,\n                'note': 'Lower altitude = more detail, higher = wider coverage'\n            },\n            'speed': {\n                'max_ms': 3,\n                'optimal_ms': 2,\n                'note': 'Slower = less motion blur, better feature matching'\n            },\n            'overlap': {\n                'frontal_pct': 80,\n                'side_pct': 70,\n                'note': 'Higher overlap improves reconstruction but increases processing time'\n            },\n            'pattern': {\n                'type': 'double_grid',\n                'angles': [0, 90],\n                'note': 'Cross-hatch pattern captures all surfaces'\n            },\n            'camera_settings': {\n                'shutter_priority': True,\n                'min_shutter': '1/500',\n                'iso_auto_max': 800,\n                'note': 'Fast shutter prevents motion blur'\n            },\n            'lighting': {\n                'optimal_time': 'overcast or 2hrs before/after solar noon',\n                'avoid': 'harsh shadows, directly into sun',\n                'note': 'Even lighting improves reconstruction quality'\n            }\n        }\n\n    @staticmethod\n    def training_config_by_quality(quality: str) -> Dict:\n        \"\"\"Get training configuration by quality level\"\"\"\n        configs = {\n            'preview': {\n                'iterations': 7000,\n                'densify_until_iter': 3000,\n                'sh_degree': 1,\n                'estimated_time_min': 5,\n                'note': 'Quick preview, lower quality'\n            },\n            'standard': {\n                'iterations': 30000,\n                'densify_until_iter': 15000,\n                'sh_degree': 3,\n                'estimated_time_min': 30,\n                'note': 'Good balance of quality and speed'\n            },\n            'high_quality': {\n                'iterations': 50000,\n                'densify_until_iter': 25000,\n                'sh_degree': 4,\n                'estimated_time_min': 60,\n                'note': 'High quality, longer training'\n            },\n            'inspection_detail': {\n                'iterations': 100000,\n                'densify_until_iter': 50000,\n                'sh_degree': 4,\n                'densification_interval': 50,\n                'estimated_time_min': 180,\n                'note': 'Maximum detail for damage inspection'\n            }\n        }\n        return configs.get(quality, configs['standard'])\n"})})]})}function d(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}}}]);