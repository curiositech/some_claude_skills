"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[60435],{28453:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>l});var s=r(96540);const i={},t=s.createContext(i);function c(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),s.createElement(t.Provider,{value:n},e.children)}},98532:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>c,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"skills/computer_vision_pipeline/references/tracking-algorithms","title":"Multi-Object Tracking Algorithms","description":"Comprehensive guide to tracking algorithms for maintaining object identity across video frames.","source":"@site/docs/skills/computer_vision_pipeline/references/tracking-algorithms.md","sourceDirName":"skills/computer_vision_pipeline/references","slug":"/skills/computer_vision_pipeline/references/tracking-algorithms","permalink":"/docs/skills/computer_vision_pipeline/references/tracking-algorithms","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Multi-Object Tracking Algorithms","sidebar_label":"Multi-Object Tracking Algor...","sidebar_position":1}}');var i=r(74848),t=r(28453);const c={title:"Multi-Object Tracking Algorithms",sidebar_label:"Multi-Object Tracking Algor...",sidebar_position:1},l="Multi-Object Tracking Algorithms",o={},a=[{value:"Why Tracking Matters",id:"why-tracking-matters",level:2},{value:"Algorithm Comparison",id:"algorithm-comparison",level:2},{value:"SORT (Simple Online and Realtime Tracking)",id:"sort-simple-online-and-realtime-tracking",level:2},{value:"Algorithm Overview",id:"algorithm-overview",level:3},{value:"SORT Implementation",id:"sort-implementation",level:3},{value:"DeepSORT (Deep Simple Online and Realtime Tracking)",id:"deepsort-deep-simple-online-and-realtime-tracking",level:2},{value:"Algorithm Overview",id:"algorithm-overview-1",level:3},{value:"DeepSORT Implementation",id:"deepsort-implementation",level:3},{value:"ByteTrack",id:"bytetrack",level:2},{value:"Algorithm Overview",id:"algorithm-overview-2",level:3},{value:"ByteTrack Implementation",id:"bytetrack-implementation",level:3},{value:"BotSORT",id:"botsort",level:2},{value:"Algorithm Overview",id:"algorithm-overview-3",level:3},{value:"BotSORT Implementation",id:"botsort-implementation",level:3},{value:"Performance Comparison",id:"performance-comparison",level:2},{value:"Speed Benchmarks",id:"speed-benchmarks",level:3},{value:"Accuracy Benchmarks",id:"accuracy-benchmarks",level:3},{value:"Use Case Recommendations",id:"use-case-recommendations",level:2},{value:"Wildlife Monitoring (Dolphins, Birds, etc.)",id:"wildlife-monitoring-dolphins-birds-etc",level:3},{value:"Crowded Indoor Scenes (Retail, Security)",id:"crowded-indoor-scenes-retail-security",level:3},{value:"Drone Footage (Archaeological Surveys, Inspection)",id:"drone-footage-archaeological-surveys-inspection",level:3},{value:"Sports Tracking (Soccer, Basketball)",id:"sports-tracking-soccer-basketball",level:3},{value:"Real-Time Applications (Edge Devices, Webcams)",id:"real-time-applications-edge-devices-webcams",level:3},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:2},{value:"Issue 1: Too Many ID Switches",id:"issue-1-too-many-id-switches",level:3},{value:"Issue 2: Lost Tracks During Occlusion",id:"issue-2-lost-tracks-during-occlusion",level:3},{value:"Issue 3: Tracks Not Re-identified After Long Absence",id:"issue-3-tracks-not-re-identified-after-long-absence",level:3},{value:"Issue 4: Slow Tracking Speed",id:"issue-4-slow-tracking-speed",level:3},{value:"Advanced Techniques",id:"advanced-techniques",level:2},{value:"1. Multi-Camera Tracking",id:"1-multi-camera-tracking",level:3},{value:"2. Track Smoothing",id:"2-track-smoothing",level:3},{value:"3. Track Validation",id:"3-track-validation",level:3},{value:"Resources",id:"resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"multi-object-tracking-algorithms",children:"Multi-Object Tracking Algorithms"})}),"\n",(0,i.jsx)(n.p,{children:"Comprehensive guide to tracking algorithms for maintaining object identity across video frames."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"why-tracking-matters",children:"Why Tracking Matters"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Without Tracking"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Frame 1: Detected 3 dolphins\nFrame 2: Detected 3 dolphins\nFrame 3: Detected 2 dolphins\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Question"}),": Are these the same dolphins? Which one left?"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"With Tracking"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Frame 1: Dolphin #1, #2, #3\nFrame 2: Dolphin #1, #2, #3\nFrame 3: Dolphin #1, #3 (Dolphin #2 disappeared)\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer"}),": Dolphin #2 left the scene"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"algorithm-comparison",children:"Algorithm Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Algorithm"}),(0,i.jsx)(n.th,{children:"Speed (FPS)"}),(0,i.jsx)(n.th,{children:"Robustness"}),(0,i.jsx)(n.th,{children:"Occlusion"}),(0,i.jsx)(n.th,{children:"Re-ID"}),(0,i.jsx)(n.th,{children:"Use Case"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"SORT"}),(0,i.jsx)(n.td,{children:"260"}),(0,i.jsx)(n.td,{children:"Fair"}),(0,i.jsx)(n.td,{children:"Poor"}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"Simple scenes, speed critical"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DeepSORT"}),(0,i.jsx)(n.td,{children:"40"}),(0,i.jsx)(n.td,{children:"Excellent"}),(0,i.jsx)(n.td,{children:"Good"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Crowded scenes, re-identification"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ByteTrack"}),(0,i.jsx)(n.td,{children:"150"}),(0,i.jsx)(n.td,{children:"Very Good"}),(0,i.jsx)(n.td,{children:"Excellent"}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"Balanced performance"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BotSORT"}),(0,i.jsx)(n.td,{children:"45"}),(0,i.jsx)(n.td,{children:"Excellent"}),(0,i.jsx)(n.td,{children:"Excellent"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Complex scenes, high accuracy"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Metrics"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Speed"}),": Frames per second (higher = faster)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robustness"}),": Handling ID switches"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Occlusion"}),": Tracking through overlaps"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Re-ID"}),": Re-identifying after long absence"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"sort-simple-online-and-realtime-tracking",children:"SORT (Simple Online and Realtime Tracking)"}),"\n",(0,i.jsx)(n.h3,{id:"algorithm-overview",children:"Algorithm Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Detect objects in frame (YOLO, etc.)"}),"\n",(0,i.jsx)(n.li,{children:"Associate detections with existing tracks using IoU"}),"\n",(0,i.jsx)(n.li,{children:"Update tracks with Kalman filter"}),"\n",(0,i.jsx)(n.li,{children:"Remove tracks that haven't been seen for N frames"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Strengths"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Extremely fast (260 FPS)"}),"\n",(0,i.jsx)(n.li,{children:"Simple to implement"}),"\n",(0,i.jsx)(n.li,{children:"Works well for sparse scenes"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Weaknesses"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Many ID switches in crowded scenes"}),"\n",(0,i.jsx)(n.li,{children:"Poor occlusion handling"}),"\n",(0,i.jsx)(n.li,{children:"No appearance-based matching"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"sort-implementation",children:"SORT Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from sort import Sort\n\n# Initialize tracker\ntracker = Sort(\n    max_age=30,        # Max frames to keep track without detection\n    min_hits=3,        # Min detections before track is confirmed\n    iou_threshold=0.3  # IoU threshold for matching\n)\n\n# Process video\nvideo = cv2.VideoCapture('video.mp4')\nwhile True:\n    ret, frame = video.read()\n    if not ret:\n        break\n\n    # Run detector\n    results = yolo_model(frame)\n\n    # Convert to SORT format: [x1, y1, x2, y2, confidence]\n    detections = []\n    for box in results[0].boxes:\n        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n        conf = float(box.conf[0])\n        detections.append([x1, y1, x2, y2, conf])\n\n    # Update tracker\n    tracks = tracker.update(np.array(detections))\n\n    # tracks: [x1, y1, x2, y2, track_id]\n    for track in tracks:\n        x1, y1, x2, y2, track_id = track\n        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n        cv2.putText(frame, f'ID {int(track_id)}', (int(x1), int(y1)-10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Installation"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install filterpy scikit-learn\ngit clone https://github.com/abewley/sort.git\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"deepsort-deep-simple-online-and-realtime-tracking",children:"DeepSORT (Deep Simple Online and Realtime Tracking)"}),"\n",(0,i.jsx)(n.h3,{id:"algorithm-overview-1",children:"Algorithm Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Detect objects (YOLO)"}),"\n",(0,i.jsx)(n.li,{children:"Extract appearance features (deep CNN)"}),"\n",(0,i.jsx)(n.li,{children:"Associate using IoU + appearance similarity"}),"\n",(0,i.jsx)(n.li,{children:"Update with Kalman filter"}),"\n",(0,i.jsx)(n.li,{children:"Re-identify objects after long absence"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Strengths"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Excellent robustness in crowded scenes"}),"\n",(0,i.jsx)(n.li,{children:"Re-identification after occlusion"}),"\n",(0,i.jsx)(n.li,{children:"Appearance-based matching reduces ID switches"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Weaknesses"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Slower than SORT (40 FPS vs 260 FPS)"}),"\n",(0,i.jsx)(n.li,{children:"Requires pre-trained re-identification model"}),"\n",(0,i.jsx)(n.li,{children:"Higher computational cost"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"deepsort-implementation",children:"DeepSORT Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from deep_sort_realtime.deepsort_tracker import DeepSort\n\n# Initialize tracker\ntracker = DeepSort(\n    max_age=30,              # Max frames without detection\n    n_init=3,                # Min detections before confirmed\n    max_iou_distance=0.7,    # IoU threshold\n    max_cosine_distance=0.3, # Appearance similarity threshold\n    embedder=\"mobilenet\",    # Feature extractor (mobilenet, resnet50, etc.)\n    half=True,               # Use FP16 for speed\n    bgr=True                 # Input is BGR (OpenCV default)\n)\n\n# Process video\nvideo = cv2.VideoCapture('video.mp4')\nwhile True:\n    ret, frame = video.read()\n    if not ret:\n        break\n\n    # Run detector\n    results = yolo_model(frame)\n\n    # Convert to DeepSORT format: ([x1, y1, w, h], confidence, class)\n    detections = []\n    for box in results[0].boxes:\n        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n        w, h = x2 - x1, y2 - y1\n        conf = float(box.conf[0])\n        cls = int(box.cls[0])\n\n        detections.append(([x1, y1, w, h], conf, cls))\n\n    # Update tracker\n    tracks = tracker.update_tracks(detections, frame=frame)\n\n    # Draw tracks\n    for track in tracks:\n        if not track.is_confirmed():\n            continue\n\n        track_id = track.track_id\n        ltrb = track.to_ltrb()  # [left, top, right, bottom]\n\n        cv2.rectangle(frame, (int(ltrb[0]), int(ltrb[1])),\n                      (int(ltrb[2]), int(ltrb[3])), (0, 255, 0), 2)\n        cv2.putText(frame, f'ID {track_id}', (int(ltrb[0]), int(ltrb[1])-10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Installation"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install deep-sort-realtime\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"bytetrack",children:"ByteTrack"}),"\n",(0,i.jsx)(n.h3,{id:"algorithm-overview-2",children:"Algorithm Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Detect objects with YOLO"}),"\n",(0,i.jsx)(n.li,{children:"Separate detections into high-confidence and low-confidence"}),"\n",(0,i.jsx)(n.li,{children:"Match high-confidence detections first (like SORT)"}),"\n",(0,i.jsx)(n.li,{children:"Use low-confidence detections to recover occluded objects"}),"\n",(0,i.jsx)(n.li,{children:"Update with Kalman filter"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Innovation"}),": Uses low-confidence detections that other trackers ignore"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Strengths"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Fast (150 FPS) - 3.75x faster than DeepSORT"}),"\n",(0,i.jsx)(n.li,{children:"Excellent occlusion handling"}),"\n",(0,i.jsx)(n.li,{children:"No appearance model needed (no extra GPU memory)"}),"\n",(0,i.jsx)(n.li,{children:"SOTA performance on MOT benchmarks"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Weaknesses"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"No re-identification after long absence"}),"\n",(0,i.jsx)(n.li,{children:"Requires tuning confidence thresholds"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"bytetrack-implementation",children:"ByteTrack Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from ultralytics import YOLO\n\n# YOLOv8 has ByteTrack built-in!\nmodel = YOLO('yolov8n.pt')\n\n# Track with ByteTrack\nresults = model.track(\n    'video.mp4',\n    tracker='bytetrack.yaml',  # Use ByteTrack\n    conf=0.3,                  # Detection confidence (low for ByteTrack)\n    iou=0.5,                   # IoU threshold for NMS\n    persist=True,              # Persist tracks across frames\n    verbose=False\n)\n\n# Process results\nfor result in results:\n    boxes = result.boxes\n\n    if boxes is not None and boxes.id is not None:\n        for box in boxes:\n            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n            track_id = int(box.id[0])\n            conf = float(box.conf[0])\n            cls = int(box.cls[0])\n\n            print(f'Track {track_id}: {result.names[cls]} ({conf:.2f})')\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Custom ByteTrack Config"})," (",(0,i.jsx)(n.code,{children:"bytetrack.yaml"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: bytetrack\ntrack_high_thresh: 0.5    # High confidence threshold\ntrack_low_thresh: 0.1     # Low confidence threshold (key!)\nnew_track_thresh: 0.6     # Threshold for new track\ntrack_buffer: 30          # Max frames without detection\nmatch_thresh: 0.8         # Matching threshold\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"botsort",children:"BotSORT"}),"\n",(0,i.jsx)(n.h3,{id:"algorithm-overview-3",children:"Algorithm Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"ByteTrack foundation (high + low confidence)"}),"\n",(0,i.jsx)(n.li,{children:"Add camera motion compensation"}),"\n",(0,i.jsx)(n.li,{children:"Add appearance-based re-identification"}),"\n",(0,i.jsx)(n.li,{children:"Use more sophisticated motion model"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Strengths"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Best overall accuracy (SOTA on MOT17/20)"}),"\n",(0,i.jsx)(n.li,{children:"Excellent occlusion handling (from ByteTrack)"}),"\n",(0,i.jsx)(n.li,{children:"Re-identification (from DeepSORT)"}),"\n",(0,i.jsx)(n.li,{children:"Camera motion compensation (unique)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Weaknesses"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Slower than ByteTrack (45 FPS)"}),"\n",(0,i.jsx)(n.li,{children:"More complex to tune"}),"\n",(0,i.jsx)(n.li,{children:"Requires appearance model"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"botsort-implementation",children:"BotSORT Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')\n\n# Track with BotSORT\nresults = model.track(\n    'video.mp4',\n    tracker='botsort.yaml',  # Use BotSORT\n    conf=0.3,\n    persist=True\n)\n\n# Process same as ByteTrack example above\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Custom BotSORT Config"})," (",(0,i.jsx)(n.code,{children:"botsort.yaml"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: botsort\ntrack_high_thresh: 0.5\ntrack_low_thresh: 0.1\nnew_track_thresh: 0.6\ntrack_buffer: 30\nmatch_thresh: 0.8\nproximity_thresh: 0.5     # For appearance matching\nappearance_thresh: 0.25   # Appearance similarity\ncmc_method: sparseOptFlow # Camera motion compensation (sparseOptFlow, orb, ecc)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"performance-comparison",children:"Performance Comparison"}),"\n",(0,i.jsx)(n.h3,{id:"speed-benchmarks",children:"Speed Benchmarks"}),"\n",(0,i.jsx)(n.p,{children:"Tested on 1080p video, 30 FPS, 20 objects per frame (NVIDIA RTX 3080):"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Tracker"}),(0,i.jsx)(n.th,{children:"Inference (ms)"}),(0,i.jsx)(n.th,{children:"Tracking (ms)"}),(0,i.jsx)(n.th,{children:"Total (ms)"}),(0,i.jsx)(n.th,{children:"FPS"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"SORT"}),(0,i.jsx)(n.td,{children:"28"}),(0,i.jsx)(n.td,{children:"1"}),(0,i.jsx)(n.td,{children:"29"}),(0,i.jsx)(n.td,{children:"34"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DeepSORT"}),(0,i.jsx)(n.td,{children:"28"}),(0,i.jsx)(n.td,{children:"18"}),(0,i.jsx)(n.td,{children:"46"}),(0,i.jsx)(n.td,{children:"22"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ByteTrack"}),(0,i.jsx)(n.td,{children:"28"}),(0,i.jsx)(n.td,{children:"3"}),(0,i.jsx)(n.td,{children:"31"}),(0,i.jsx)(n.td,{children:"32"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BotSORT"}),(0,i.jsx)(n.td,{children:"28"}),(0,i.jsx)(n.td,{children:"14"}),(0,i.jsx)(n.td,{children:"42"}),(0,i.jsx)(n.td,{children:"24"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Insight"}),": Tracking overhead is minimal for SORT/ByteTrack, significant for DeepSORT/BotSORT"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"accuracy-benchmarks",children:"Accuracy Benchmarks"}),"\n",(0,i.jsx)(n.p,{children:"MOT17 Dataset (Multiple Object Tracking benchmark):"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Tracker"}),(0,i.jsx)(n.th,{children:"MOTA"}),(0,i.jsx)(n.th,{children:"IDF1"}),(0,i.jsx)(n.th,{children:"ID Switches"}),(0,i.jsx)(n.th,{children:"False Positives"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"SORT"}),(0,i.jsx)(n.td,{children:"64.1%"}),(0,i.jsx)(n.td,{children:"62.2%"}),(0,i.jsx)(n.td,{children:"1,423"}),(0,i.jsx)(n.td,{children:"12,852"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DeepSORT"}),(0,i.jsx)(n.td,{children:"61.4%"}),(0,i.jsx)(n.td,{children:"62.2%"}),(0,i.jsx)(n.td,{children:"781"}),(0,i.jsx)(n.td,{children:"8,013"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ByteTrack"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"80.3%"})}),(0,i.jsx)(n.td,{children:"77.3%"}),(0,i.jsx)(n.td,{children:"2,196"}),(0,i.jsx)(n.td,{children:"8,112"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BotSORT"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"80.5%"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"80.2%"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"1,212"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"7,538"})})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Metrics"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MOTA"}),": Multi-Object Tracking Accuracy (higher = better)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IDF1"}),": ID F1 Score (higher = better, measures ID consistency)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ID Switches"}),": Number of times IDs change (lower = better)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Winner"}),": BotSORT (best overall), ByteTrack (best speed/accuracy)"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"use-case-recommendations",children:"Use Case Recommendations"}),"\n",(0,i.jsx)(n.h3,{id:"wildlife-monitoring-dolphins-birds-etc",children:"Wildlife Monitoring (Dolphins, Birds, etc.)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Choice"}),": ",(0,i.jsx)(n.strong,{children:"ByteTrack"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Animals move smoothly (Kalman filter works well)"}),"\n",(0,i.jsx)(n.li,{children:"Occlusions are common (ByteTrack excels)"}),"\n",(0,i.jsx)(n.li,{children:"No need for re-ID (animals don't leave and return)"}),"\n",(0,i.jsx)(n.li,{children:"Speed allows real-time processing"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Config"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: bytetrack\ntrack_high_thresh: 0.4    # Lower for animals (harder to detect)\ntrack_low_thresh: 0.1\ntrack_buffer: 60          # Longer buffer (animals move slower)\nmatch_thresh: 0.7         # Lower threshold (animal appearance varies)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"crowded-indoor-scenes-retail-security",children:"Crowded Indoor Scenes (Retail, Security)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Choice"}),": ",(0,i.jsx)(n.strong,{children:"BotSORT"})," or ",(0,i.jsx)(n.strong,{children:"DeepSORT"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Many occlusions (need appearance model)"}),"\n",(0,i.jsx)(n.li,{children:"People leave and return (need re-ID)"}),"\n",(0,i.jsx)(n.li,{children:"Camera is stationary (can use camera motion compensation)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Config"})," (BotSORT):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: botsort\ntrack_high_thresh: 0.5\ntrack_low_thresh: 0.1\ntrack_buffer: 30\nappearance_thresh: 0.25   # Strict appearance matching\ncmc_method: sparseOptFlow # Compensate for camera jitter\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"drone-footage-archaeological-surveys-inspection",children:"Drone Footage (Archaeological Surveys, Inspection)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Choice"}),": ",(0,i.jsx)(n.strong,{children:"ByteTrack"})," with custom config"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Camera moves (simpler motion model better)"}),"\n",(0,i.jsx)(n.li,{children:"Objects may be small/low confidence"}),"\n",(0,i.jsx)(n.li,{children:"Speed important for large footage volumes"}),"\n",(0,i.jsx)(n.li,{children:"No re-ID needed (continuous tracking)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Config"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: bytetrack\ntrack_high_thresh: 0.3    # Very low (objects are small)\ntrack_low_thresh: 0.05    # Extremely low (catch faint objects)\ntrack_buffer: 90          # Long buffer (objects move slowly relative to camera)\nmatch_thresh: 0.6         # Lenient matching (camera motion)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"sports-tracking-soccer-basketball",children:"Sports Tracking (Soccer, Basketball)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Choice"}),": ",(0,i.jsx)(n.strong,{children:"BotSORT"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Fast, erratic motion"}),"\n",(0,i.jsx)(n.li,{children:"Frequent occlusions (players overlap)"}),"\n",(0,i.jsx)(n.li,{children:"Need re-ID (players leave/enter frame)"}),"\n",(0,i.jsx)(n.li,{children:"Camera pans/zooms (camera motion compensation helps)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Config"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"tracker_type: botsort\ntrack_high_thresh: 0.5\ntrack_low_thresh: 0.1\ntrack_buffer: 20          # Short buffer (fast action)\nappearance_thresh: 0.3\ncmc_method: ecc           # Best for sports (handles zoom)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"real-time-applications-edge-devices-webcams",children:"Real-Time Applications (Edge Devices, Webcams)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Choice"}),": ",(0,i.jsx)(n.strong,{children:"SORT"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Fastest option (260 FPS)"}),"\n",(0,i.jsx)(n.li,{children:"Low memory footprint"}),"\n",(0,i.jsx)(n.li,{children:"Good enough for simple scenes"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Config"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"tracker = Sort(\n    max_age=15,       # Short buffer for real-time\n    min_hits=2,       # Quick confirmation\n    iou_threshold=0.3\n)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,i.jsx)(n.h3,{id:"issue-1-too-many-id-switches",children:"Issue 1: Too Many ID Switches"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Same object gets new ID every few frames"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Detection confidence too low"}),"\n",(0,i.jsx)(n.li,{children:"Match threshold too high"}),"\n",(0,i.jsx)(n.li,{children:"Track buffer too short"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Increase detection confidence\nconf: 0.5  # Instead of 0.3\n\n# Lower match threshold (more lenient)\nmatch_thresh: 0.6  # Instead of 0.8\n\n# Longer track buffer\ntrack_buffer: 60  # Instead of 30\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"issue-2-lost-tracks-during-occlusion",children:"Issue 2: Lost Tracks During Occlusion"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Object disappears behind another, gets new ID when reappearing"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Tracker doesn't use low-confidence detections"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use ByteTrack or BotSORT"})," (designed for occlusion)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lower track_low_thresh"}),":","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"track_low_thresh: 0.05  # Catch low-confidence detections\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Increase track_buffer"}),":","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"track_buffer: 90  # Keep track alive longer\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"issue-3-tracks-not-re-identified-after-long-absence",children:"Issue 3: Tracks Not Re-identified After Long Absence"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Object leaves frame, returns later with new ID"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": SORT/ByteTrack don't support re-identification"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Switch to ",(0,i.jsx)(n.strong,{children:"DeepSORT"})," or ",(0,i.jsx)(n.strong,{children:"BotSORT"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"issue-4-slow-tracking-speed",children:"Issue 4: Slow Tracking Speed"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Tracking overhead dominates inference time"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Using appearance model (DeepSORT/BotSORT)"}),"\n",(0,i.jsx)(n.li,{children:"Too many tracks"}),"\n",(0,i.jsx)(n.li,{children:"Too many detections"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Switch to ByteTrack or SORT"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Increase detection confidence"}),":","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"conf: 0.5  # Fewer detections = faster tracking\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use FP16 for appearance model"}),":","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"tracker = DeepSort(half=True)  # 2x faster\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"advanced-techniques",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"1-multi-camera-tracking",children:"1. Multi-Camera Tracking"}),"\n",(0,i.jsx)(n.p,{children:"Track objects across multiple camera views:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from deep_sort_realtime.deepsort_tracker import DeepSort\n\n# Shared appearance database\nglobal_tracker = DeepSort(\n    max_cosine_distance=0.2,  # Strict appearance matching\n    embedder="resnet50"       # Better features for cross-camera\n)\n\n# Camera 1\ntracks_cam1 = global_tracker.update_tracks(detections_cam1, frame_cam1)\n\n# Camera 2 (shares appearance database with cam 1)\ntracks_cam2 = global_tracker.update_tracks(detections_cam2, frame_cam2)\n\n# Match tracks by appearance\nfor t1 in tracks_cam1:\n    for t2 in tracks_cam2:\n        if appearance_similarity(t1, t2) > 0.8:\n            print(f"Same object: Cam1 ID {t1.track_id} = Cam2 ID {t2.track_id}")\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"2-track-smoothing",children:"2. Track Smoothing"}),"\n",(0,i.jsx)(n.p,{children:"Reduce jittery bounding boxes with moving average:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from collections import deque\n\nclass TrackSmoother:\n    def __init__(self, window_size=5):\n        self.tracks = {}  # track_id -> deque of boxes\n        self.window_size = window_size\n\n    def smooth(self, track_id, box):\n        """Smooth bounding box with moving average"""\n        if track_id not in self.tracks:\n            self.tracks[track_id] = deque(maxlen=self.window_size)\n\n        self.tracks[track_id].append(box)\n\n        # Average boxes\n        boxes = np.array(self.tracks[track_id])\n        smoothed = boxes.mean(axis=0)\n\n        return smoothed\n\n# Usage\nsmoother = TrackSmoother(window_size=5)\n\nfor track in tracks:\n    x1, y1, x2, y2, track_id = track\n    smoothed_box = smoother.smooth(int(track_id), [x1, y1, x2, y2])\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"3-track-validation",children:"3. Track Validation"}),"\n",(0,i.jsx)(n.p,{children:"Filter out false positive tracks:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def validate_track(track_history, min_length=10, min_movement=50):\n    """\n    Validate track is real (not false positive)\n\n    Args:\n        track_history: List of (x, y) center points\n        min_length: Minimum track length\n        min_movement: Minimum total movement (pixels)\n\n    Returns:\n        True if valid track\n    """\n    if len(track_history) < min_length:\n        return False\n\n    # Calculate total movement\n    total_movement = 0\n    for i in range(1, len(track_history)):\n        dx = track_history[i][0] - track_history[i-1][0]\n        dy = track_history[i][1] - track_history[i-1][1]\n        total_movement += np.sqrt(dx**2 + dy**2)\n\n    return total_movement >= min_movement\n\n# Usage\ntrack_histories = {}  # track_id -> list of (x, y)\n\nfor track in tracks:\n    x1, y1, x2, y2, track_id = track\n    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n\n    if track_id not in track_histories:\n        track_histories[track_id] = []\n\n    track_histories[track_id].append((center_x, center_y))\n\n    # Validate\n    if validate_track(track_histories[track_id]):\n        # Draw only valid tracks\n        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2110.06864",children:"ByteTrack Paper"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1703.07402",children:"DeepSORT Paper"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2206.14651",children:"BotSORT Paper"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/abewley/sort",children:"SORT Implementation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/levan92/deep_sort_realtime",children:"DeepSORT Implementation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.ultralytics.com/modes/track/",children:"YOLOv8 Tracking"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://motchallenge.net/",children:"MOT Challenge"})," - Tracking benchmarks"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);