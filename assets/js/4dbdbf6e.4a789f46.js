"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[33198],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(96540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},48008:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"skills/hr_network_analyst/references/algorithms","title":"Network Analysis Algorithms Reference","description":"Centrality Measures","source":"@site/docs/skills/hr_network_analyst/references/algorithms.md","sourceDirName":"skills/hr_network_analyst/references","slug":"/skills/hr_network_analyst/references/algorithms","permalink":"/docs/skills/hr_network_analyst/references/algorithms","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Network Analysis Algorithms Reference","sidebar_label":"Network Analysis Algorithms...","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Hr Network Analyst","permalink":"/docs/skills/hr_network_analyst/"},"next":{"title":"Data Sources & Implementati...","permalink":"/docs/skills/hr_network_analyst/references/data-sources-implementation"}}');var r=t(74848),s=t(28453);const o={title:"Network Analysis Algorithms Reference",sidebar_label:"Network Analysis Algorithms...",sidebar_position:1},a="Network Analysis Algorithms Reference",l={},c=[{value:"Centrality Measures",id:"centrality-measures",level:2},{value:"Betweenness Centrality",id:"betweenness-centrality",level:3},{value:"Degree Centrality",id:"degree-centrality",level:3},{value:"Eigenvector Centrality",id:"eigenvector-centrality",level:3},{value:"PageRank",id:"pagerank",level:3},{value:"Closeness Centrality",id:"closeness-centrality",level:3},{value:"Structural Holes (Burt)",id:"structural-holes-burt",level:2},{value:"Constraint",id:"constraint",level:3},{value:"Effective Size",id:"effective-size",level:3},{value:"Community Detection",id:"community-detection",level:2},{value:"Louvain Algorithm",id:"louvain-algorithm",level:3},{value:"Label Propagation",id:"label-propagation",level:3},{value:"Modularity Score",id:"modularity-score",level:3},{value:"Network Statistics",id:"network-statistics",level:2},{value:"Basic Properties",id:"basic-properties",level:3},{value:"K-Core Decomposition",id:"k-core-decomposition",level:3},{value:"Useful Patterns",id:"useful-patterns",level:2},{value:"Multi-Layer Network Fusion",id:"multi-layer-network-fusion",level:3},{value:"Temporal Decay Weighting",id:"temporal-decay-weighting",level:3},{value:"Gladwell Classification",id:"gladwell-classification",level:3},{value:"Data Source APIs",id:"data-source-apis",level:2},{value:"Semantic Scholar",id:"semantic-scholar",level:3},{value:"GitHub",id:"github",level:3},{value:"Visualization",id:"visualization",level:2},{value:"Interactive HTML Network",id:"interactive-html-network",level:3},{value:"Static Matplotlib",id:"static-matplotlib",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"network-analysis-algorithms-reference",children:"Network Analysis Algorithms Reference"})}),"\n",(0,r.jsx)(n.h2,{id:"centrality-measures",children:"Centrality Measures"}),"\n",(0,r.jsx)(n.h3,{id:"betweenness-centrality",children:"Betweenness Centrality"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CB(v) = \u03a3 \u03c3st(v) / \u03c3st\n       s\u2260v\u2260t\n"})}),"\n",(0,r.jsx)(n.p,{children:"Where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u03c3st = total number of shortest paths from node s to node t"}),"\n",(0,r.jsx)(n.li,{children:"\u03c3st(v) = number of those paths passing through v"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": Measures how often a node acts as a bridge along shortest paths."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import networkx as nx\n\n# Basic betweenness\nbc = nx.betweenness_centrality(G)\n\n# Weighted (edges with 'weight' attribute)\nbc_weighted = nx.betweenness_centrality(G, weight='weight')\n\n# Normalized (default) vs unnormalized\nbc_unnorm = nx.betweenness_centrality(G, normalized=False)\n\n# Approximate (faster for large graphs)\nbc_approx = nx.betweenness_centrality(G, k=100)  # sample k nodes\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Complexity"}),": O(VE) for unweighted, O(VE + V\xb2 log V) for weighted"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"degree-centrality",children:"Degree Centrality"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CD(v) = deg(v) / (n-1)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": Simple count of connections, normalized."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Undirected\ndc = nx.degree_centrality(G)\n\n# Directed\nin_dc = nx.in_degree_centrality(G)\nout_dc = nx.out_degree_centrality(G)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"eigenvector-centrality",children:"Eigenvector Centrality"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"xi = (1/\u03bb) \u03a3 Aij xj\n           j\n"})}),"\n",(0,r.jsx)(n.p,{children:"Where A is the adjacency matrix and \u03bb is the largest eigenvalue."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": A node is important if connected to other important nodes (recursive)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"ec = nx.eigenvector_centrality(G)\n\n# With weights\nec_weighted = nx.eigenvector_centrality(G, weight='weight')\n\n# NumPy version (faster)\nec_numpy = nx.eigenvector_centrality_numpy(G)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"pagerank",children:"PageRank"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"PR(v) = (1-d)/N + d \u03a3 PR(u)/L(u)\n                   u\u2208Bin(v)\n"})}),"\n",(0,r.jsx)(n.p,{children:"Where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"d = damping factor (typically 0.85)"}),"\n",(0,r.jsx)(n.li,{children:"N = total nodes"}),"\n",(0,r.jsx)(n.li,{children:"Bin(v) = nodes linking to v"}),"\n",(0,r.jsx)(n.li,{children:"L(u) = outgoing links from u"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": Probability of random walker landing on node."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"pr = nx.pagerank(G)\n\n# Custom damping\npr = nx.pagerank(G, alpha=0.9)\n\n# With weights\npr = nx.pagerank(G, weight='weight')\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"closeness-centrality",children:"Closeness Centrality"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CC(v) = (n-1) / \u03a3 d(v,u)\n               u\u2260v\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": Inverse of average distance to all other nodes."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"cc = nx.closeness_centrality(G)\n\n# For disconnected graphs\ncc = nx.closeness_centrality(G, wf_improved=True)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"structural-holes-burt",children:"Structural Holes (Burt)"}),"\n",(0,r.jsx)(n.h3,{id:"constraint",children:"Constraint"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Ci = \u03a3 cij\xb2\n     j\n\ncij = (pij + \u03a3 piq \xd7 pqj)\xb2\n           q\n"})}),"\n",(0,r.jsx)(n.p,{children:"Where pij = proportion of i's network invested in j."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": How constrained is a node by its network? Low constraint = spanning structural holes."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"constraint = nx.constraint(G)\n\n# With weights\nconstraint_w = nx.constraint(G, weight='weight')\n\n# For specific nodes\nconstraint_node = nx.constraint(G, nodes=['Alice', 'Bob'])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"effective-size",children:"Effective Size"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Definition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"ES(i) = \u03a3 [1 - \u03a3 piq \xd7 mjq]\n        j    q\u2260j\n\nmjq = pjq / max(pkq for all k)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": Redundancy-adjusted network size."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NetworkX Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"eff_size = nx.effective_size(G)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"community-detection",children:"Community Detection"}),"\n",(0,r.jsx)(n.h3,{id:"louvain-algorithm",children:"Louvain Algorithm"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Implementation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from networkx.algorithms.community import louvain_communities\n\ncommunities = louvain_communities(G)\n\n# With resolution parameter\ncommunities = louvain_communities(G, resolution=1.5)\n\n# Get partition as dict\npartition = {}\nfor i, comm in enumerate(communities):\n    for node in comm:\n        partition[node] = i\n"})}),"\n",(0,r.jsx)(n.h3,{id:"label-propagation",children:"Label Propagation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from networkx.algorithms.community import label_propagation_communities\n\ncommunities = label_propagation_communities(G)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"modularity-score",children:"Modularity Score"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from networkx.algorithms.community import modularity\n\nQ = modularity(G, communities)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"network-statistics",children:"Network Statistics"}),"\n",(0,r.jsx)(n.h3,{id:"basic-properties",children:"Basic Properties"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Number of nodes and edges\nn = G.number_of_nodes()\nm = G.number_of_edges()\n\n# Density\ndensity = nx.density(G)\n\n# Average clustering coefficient\navg_clustering = nx.average_clustering(G)\n\n# Transitivity (global clustering)\ntransitivity = nx.transitivity(G)\n\n# Average shortest path (for connected graphs)\nif nx.is_connected(G):\n    avg_path = nx.average_shortest_path_length(G)\n\n# Diameter\nif nx.is_connected(G):\n    diameter = nx.diameter(G)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"k-core-decomposition",children:"K-Core Decomposition"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Find k-core (subgraph where all nodes have degree >= k)\nk_core = nx.k_core(G, k=5)\n\n# Core number of each node\ncore_numbers = nx.core_number(G)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"useful-patterns",children:"Useful Patterns"}),"\n",(0,r.jsx)(n.h3,{id:"multi-layer-network-fusion",children:"Multi-Layer Network Fusion"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def fuse_networks(networks, weights):\n    \"\"\"\n    Combine multiple network sources with weights.\n\n    Args:\n        networks: dict of {source_name: networkx.Graph}\n        weights: dict of {source_name: float}\n\n    Returns:\n        Fused network with combined edge weights\n    \"\"\"\n    G_fused = nx.Graph()\n\n    for source, G_source in networks.items():\n        w = weights.get(source, 1.0)\n\n        for u, v, data in G_source.edges(data=True):\n            edge_weight = data.get('weight', 1.0) * w\n\n            if G_fused.has_edge(u, v):\n                G_fused[u][v]['weight'] += edge_weight\n                G_fused[u][v]['sources'].append(source)\n            else:\n                G_fused.add_edge(u, v, weight=edge_weight, sources=[source])\n\n    return G_fused\n"})}),"\n",(0,r.jsx)(n.h3,{id:"temporal-decay-weighting",children:"Temporal Decay Weighting"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from datetime import datetime\nimport math\n\ndef apply_temporal_decay(G, date_attr='date', half_life_days=365):\n    \"\"\"\n    Apply exponential decay to edge weights based on recency.\n    \"\"\"\n    now = datetime.now()\n\n    for u, v, data in G.edges(data=True):\n        if date_attr in data:\n            edge_date = data[date_attr]\n            days_old = (now - edge_date).days\n            decay = math.exp(-math.log(2) * days_old / half_life_days)\n            data['weight'] = data.get('weight', 1.0) * decay\n\n    return G\n"})}),"\n",(0,r.jsx)(n.h3,{id:"gladwell-classification",children:"Gladwell Classification"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def classify_gladwell(G, metrics=None):\n    \"\"\"\n    Classify nodes into Gladwell archetypes.\n\n    Returns dict mapping node -> archetype\n    \"\"\"\n    if metrics is None:\n        metrics = {\n            'betweenness': nx.betweenness_centrality(G),\n            'degree': nx.degree_centrality(G),\n            'eigenvector': nx.eigenvector_centrality(G),\n        }\n        try:\n            metrics['constraint'] = nx.constraint(G)\n        except:\n            metrics['constraint'] = {n: 0.5 for n in G.nodes()}\n\n    classifications = {}\n\n    # Compute thresholds (top percentile)\n    bc_threshold = sorted(metrics['betweenness'].values())[-int(len(G)*0.1)]\n    dc_threshold = sorted(metrics['degree'].values())[-int(len(G)*0.1)]\n    ec_threshold = sorted(metrics['eigenvector'].values())[-int(len(G)*0.1)]\n\n    for node in G.nodes():\n        bc = metrics['betweenness'][node]\n        dc = metrics['degree'][node]\n        ec = metrics['eigenvector'][node]\n        constraint = metrics['constraint'].get(node, 0.5)\n\n        if bc >= bc_threshold and dc >= dc_threshold:\n            classifications[node] = 'connector'\n        elif ec >= ec_threshold and dc < dc_threshold:\n            classifications[node] = 'maven'\n        elif dc >= dc_threshold and constraint < 0.3:\n            classifications[node] = 'salesman'\n        else:\n            classifications[node] = 'standard'\n\n    return classifications\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"data-source-apis",children:"Data Source APIs"}),"\n",(0,r.jsx)(n.h3,{id:"semantic-scholar",children:"Semantic Scholar"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import requests\n\ndef get_author_collaborators(author_id):\n    \"\"\"Get co-authors from Semantic Scholar.\"\"\"\n    url = f\"https://api.semanticscholar.org/graph/v1/author/{author_id}\"\n    params = {\n        'fields': 'papers.authors'\n    }\n    resp = requests.get(url, params=params)\n    data = resp.json()\n\n    coauthors = set()\n    for paper in data.get('papers', []):\n        for author in paper.get('authors', []):\n            if author['authorId'] != author_id:\n                coauthors.add((author['authorId'], author['name']))\n\n    return coauthors\n"})}),"\n",(0,r.jsx)(n.h3,{id:"github",children:"GitHub"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import requests\n\ndef get_repo_contributors(owner, repo, token=None):\n    """Get contributors to a GitHub repo."""\n    headers = {}\n    if token:\n        headers[\'Authorization\'] = f\'token {token}\'\n\n    url = f"https://api.github.com/repos/{owner}/{repo}/contributors"\n    resp = requests.get(url, headers=headers)\n\n    return [(c[\'login\'], c[\'contributions\']) for c in resp.json()]\n\n\ndef build_github_network(repos, token=None):\n    """Build collaboration network from list of repos."""\n    G = nx.Graph()\n\n    for owner, repo in repos:\n        contributors = get_repo_contributors(owner, repo, token)\n\n        # Add edges between all contributors to same repo\n        for i, (user1, contrib1) in enumerate(contributors):\n            for user2, contrib2 in contributors[i+1:]:\n                if G.has_edge(user1, user2):\n                    G[user1][user2][\'weight\'] += 1\n                    G[user1][user2][\'repos\'].append(f"{owner}/{repo}")\n                else:\n                    G.add_edge(user1, user2, weight=1, repos=[f"{owner}/{repo}"])\n\n    return G\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"visualization",children:"Visualization"}),"\n",(0,r.jsx)(n.h3,{id:"interactive-html-network",children:"Interactive HTML Network"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from pyvis.network import Network\n\ndef visualize_network(G, metrics, output='network.html'):\n    \"\"\"Create interactive HTML visualization.\"\"\"\n    net = Network(height='800px', width='100%', bgcolor='#1a1a2e')\n\n    # Color map for Gladwell types\n    colors = {\n        'connector': '#e94560',\n        'maven': '#0f3460',\n        'salesman': '#16c79a',\n        'standard': '#666666'\n    }\n\n    classifications = classify_gladwell(G, metrics)\n\n    for node in G.nodes():\n        bc = metrics['betweenness'][node]\n        size = 10 + 100 * bc\n        color = colors[classifications[node]]\n        title = f\"{node}<br>Type: {classifications[node]}<br>BC: {bc:.4f}\"\n\n        net.add_node(node, size=size, color=color, title=title)\n\n    for u, v, data in G.edges(data=True):\n        weight = data.get('weight', 1)\n        net.add_edge(u, v, value=weight)\n\n    net.show_buttons(filter_=['physics'])\n    net.save_graph(output)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"static-matplotlib",children:"Static Matplotlib"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import matplotlib.pyplot as plt\n\ndef plot_network_static(G, metrics, figsize=(12, 12)):\n    \"\"\"Create static network visualization.\"\"\"\n    fig, ax = plt.subplots(figsize=figsize)\n\n    # Layout\n    pos = nx.spring_layout(G, k=2, iterations=50)\n\n    # Node sizes by betweenness\n    node_sizes = [1000 * metrics['betweenness'][n] + 50 for n in G.nodes()]\n\n    # Node colors by eigenvector centrality\n    node_colors = [metrics['eigenvector'][n] for n in G.nodes()]\n\n    nx.draw_networkx(\n        G, pos, ax=ax,\n        node_size=node_sizes,\n        node_color=node_colors,\n        cmap=plt.cm.viridis,\n        with_labels=True,\n        font_size=8,\n        alpha=0.8\n    )\n\n    plt.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.viridis),\n                 label='Eigenvector Centrality', ax=ax)\n\n    plt.tight_layout()\n    return fig\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);