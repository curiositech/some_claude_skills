"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[54356],{327:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"skills/vr_avatar_engineer/index","title":"\ud83e\udd16 Vr Avatar Engineer","description":"Expert in photorealistic and stylized VR avatar systems for Apple Vision Pro, Meta Quest, and cross-platform metaverse. Specializes in facial tracking (52+ blend shapes), subsurface scattering, Persona-style generation, Photon networking, and real-time LOD. Activate on \'VR avatar\', \'Vision Pro Persona\', \'Meta avatar\', \'facial tracking\', \'blend shapes\', \'avatar networking\', \'photorealistic avatar\'. NOT for 2D profile pictures (use image generation), non-VR game characters (use game engine tools), static 3D models (use modeling tools), or motion capture hardware setup.","source":"@site/docs/skills/vr_avatar_engineer/index.md","sourceDirName":"skills/vr_avatar_engineer","slug":"/skills/vr_avatar_engineer/","permalink":"/docs/skills/vr_avatar_engineer/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Vr Avatar Engineer","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"PBR Shader Implementation","permalink":"/docs/skills/metal_shader_expert/references/pbr-shaders"},"next":{"title":"Physics Rendering Expert","permalink":"/docs/skills/physics_rendering_expert/"}}');var t=r(74848),s=r(28453);const a={sidebar_label:"Vr Avatar Engineer",sidebar_position:1},l="\ud83e\udd16 Vr Avatar Engineer",o={},d=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"When to Use This Skill",id:"when-to-use-this-skill",level:2},{value:"MCP Integrations",id:"mcp-integrations",level:2},{value:"Expert vs Novice Shibboleths",id:"expert-vs-novice-shibboleths",level:2},{value:"Common Anti-Patterns",id:"common-anti-patterns",level:2},{value:"Anti-Pattern: Uncanny Valley Through Over-Realism",id:"anti-pattern-uncanny-valley-through-over-realism",level:3},{value:"Anti-Pattern: Ignoring Platform Differences",id:"anti-pattern-ignoring-platform-differences",level:3},{value:"Anti-Pattern: Synchronous Networking",id:"anti-pattern-synchronous-networking",level:3},{value:"Anti-Pattern: Single Skin Shader",id:"anti-pattern-single-skin-shader",level:3},{value:"Evolution Timeline",id:"evolution-timeline",level:2},{value:"Pre-2020: Early VR Avatars",id:"pre-2020-early-vr-avatars",level:3},{value:"2020-2022: Quest 2 Era",id:"2020-2022-quest-2-era",level:3},{value:"2023-2024: Spatial Computing",id:"2023-2024-spatial-computing",level:3},{value:"2025+: Current Best Practices",id:"2025-current-best-practices",level:3},{value:"Core Implementation Patterns",id:"core-implementation-patterns",level:2},{value:"Facial Tracking (ARKit \u2192 Avatar)",id:"facial-tracking-arkit--avatar",level:3},{value:"Network-Optimized Avatar State",id:"network-optimized-avatar-state",level:3},{value:"Subsurface Scattering for Skin",id:"subsurface-scattering-for-skin",level:3},{value:"Performance Targets",id:"performance-targets",level:2},{value:"Integrates With",id:"integrates-with",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-vr-avatar-engineer",children:"\ud83e\udd16 Vr Avatar Engineer"})}),"\n",(0,t.jsx)(n.p,{children:"Expert in photorealistic and stylized VR avatar systems for Apple Vision Pro, Meta Quest, and cross-platform metaverse. Specializes in facial tracking (52+ blend shapes), subsurface scattering, Persona-style generation, Photon networking, and real-time LOD. Activate on 'VR avatar', 'Vision Pro Persona', 'Meta avatar', 'facial tracking', 'blend shapes', 'avatar networking', 'photorealistic avatar'. NOT for 2D profile pictures (use image generation), non-VR game characters (use game engine tools), static 3D models (use modeling tools), or motion capture hardware setup."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Read, Write, Edit, Bash, mcp__firecrawl__firecrawl_search, WebFetch, mcp__stability-ai__stability-ai-generate-image\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tags",children:"Tags"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"vr"})," ",(0,t.jsx)(n.code,{children:"avatar"})," ",(0,t.jsx)(n.code,{children:"facial-tracking"})," ",(0,t.jsx)(n.code,{children:"vision-pro"})," ",(0,t.jsx)(n.code,{children:"metaverse"})]}),"\n",(0,t.jsx)(n.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/skills/metal_shader_expert",children:"Metal Shader Expert"})}),": GPU-accelerated avatar rendering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/skills/physics_rendering_expert",children:"Physics Rendering Expert"})}),": Avatar physics simulation"]}),"\n"]}),"\n",(0,t.jsx)(n.h1,{id:"vr-avatar-excellence-engineer",children:"VR Avatar Excellence Engineer"}),"\n",(0,t.jsx)(n.p,{children:"Expert in building high-quality avatar systems for VR/metaverse. Deep knowledge of real-time rendering, facial tracking, and cross-platform development for Vision Pro, Quest, and PC VR."}),"\n",(0,t.jsx)(n.h2,{id:"when-to-use-this-skill",children:"When to Use This Skill"}),"\n",(0,t.jsxs)(n.p,{children:["\u2705 ",(0,t.jsx)(n.strong,{children:"Use for:"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"VR avatar systems (Vision Pro, Quest, PCVR)"}),"\n",(0,t.jsx)(n.li,{children:"Facial tracking integration (ARKit 52 blend shapes, Meta face tracking)"}),"\n",(0,t.jsx)(n.li,{children:"Avatar generation from photos/scans"}),"\n",(0,t.jsx)(n.li,{children:"Real-time networking for multiplayer avatars"}),"\n",(0,t.jsx)(n.li,{children:"Subsurface scattering and skin rendering"}),"\n",(0,t.jsx)(n.li,{children:"Performance optimization for VR frame rates"}),"\n",(0,t.jsx)(n.li,{children:"Cross-platform avatar synchronization"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["\u274c ",(0,t.jsx)(n.strong,{children:"Do NOT use for:"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"2D profile pictures \u2192 use image generation tools"}),"\n",(0,t.jsx)(n.li,{children:"Non-VR game characters \u2192 use game engine character tools"}),"\n",(0,t.jsx)(n.li,{children:"Static 3D modeling \u2192 use Blender/Maya skills"}),"\n",(0,t.jsx)(n.li,{children:"Motion capture hardware setup \u2192 specialized mocap domain"}),"\n",(0,t.jsx)(n.li,{children:"Deepfakes/non-consensual likenesses \u2192 ethical boundary"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"mcp-integrations",children:"MCP Integrations"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"MCP"}),(0,t.jsx)(n.th,{children:"Purpose"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Stability AI"})}),(0,t.jsx)(n.td,{children:"Generate avatar concept art, texture references"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Firecrawl"})}),(0,t.jsx)(n.td,{children:"Research Meta/Apple SDKs, avatar papers"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"WebFetch"})}),(0,t.jsx)(n.td,{children:"Fetch ARKit, Meta SDK documentation"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"expert-vs-novice-shibboleths",children:"Expert vs Novice Shibboleths"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Topic"}),(0,t.jsx)(n.th,{children:"Novice"}),(0,t.jsx)(n.th,{children:"Expert"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Blend shapes"})}),(0,t.jsx)(n.td,{children:'"Just use morph targets"'}),(0,t.jsx)(n.td,{children:"Knows ARKit has 52 specific shapes; Meta has different set; mapping required"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Skin rendering"})}),(0,t.jsx)(n.td,{children:'"Just use PBR"'}),(0,t.jsx)(n.td,{children:"SSS is essential; different models for different skin tones"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Eye tracking"})}),(0,t.jsx)(n.td,{children:'"Point eyes at target"'}),(0,t.jsx)(n.td,{children:"Saccades, microsaccades, blink patterns make presence"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Networking"})}),(0,t.jsx)(n.td,{children:'"Send all data every frame"'}),(0,t.jsx)(n.td,{children:"Delta compression, interpolation, dead reckoning"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Frame rate"})}),(0,t.jsx)(n.td,{children:'"60fps is fine"'}),(0,t.jsx)(n.td,{children:"Quest: 72/90/120hz modes; Vision Pro: 90hz minimum; dropped frames = nausea"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"LOD"})}),(0,t.jsx)(n.td,{children:'"Lower poly for distance"'}),(0,t.jsx)(n.td,{children:"Foveated rendering integration, dynamic LOD based on gaze"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"common-anti-patterns",children:"Common Anti-Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"anti-pattern-uncanny-valley-through-over-realism",children:"Anti-Pattern: Uncanny Valley Through Over-Realism"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What it looks like"}),": Photorealistic face with robotic expressions\n",(0,t.jsx)(n.strong,{children:"Why it's wrong"}),": Partial realism triggers uncanny valley; stylization often works better\n",(0,t.jsx)(n.strong,{children:"What to do instead"}),": Match rendering fidelity to tracking fidelity; stylized avatars hide tracking limitations\n",(0,t.jsx)(n.strong,{children:"Example"}),": Vision Pro Personas work because they're slightly stylized, not photorealistic"]}),"\n",(0,t.jsx)(n.h3,{id:"anti-pattern-ignoring-platform-differences",children:"Anti-Pattern: Ignoring Platform Differences"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What it looks like"}),": Same avatar pipeline for Quest and Vision Pro\n",(0,t.jsx)(n.strong,{children:"Why it's wrong"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Quest: Mobile GPU, 72fps minimum, limited polys"}),"\n",(0,t.jsxs)(n.li,{children:["Vision Pro: Desktop-class GPU, 90fps, Personas API is different\n",(0,t.jsx)(n.strong,{children:"What to do instead"}),": Platform-specific LOD targets, shader variants, API abstractions"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"anti-pattern-synchronous-networking",children:"Anti-Pattern: Synchronous Networking"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What it looks like"}),": Blocking on avatar state updates\n",(0,t.jsx)(n.strong,{children:"Why it's wrong"}),": Network latency causes frame drops = VR sickness\n",(0,t.jsx)(n.strong,{children:"What to do instead"}),": Asynchronous updates with interpolation and prediction"]}),"\n",(0,t.jsx)(n.h3,{id:"anti-pattern-single-skin-shader",children:"Anti-Pattern: Single Skin Shader"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What it looks like"}),": One SSS configuration for all skin tones\n",(0,t.jsx)(n.strong,{children:"Why it's wrong"}),": Melanin affects scattering; darker skin needs different SSS parameters\n",(0,t.jsx)(n.strong,{children:"What to do instead"}),": Parameterized skin shader with melanin-aware scattering"]}),"\n",(0,t.jsx)(n.h2,{id:"evolution-timeline",children:"Evolution Timeline"}),"\n",(0,t.jsx)(n.h3,{id:"pre-2020-early-vr-avatars",children:"Pre-2020: Early VR Avatars"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Stylized/cartoon avatars dominant (VRChat, Rec Room)"}),"\n",(0,t.jsx)(n.li,{children:"Limited tracking (3-point: HMD + controllers)"}),"\n",(0,t.jsx)(n.li,{children:"No facial expressions in most apps"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2020-2022-quest-2-era",children:"2020-2022: Quest 2 Era"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Hand tracking mainstream"}),"\n",(0,t.jsx)(n.li,{children:"Basic lip sync from audio"}),"\n",(0,t.jsx)(n.li,{children:"Meta Avatars SDK emerges"}),"\n",(0,t.jsx)(n.li,{children:"72fps becomes standard"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2023-2024-spatial-computing",children:"2023-2024: Spatial Computing"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Vision Pro Personas"})," (Feb 2024): ML-generated photorealistic avatars"]}),"\n",(0,t.jsx)(n.li,{children:"Quest 3 with improved face/eye tracking (add-on)"}),"\n",(0,t.jsx)(n.li,{children:"Codec Avatars research (Meta) shows photorealistic path"}),"\n",(0,t.jsx)(n.li,{children:"Cross-platform interop becomes critical"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2025-current-best-practices",children:"2025+: Current Best Practices"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Hybrid approach: Personas for presence, stylized for games"}),"\n",(0,t.jsx)(n.li,{children:"Neural rendering for hair/fabric"}),"\n",(0,t.jsx)(n.li,{children:"Real-time relighting from environment"}),"\n",(0,t.jsx)(n.li,{children:"Privacy-preserving avatar generation (on-device)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"core-implementation-patterns",children:"Core Implementation Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"facial-tracking-arkit--avatar",children:"Facial Tracking (ARKit \u2192 Avatar)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-swift",children:'// ARKit face tracking to blend shape weights\nfunc mapARKitToAvatar(faceAnchor: ARFaceAnchor) -> [String: Float] {\n    let arkit = faceAnchor.blendShapes\n\n    // Direct mappings (ARKit names \u2192 avatar shapes)\n    var weights: [String: Float] = [:]\n    weights["jawOpen"] = arkit[.jawOpen]?.floatValue ?? 0\n    weights["mouthSmileLeft"] = arkit[.mouthSmileLeft]?.floatValue ?? 0\n    weights["mouthSmileRight"] = arkit[.mouthSmileRight]?.floatValue ?? 0\n    weights["eyeBlinkLeft"] = arkit[.eyeBlinkLeft]?.floatValue ?? 0\n    weights["eyeBlinkRight"] = arkit[.eyeBlinkRight]?.floatValue ?? 0\n\n    // Derived expressions (combinations)\n    let smile = ((weights["mouthSmileLeft"] ?? 0) + (weights["mouthSmileRight"] ?? 0)) / 2\n    weights["expression_happy"] = smile\n\n    return weights\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"network-optimized-avatar-state",children:"Network-Optimized Avatar State"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Photon PUN2 - efficient avatar sync\npublic struct AvatarState : INetworkStruct {\n    // Pack position: 3 floats \u2192 6 bytes (half precision)\n    public Half3 Position;\n\n    // Pack rotation: quaternion \u2192 4 bytes (compressed)\n    public CompressedQuaternion Rotation;\n\n    // Blend shapes: 52 weights \u2192 52 bytes (uint8 each, 0-255 \u2192 0-1)\n    public fixed byte BlendShapes[52];\n\n    // Eye gaze: 2 directions \u2192 4 bytes\n    public Half2 LeftEyeGaze;\n    public Half2 RightEyeGaze;\n\n    // Total: ~70 bytes per update (vs 400+ uncompressed)\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"subsurface-scattering-for-skin",children:"Subsurface Scattering for Skin"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-hlsl",children:"// Simplified SSS for real-time (pre-integrated)\nfloat3 SubsurfaceScattering(float3 normal, float3 light, float3 view,\n                            float curvature, float3 skinColor, float melanin) {\n    float NdotL = dot(normal, light);\n\n    // Wrap lighting for soft terminator\n    float wrap = 0.5;\n    float diffuse = saturate((NdotL + wrap) / (1 + wrap));\n\n    // Pre-integrated scattering lookup (curvature-based)\n    float2 sssUV = float2(NdotL * 0.5 + 0.5, curvature);\n    float3 sss = tex2D(_SSSLookup, sssUV).rgb;\n\n    // Melanin affects scattering color\n    float3 scatterColor = lerp(float3(1, 0.4, 0.25), float3(0.8, 0.5, 0.4), melanin);\n\n    return skinColor * diffuse + sss * scatterColor * (1 - diffuse);\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Platform"}),(0,t.jsx)(n.th,{children:"Frame Rate"}),(0,t.jsx)(n.th,{children:"Avatar Poly Budget"}),(0,t.jsx)(n.th,{children:"Texture Budget"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Quest 2"}),(0,t.jsx)(n.td,{children:"72-90 fps"}),(0,t.jsx)(n.td,{children:"10-15k tris"}),(0,t.jsx)(n.td,{children:"512\xd7512"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Quest 3"}),(0,t.jsx)(n.td,{children:"90-120 fps"}),(0,t.jsx)(n.td,{children:"20-30k tris"}),(0,t.jsx)(n.td,{children:"1024\xd71024"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Vision Pro"}),(0,t.jsx)(n.td,{children:"90 fps"}),(0,t.jsx)(n.td,{children:"50-100k tris"}),(0,t.jsx)(n.td,{children:"2048\xd72048"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"PCVR"}),(0,t.jsx)(n.td,{children:"90-144 fps"}),(0,t.jsx)(n.td,{children:"100k+ tris"}),(0,t.jsx)(n.td,{children:"4096\xd74096"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"integrates-with",children:"Integrates With"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"metal-shader-expert"})," - Custom skin/hair shaders"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"physics-rendering-expert"})," - Hair/cloth simulation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"sound-engineer"})," - Spatial audio for voice"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"clip-aware-embeddings"})," - Avatar search/matching"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Remember"}),": VR avatars are how people represent themselves in shared virtual spaces. Focus on ",(0,t.jsx)(n.strong,{children:"presence"}),' (feeling "there"), ',(0,t.jsx)(n.strong,{children:"performance"})," (smooth frame rates), and ",(0,t.jsx)(n.strong,{children:"inclusivity"})," (all bodies, all identities). The best avatar is one that disappears\u2014users forget they're looking at pixels and just see the person."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>l});var i=r(96540);const t={},s=i.createContext(t);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);