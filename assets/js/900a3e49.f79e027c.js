"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[74556],{28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var r=t(96540);const i={},a=r.createContext(i);function s(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(a.Provider,{value:n},e.children)}},64264:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"skills/dag_pattern_learner/index","title":"\ud83d\udce6 Dag Pattern Learner","description":"Learns from DAG execution history to improve future performance. Identifies successful patterns, detects anti-patterns, and provides recommendations. Activate on \'learn patterns\', \'execution patterns\', \'what worked\', \'optimize based on history\', \'pattern analysis\'. NOT for failure analysis (use dag-failure-analyzer) or performance profiling (use dag-performance-profiler).","source":"@site/docs/skills/dag_pattern_learner/index.md","sourceDirName":"skills/dag_pattern_learner","slug":"/skills/dag_pattern_learner/","permalink":"/docs/skills/dag_pattern_learner/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Dag Pattern Learner","sidebar_position":1}}');var i=t(74848),a=t(28453);const s={sidebar_label:"Dag Pattern Learner",sidebar_position:1},o="\ud83d\udce6 Dag Pattern Learner",c={},l=[{value:"Allowed Tools",id:"allowed-tools",level:2},{value:"Tags",id:"tags",level:2},{value:"\ud83e\udd1d Pairs Great With",id:"-pairs-great-with",level:2},{value:"Core Responsibilities",id:"core-responsibilities",level:2},{value:"1. Pattern Extraction",id:"1-pattern-extraction",level:3},{value:"2. Anti-Pattern Detection",id:"2-anti-pattern-detection",level:3},{value:"3. Recommendation Generation",id:"3-recommendation-generation",level:3},{value:"4. Knowledge Accumulation",id:"4-knowledge-accumulation",level:3},{value:"Pattern Learning Architecture",id:"pattern-learning-architecture",level:2},{value:"Pattern Extraction",id:"pattern-extraction",level:2},{value:"Anti-Pattern Detection",id:"anti-pattern-detection",level:2},{value:"Recommendation Generation",id:"recommendation-generation",level:2},{value:"Pattern Library Report",id:"pattern-library-report",level:2},{value:"Integration Points",id:"integration-points",level:2},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"-dag-pattern-learner",children:"\ud83d\udce6 Dag Pattern Learner"})}),"\n",(0,i.jsx)(n.p,{children:"Learns from DAG execution history to improve future performance. Identifies successful patterns, detects anti-patterns, and provides recommendations. Activate on 'learn patterns', 'execution patterns', 'what worked', 'optimize based on history', 'pattern analysis'. NOT for failure analysis (use dag-failure-analyzer) or performance profiling (use dag-performance-profiler)."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"allowed-tools",children:"Allowed Tools"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Read, Write, Edit, Glob, Grep\n"})}),"\n",(0,i.jsx)(n.h2,{id:"tags",children:"Tags"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"dag"})," ",(0,i.jsx)(n.code,{children:"observability"})," ",(0,i.jsx)(n.code,{children:"learning"})," ",(0,i.jsx)(n.code,{children:"patterns"})," ",(0,i.jsx)(n.code,{children:"optimization"})]}),"\n",(0,i.jsx)(n.h2,{id:"-pairs-great-with",children:"\ud83e\udd1d Pairs Great With"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/dag_execution_tracer",children:"Dag Execution Tracer"})}),": Source of execution data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/dag_performance_profiler",children:"Dag Performance Profiler"})}),": Source of performance data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/dag_failure_analyzer",children:"Dag Failure Analyzer"})}),": Source of failure patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/skills/dag_graph_builder",children:"Dag Graph Builder"})}),": Applies learned patterns"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"You are a DAG Pattern Learner, an expert at extracting actionable knowledge from DAG execution history. You identify successful patterns, detect anti-patterns, correlate configurations with outcomes, and generate recommendations that improve future DAG performance."}),"\n",(0,i.jsx)(n.h2,{id:"core-responsibilities",children:"Core Responsibilities"}),"\n",(0,i.jsx)(n.h3,{id:"1-pattern-extraction",children:"1. Pattern Extraction"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Identify recurring execution patterns"}),"\n",(0,i.jsx)(n.li,{children:"Detect successful vs failing configurations"}),"\n",(0,i.jsx)(n.li,{children:"Find correlations in execution data"}),"\n",(0,i.jsx)(n.li,{children:"Extract reusable templates"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-anti-pattern-detection",children:"2. Anti-Pattern Detection"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Identify configurations that lead to failures"}),"\n",(0,i.jsx)(n.li,{children:"Detect inefficient graph structures"}),"\n",(0,i.jsx)(n.li,{children:"Find common mistakes"}),"\n",(0,i.jsx)(n.li,{children:"Flag problematic dependencies"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-recommendation-generation",children:"3. Recommendation Generation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Suggest optimal configurations"}),"\n",(0,i.jsx)(n.li,{children:"Recommend parallel execution opportunities"}),"\n",(0,i.jsx)(n.li,{children:"Propose retry strategies"}),"\n",(0,i.jsx)(n.li,{children:"Guide skill selection"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-knowledge-accumulation",children:"4. Knowledge Accumulation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Build pattern library"}),"\n",(0,i.jsx)(n.li,{children:"Track pattern effectiveness"}),"\n",(0,i.jsx)(n.li,{children:"Update recommendations based on outcomes"}),"\n",(0,i.jsx)(n.li,{children:"Maintain confidence scores"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"pattern-learning-architecture",children:"Pattern Learning Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface PatternLibrary {\n  libraryId: string;\n  lastUpdated: Date;\n  patterns: Pattern[];\n  antiPatterns: AntiPattern[];\n  recommendations: LearnedRecommendation[];\n  statistics: LibraryStatistics;\n}\n\ninterface Pattern {\n  patternId: string;\n  name: string;\n  description: string;\n  type: PatternType;\n  structure: PatternStructure;\n  conditions: PatternCondition[];\n  outcomes: PatternOutcome;\n  confidence: number;\n  occurrences: number;\n  lastSeen: Date;\n}\n\ntype PatternType =\n  | 'graph_structure'      // DAG topology patterns\n  | 'skill_combination'    // Skills that work well together\n  | 'execution_order'      // Optimal ordering patterns\n  | 'parallelization'      // Effective parallel execution\n  | 'retry_strategy'       // Successful retry approaches\n  | 'resource_allocation'  // Optimal resource usage\n  | 'failure_recovery';    // Successful recovery patterns\n\ninterface PatternStructure {\n  nodes?: NodePattern[];\n  edges?: EdgePattern[];\n  constraints?: StructureConstraint[];\n  template?: string;  // Serialized pattern template\n}\n\ninterface PatternOutcome {\n  successRate: number;\n  avgDuration: number;\n  avgCost: number;\n  avgQuality: number;\n  sampleSize: number;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"pattern-extraction",children:"Pattern Extraction"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface ExecutionDataset {\n  executions: ExecutionRecord[];\n  timeRange: { start: Date; end: Date };\n  filters?: DatasetFilters;\n}\n\ninterface ExecutionRecord {\n  traceId: string;\n  dagId: string;\n  dagStructure: DAGStructure;\n  outcome: ExecutionOutcome;\n  metrics: ExecutionMetrics;\n  context: ExecutionContext;\n}\n\nfunction extractPatterns(dataset: ExecutionDataset): Pattern[] {\n  const patterns: Pattern[] = [];\n\n  // Extract graph structure patterns\n  patterns.push(...extractGraphPatterns(dataset));\n\n  // Extract skill combination patterns\n  patterns.push(...extractSkillCombinations(dataset));\n\n  // Extract execution order patterns\n  patterns.push(...extractOrderingPatterns(dataset));\n\n  // Extract parallelization patterns\n  patterns.push(...extractParallelPatterns(dataset));\n\n  // Filter by confidence threshold\n  return patterns.filter(p => p.confidence >= 0.6);\n}\n\nfunction extractGraphPatterns(dataset: ExecutionDataset): Pattern[] {\n  const structureGroups = groupByStructure(dataset.executions);\n  const patterns: Pattern[] = [];\n\n  for (const [structureHash, executions] of structureGroups) {\n    if (executions.length < 3) continue;  // Need minimum samples\n\n    const outcomes = analyzeOutcomes(executions);\n\n    if (outcomes.successRate >= 0.8) {\n      patterns.push({\n        patternId: generatePatternId(),\n        name: inferPatternName(executions[0].dagStructure),\n        description: describePattern(executions[0].dagStructure),\n        type: 'graph_structure',\n        structure: extractStructurePattern(executions[0].dagStructure),\n        conditions: inferConditions(executions),\n        outcomes,\n        confidence: calculateConfidence(outcomes, executions.length),\n        occurrences: executions.length,\n        lastSeen: maxDate(executions.map(e => e.metrics.completedAt)),\n      });\n    }\n  }\n\n  return patterns;\n}\n\nfunction extractSkillCombinations(dataset: ExecutionDataset): Pattern[] {\n  const combinations = new Map<string, ExecutionRecord[]>();\n\n  for (const execution of dataset.executions) {\n    const skills = extractSkillIds(execution.dagStructure);\n    const key = skills.sort().join(',');\n\n    const existing = combinations.get(key) ?? [];\n    existing.push(execution);\n    combinations.set(key, existing);\n  }\n\n  const patterns: Pattern[] = [];\n\n  for (const [key, executions] of combinations) {\n    if (executions.length < 3) continue;\n\n    const outcomes = analyzeOutcomes(executions);\n\n    if (outcomes.successRate >= 0.75) {\n      const skills = key.split(',');\n      patterns.push({\n        patternId: generatePatternId(),\n        name: `Skill Combination: ${skills.slice(0, 3).join(' + ')}${skills.length > 3 ? '...' : ''}`,\n        description: `Effective combination of ${skills.length} skills`,\n        type: 'skill_combination',\n        structure: {\n          nodes: skills.map(s => ({ skillId: s })),\n        },\n        conditions: inferCombinationConditions(executions),\n        outcomes,\n        confidence: calculateConfidence(outcomes, executions.length),\n        occurrences: executions.length,\n        lastSeen: maxDate(executions.map(e => e.metrics.completedAt)),\n      });\n    }\n  }\n\n  return patterns;\n}\n\nfunction extractParallelPatterns(dataset: ExecutionDataset): Pattern[] {\n  const patterns: Pattern[] = [];\n\n  for (const execution of dataset.executions) {\n    const parallelGroups = identifyParallelGroups(execution);\n\n    for (const group of parallelGroups) {\n      if (group.nodes.length >= 2 && group.success) {\n        const patternKey = generateParallelPatternKey(group);\n\n        // Check if pattern already exists\n        const existing = patterns.find(p =>\n          p.type === 'parallelization' &&\n          matchesParallelPattern(p, group)\n        );\n\n        if (existing) {\n          existing.occurrences++;\n          existing.lastSeen = execution.metrics.completedAt;\n          // Update outcomes\n          updateOutcomes(existing.outcomes, group.metrics);\n        } else {\n          patterns.push({\n            patternId: generatePatternId(),\n            name: `Parallel Group: ${group.nodes.length} nodes`,\n            description: `Successfully parallelized ${group.nodes.map(n => n.type).join(', ')}`,\n            type: 'parallelization',\n            structure: {\n              nodes: group.nodes.map(n => ({ type: n.type, skillId: n.skillId })),\n              constraints: [{ type: 'no_dependencies_between', nodes: group.nodes.map(n => n.id) }],\n            },\n            conditions: [{ condition: 'Nodes have no interdependencies' }],\n            outcomes: {\n              successRate: 1,\n              avgDuration: group.metrics.duration,\n              avgCost: group.metrics.cost,\n              avgQuality: group.metrics.quality,\n              sampleSize: 1,\n            },\n            confidence: 0.6,  // Start low, increase with more observations\n            occurrences: 1,\n            lastSeen: execution.metrics.completedAt,\n          });\n        }\n      }\n    }\n  }\n\n  return patterns;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"anti-pattern-detection",children:"Anti-Pattern Detection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface AntiPattern {\n  antiPatternId: string;\n  name: string;\n  description: string;\n  type: AntiPatternType;\n  indicators: AntiPatternIndicator[];\n  consequences: string[];\n  remediation: string;\n  occurrences: number;\n  severity: 'critical' | 'high' | 'medium' | 'low';\n}\n\ntype AntiPatternType =\n  | 'circular_dependency_risk'\n  | 'bottleneck_structure'\n  | 'over_parallelization'\n  | 'under_parallelization'\n  | 'excessive_retries'\n  | 'resource_waste'\n  | 'fragile_dependency';\n\ninterface AntiPatternIndicator {\n  metric: string;\n  threshold: number;\n  observed: number;\n  comparison: 'above' | 'below';\n}\n\nfunction detectAntiPatterns(dataset: ExecutionDataset): AntiPattern[] {\n  const antiPatterns: AntiPattern[] = [];\n\n  // Detect bottleneck structures\n  antiPatterns.push(...detectBottlenecks(dataset));\n\n  // Detect over-parallelization\n  antiPatterns.push(...detectOverParallelization(dataset));\n\n  // Detect excessive retries\n  antiPatterns.push(...detectExcessiveRetries(dataset));\n\n  // Detect resource waste\n  antiPatterns.push(...detectResourceWaste(dataset));\n\n  return antiPatterns;\n}\n\nfunction detectBottlenecks(dataset: ExecutionDataset): AntiPattern[] {\n  const antiPatterns: AntiPattern[] = [];\n\n  for (const execution of dataset.executions) {\n    const bottlenecks = findBottleneckNodes(execution);\n\n    for (const bottleneck of bottlenecks) {\n      if (bottleneck.impact >= 0.3) {  // Node accounts for 30%+ of total time\n        const existing = antiPatterns.find(ap =>\n          ap.type === 'bottleneck_structure' &&\n          ap.indicators[0]?.metric === bottleneck.nodeType\n        );\n\n        if (existing) {\n          existing.occurrences++;\n        } else {\n          antiPatterns.push({\n            antiPatternId: generateAntiPatternId(),\n            name: `Bottleneck: ${bottleneck.nodeType}`,\n            description: `Node type ${bottleneck.nodeType} consistently blocks parallel execution`,\n            type: 'bottleneck_structure',\n            indicators: [{\n              metric: bottleneck.nodeType,\n              threshold: 0.2,\n              observed: bottleneck.impact,\n              comparison: 'above',\n            }],\n            consequences: [\n              'Limits parallel execution potential',\n              'Increases total DAG duration',\n              'Creates single point of failure',\n            ],\n            remediation: 'Consider splitting into smaller, parallelizable units or moving earlier in the DAG',\n            occurrences: 1,\n            severity: bottleneck.impact >= 0.5 ? 'high' : 'medium',\n          });\n        }\n      }\n    }\n  }\n\n  return antiPatterns;\n}\n\nfunction detectExcessiveRetries(dataset: ExecutionDataset): AntiPattern[] {\n  const antiPatterns: AntiPattern[] = [];\n  const retryStats = new Map<string, { total: number; retries: number }>();\n\n  for (const execution of dataset.executions) {\n    for (const node of execution.dagStructure.nodes) {\n      const stats = retryStats.get(node.type) ?? { total: 0, retries: 0 };\n      stats.total++;\n      stats.retries += (node.retryCount ?? 0);\n      retryStats.set(node.type, stats);\n    }\n  }\n\n  for (const [nodeType, stats] of retryStats) {\n    const avgRetries = stats.retries / stats.total;\n\n    if (avgRetries > 1.5 && stats.total >= 5) {\n      antiPatterns.push({\n        antiPatternId: generateAntiPatternId(),\n        name: `Excessive Retries: ${nodeType}`,\n        description: `Node type ${nodeType} requires ${avgRetries.toFixed(1)} retries on average`,\n        type: 'excessive_retries',\n        indicators: [{\n          metric: 'avg_retries',\n          threshold: 1.0,\n          observed: avgRetries,\n          comparison: 'above',\n        }],\n        consequences: [\n          'Increased execution time',\n          'Higher token costs',\n          'Reduced reliability',\n        ],\n        remediation: 'Investigate root cause of failures; improve input validation or add pre-checks',\n        occurrences: stats.total,\n        severity: avgRetries > 2.5 ? 'high' : 'medium',\n      });\n    }\n  }\n\n  return antiPatterns;\n}\n\nfunction detectResourceWaste(dataset: ExecutionDataset): AntiPattern[] {\n  const antiPatterns: AntiPattern[] = [];\n\n  for (const execution of dataset.executions) {\n    const waste = calculateResourceWaste(execution);\n\n    if (waste.tokenWaste > 0.3) {  // 30%+ tokens wasted\n      antiPatterns.push({\n        antiPatternId: generateAntiPatternId(),\n        name: 'Token Waste',\n        description: `${(waste.tokenWaste * 100).toFixed(0)}% of tokens used in failed nodes`,\n        type: 'resource_waste',\n        indicators: [{\n          metric: 'token_waste_ratio',\n          threshold: 0.2,\n          observed: waste.tokenWaste,\n          comparison: 'above',\n        }],\n        consequences: [\n          'Increased costs',\n          'Wasted compute resources',\n        ],\n        remediation: 'Add early validation, implement circuit breakers, or reorder to fail fast',\n        occurrences: 1,\n        severity: waste.tokenWaste > 0.5 ? 'high' : 'medium',\n      });\n    }\n  }\n\n  return antiPatterns;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"recommendation-generation",children:"Recommendation Generation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface LearnedRecommendation {\n  recommendationId: string;\n  type: RecommendationType;\n  title: string;\n  description: string;\n  applicability: ApplicabilityCondition[];\n  expectedBenefit: ExpectedBenefit;\n  confidence: number;\n  basedOn: {\n    patterns: string[];\n    antiPatterns: string[];\n    sampleSize: number;\n  };\n}\n\ntype RecommendationType =\n  | 'skill_selection'\n  | 'graph_structure'\n  | 'parallelization'\n  | 'retry_configuration'\n  | 'resource_allocation'\n  | 'ordering_optimization';\n\ninterface ExpectedBenefit {\n  metric: 'duration' | 'cost' | 'quality' | 'reliability';\n  improvement: number;  // Percentage improvement\n  confidence: number;\n}\n\nfunction generateRecommendations(\n  patterns: Pattern[],\n  antiPatterns: AntiPattern[]\n): LearnedRecommendation[] {\n  const recommendations: LearnedRecommendation[] = [];\n\n  // Recommendations from successful patterns\n  for (const pattern of patterns) {\n    if (pattern.confidence >= 0.7 && pattern.occurrences >= 5) {\n      recommendations.push(patternToRecommendation(pattern));\n    }\n  }\n\n  // Recommendations from anti-patterns (avoid these)\n  for (const antiPattern of antiPatterns) {\n    if (antiPattern.occurrences >= 3) {\n      recommendations.push(antiPatternToRecommendation(antiPattern));\n    }\n  }\n\n  // Cross-pattern analysis\n  recommendations.push(...crossPatternRecommendations(patterns, antiPatterns));\n\n  // Sort by expected impact\n  return recommendations.sort((a, b) =>\n    b.expectedBenefit.improvement - a.expectedBenefit.improvement\n  );\n}\n\nfunction patternToRecommendation(pattern: Pattern): LearnedRecommendation {\n  const typeMapping: Record<PatternType, RecommendationType> = {\n    'graph_structure': 'graph_structure',\n    'skill_combination': 'skill_selection',\n    'execution_order': 'ordering_optimization',\n    'parallelization': 'parallelization',\n    'retry_strategy': 'retry_configuration',\n    'resource_allocation': 'resource_allocation',\n    'failure_recovery': 'retry_configuration',\n  };\n\n  return {\n    recommendationId: generateRecommendationId(),\n    type: typeMapping[pattern.type],\n    title: `Use: ${pattern.name}`,\n    description: pattern.description,\n    applicability: pattern.conditions.map(c => ({\n      condition: c.condition ?? c.toString(),\n      required: true,\n    })),\n    expectedBenefit: {\n      metric: 'reliability',\n      improvement: pattern.outcomes.successRate * 100 - 50,  // Above 50% baseline\n      confidence: pattern.confidence,\n    },\n    confidence: pattern.confidence,\n    basedOn: {\n      patterns: [pattern.patternId],\n      antiPatterns: [],\n      sampleSize: pattern.occurrences,\n    },\n  };\n}\n\nfunction antiPatternToRecommendation(antiPattern: AntiPattern): LearnedRecommendation {\n  return {\n    recommendationId: generateRecommendationId(),\n    type: inferRecommendationType(antiPattern),\n    title: `Avoid: ${antiPattern.name}`,\n    description: `${antiPattern.description}. ${antiPattern.remediation}`,\n    applicability: antiPattern.indicators.map(i => ({\n      condition: `${i.metric} is ${i.comparison} ${i.threshold}`,\n      required: true,\n    })),\n    expectedBenefit: {\n      metric: antiPattern.type === 'resource_waste' ? 'cost' : 'reliability',\n      improvement: antiPattern.severity === 'critical' ? 40 :\n                   antiPattern.severity === 'high' ? 25 :\n                   antiPattern.severity === 'medium' ? 15 : 5,\n      confidence: Math.min(0.9, 0.5 + antiPattern.occurrences * 0.05),\n    },\n    confidence: Math.min(0.9, 0.5 + antiPattern.occurrences * 0.05),\n    basedOn: {\n      patterns: [],\n      antiPatterns: [antiPattern.antiPatternId],\n      sampleSize: antiPattern.occurrences,\n    },\n  };\n}\n\nfunction crossPatternRecommendations(\n  patterns: Pattern[],\n  antiPatterns: AntiPattern[]\n): LearnedRecommendation[] {\n  const recommendations: LearnedRecommendation[] = [];\n\n  // Find complementary skill patterns\n  const skillPatterns = patterns.filter(p => p.type === 'skill_combination');\n  for (let i = 0; i < skillPatterns.length; i++) {\n    for (let j = i + 1; j < skillPatterns.length; j++) {\n      const overlap = findSkillOverlap(skillPatterns[i], skillPatterns[j]);\n      if (overlap.length > 0) {\n        recommendations.push({\n          recommendationId: generateRecommendationId(),\n          type: 'skill_selection',\n          title: `Synergy: ${overlap.join(' + ')}`,\n          description: `Skills ${overlap.join(', ')} appear in multiple successful patterns`,\n          applicability: [{ condition: 'Task requires multiple capabilities', required: true }],\n          expectedBenefit: {\n            metric: 'quality',\n            improvement: 20,\n            confidence: 0.7,\n          },\n          confidence: 0.7,\n          basedOn: {\n            patterns: [skillPatterns[i].patternId, skillPatterns[j].patternId],\n            antiPatterns: [],\n            sampleSize: skillPatterns[i].occurrences + skillPatterns[j].occurrences,\n          },\n        });\n      }\n    }\n  }\n\n  return recommendations;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"pattern-library-report",children:"Pattern Library Report"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'patternLibrary:\n  libraryId: "pl-9d8c7b6a-5e4f-3a2b-1c0d"\n  lastUpdated: "2024-01-15T12:00:00Z"\n\n  statistics:\n    totalPatterns: 15\n    totalAntiPatterns: 6\n    totalRecommendations: 21\n    executionsAnalyzed: 234\n    timeSpan: "30 days"\n\n  topPatterns:\n    - patternId: "pat-001"\n      name: "Fan-out-Fan-in"\n      type: graph_structure\n      description: "Distribute work to parallel nodes, then aggregate results"\n      confidence: 0.92\n      occurrences: 45\n      outcomes:\n        successRate: 0.89\n        avgDuration: 12500\n        avgCost: 0.045\n\n    - patternId: "pat-002"\n      name: "Validation First"\n      type: execution_order\n      description: "Run validation before expensive operations"\n      confidence: 0.88\n      occurrences: 67\n      outcomes:\n        successRate: 0.94\n        avgDuration: 8200\n        avgCost: 0.028\n\n    - patternId: "pat-003"\n      name: "Code Analysis Triple"\n      type: skill_combination\n      description: "code-complexity-analyzer + code-security-scanner + code-performance-analyzer"\n      confidence: 0.85\n      occurrences: 23\n      outcomes:\n        successRate: 0.91\n        avgDuration: 15000\n        avgCost: 0.062\n\n  topAntiPatterns:\n    - antiPatternId: "anti-001"\n      name: "Sequential Bottleneck"\n      type: bottleneck_structure\n      severity: high\n      occurrences: 12\n      remediation: "Split large sequential node into parallelizable subtasks"\n\n    - antiPatternId: "anti-002"\n      name: "Retry Storm"\n      type: excessive_retries\n      severity: medium\n      occurrences: 8\n      remediation: "Add pre-validation to catch issues before execution"\n\n  recommendations:\n    - recommendationId: "rec-001"\n      type: parallelization\n      title: "Parallelize Independent Analysis"\n      description: "When running multiple analysis skills, execute them in parallel"\n      expectedBenefit:\n        metric: duration\n        improvement: 45\n        confidence: 0.85\n      basedOn:\n        patterns: ["pat-001", "pat-003"]\n        sampleSize: 68\n\n    - recommendationId: "rec-002"\n      type: ordering_optimization\n      title: "Validate Early"\n      description: "Move validation nodes to earliest possible position"\n      expectedBenefit:\n        metric: cost\n        improvement: 30\n        confidence: 0.88\n      basedOn:\n        patterns: ["pat-002"]\n        antiPatterns: ["anti-001"]\n        sampleSize: 67\n\n  trends:\n    - observation: "Success rate improving over time"\n      metric: successRate\n      change: +0.08\n      period: "last 30 days"\n\n    - observation: "Average cost decreasing"\n      metric: avgCost\n      change: -0.015\n      period: "last 30 days"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"integration-points",children:"Integration Points"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": Execution traces from ",(0,i.jsx)(n.code,{children:"dag-execution-tracer"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": Performance data from ",(0,i.jsx)(n.code,{children:"dag-performance-profiler"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": Failure data from ",(0,i.jsx)(n.code,{children:"dag-failure-analyzer"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": Patterns and recommendations to ",(0,i.jsx)(n.code,{children:"dag-graph-builder"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": Optimization hints to ",(0,i.jsx)(n.code,{children:"dag-task-scheduler"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Minimum Sample Size"}),": Require 3+ observations before extracting patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Confidence Decay"}),": Reduce confidence for patterns not seen recently"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Context Matters"}),": Patterns should include applicable conditions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actionable Output"}),": Recommendations must be implementable"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Continuous Learning"}),": Update library with each new execution"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:"Learn from history. Find what works. Continuously improve."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);