"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[33556],{21602:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>u});const a=JSON.parse('{"id":"skills/2000s_visualization_expert/references/glsl-shaders","title":"GLSL Shaders for Audio Visualization","description":"Custom shader implementations for audio-reactive effects.","source":"@site/docs/skills/2000s_visualization_expert/references/glsl-shaders.md","sourceDirName":"skills/2000s_visualization_expert/references","slug":"/skills/2000s_visualization_expert/references/glsl-shaders","permalink":"/docs/skills/2000s_visualization_expert/references/glsl-shaders","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"GLSL Shaders for Audio Visualization","sidebar_label":"GLSL Shaders for Audio Visu...","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Butterchurn Integration Guide","permalink":"/docs/skills/2000s_visualization_expert/references/butterchurn-guide"},"next":{"title":"Web Audio API FFT Reference","permalink":"/docs/skills/2000s_visualization_expert/references/web-audio-fft"}}');var o=r(74848),t=r(28453);const i={title:"GLSL Shaders for Audio Visualization",sidebar_label:"GLSL Shaders for Audio Visu...",sidebar_position:2},l="GLSL Shaders for Audio Visualization",s={},u=[{value:"Basic Audio-Reactive Fragment Shader",id:"basic-audio-reactive-fragment-shader",level:2},{value:"Tunnel Effect",id:"tunnel-effect",level:2},{value:"Plasma Effect",id:"plasma-effect",level:2},{value:"Kaleidoscope Effect",id:"kaleidoscope-effect",level:2},{value:"Spectrum Bars (Classic)",id:"spectrum-bars-classic",level:2},{value:"Waveform Display",id:"waveform-display",level:2},{value:"WebGL Shader Setup (TypeScript)",id:"webgl-shader-setup-typescript",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glsl-shaders-for-audio-visualization",children:"GLSL Shaders for Audio Visualization"})}),"\n",(0,o.jsx)(n.p,{children:"Custom shader implementations for audio-reactive effects."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"basic-audio-reactive-fragment-shader",children:"Basic Audio-Reactive Fragment Shader"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;  // FFT as 1D texture\nuniform float u_bass;\nuniform float u_mid;\nuniform float u_treble;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Audio-reactive radius\n  float dist = length(center);\n  float audioSample = texture2D(u_audioData, vec2(dist, 0.0)).r;\n\n  // Psychedelic color cycling\n  float hue = u_time * 0.1 + audioSample * 0.5;\n  vec3 color = 0.5 + 0.5 * cos(6.28 * (hue + vec3(0.0, 0.33, 0.67)));\n\n  // Pulsing glow based on bass\n  float glow = smoothstep(0.5 - u_bass * 0.3, 0.0, dist);\n\n  gl_FragColor = vec4(color * glow, 1.0);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"tunnel-effect",children:"Tunnel Effect"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform float u_bass;\nuniform float u_speed;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Convert to polar coordinates\n  float angle = atan(center.y, center.x);\n  float radius = length(center);\n\n  // Tunnel distortion\n  float tunnel = 0.1 / radius;\n\n  // Scrolling texture coordinates\n  float u = angle / 3.14159;\n  float v = tunnel + u_time * u_speed + u_bass * 0.5;\n\n  // Create stripe pattern\n  float stripes = sin(u * 10.0) * sin(v * 20.0);\n  stripes = smoothstep(0.0, 0.1, stripes);\n\n  // Color based on depth\n  vec3 color = vec3(0.2, 0.5, 1.0) * stripes;\n  color *= 1.0 - radius * 1.5;  // Fade at edges\n\n  gl_FragColor = vec4(color, 1.0);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"plasma-effect",children:"Plasma Effect"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform float u_bass;\nuniform float u_mid;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Multiple sine waves\n  float v1 = sin(uv.x * 10.0 + u_time);\n  float v2 = sin(10.0 * (uv.x * sin(u_time / 2.0) + uv.y * cos(u_time / 3.0)) + u_time);\n\n  float cx = uv.x + 0.5 * sin(u_time / 5.0);\n  float cy = uv.y + 0.5 * cos(u_time / 3.0);\n  float v3 = sin(sqrt(100.0 * (cx * cx + cy * cy) + 1.0) + u_time);\n\n  float v = v1 + v2 + v3;\n\n  // Audio modulation\n  v *= 1.0 + u_bass * 0.5;\n\n  // Color palette\n  vec3 color;\n  color.r = sin(v * 3.14159 + u_mid);\n  color.g = sin(v * 3.14159 + 2.094 + u_mid);\n  color.b = sin(v * 3.14159 + 4.188 + u_mid);\n  color = color * 0.5 + 0.5;\n\n  gl_FragColor = vec4(color, 1.0);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"kaleidoscope-effect",children:"Kaleidoscope Effect"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;\nuniform float u_bass;\n\n#define PI 3.14159265359\n#define SEGMENTS 8.0\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Convert to polar\n  float angle = atan(center.y, center.x);\n  float radius = length(center);\n\n  // Kaleidoscope fold\n  float segment = PI * 2.0 / SEGMENTS;\n  angle = mod(angle, segment);\n  if (mod(floor(atan(center.y, center.x) / segment), 2.0) == 1.0) {\n    angle = segment - angle;\n  }\n\n  // Convert back to cartesian\n  vec2 kaleido = vec2(cos(angle), sin(angle)) * radius;\n\n  // Sample audio at radius\n  float audio = texture2D(u_audioData, vec2(radius * 2.0, 0.0)).r;\n\n  // Create pattern\n  float pattern = sin(kaleido.x * 20.0 + u_time * 2.0);\n  pattern *= sin(kaleido.y * 20.0 + u_time);\n  pattern = pattern * 0.5 + 0.5;\n\n  // Color\n  vec3 color = vec3(pattern) * (audio + 0.2);\n  color *= 0.5 + 0.5 * cos(6.28 * (u_time * 0.1 + vec3(0.0, 0.33, 0.67)));\n\n  // Vignette\n  color *= 1.0 - radius;\n\n  gl_FragColor = vec4(color, 1.0);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"spectrum-bars-classic",children:"Spectrum Bars (Classic)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;\nuniform float u_barCount;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Which bar are we in?\n  float barIndex = floor(uv.x * u_barCount);\n  float barCenter = (barIndex + 0.5) / u_barCount;\n\n  // Sample audio at bar position\n  float audio = texture2D(u_audioData, vec2(barCenter, 0.0)).r;\n\n  // Bar shape\n  float barWidth = 0.8 / u_barCount;\n  float inBar = step(abs(uv.x - barCenter), barWidth * 0.5);\n\n  // Height\n  float barHeight = audio;\n  float inHeight = step(uv.y, barHeight);\n\n  // Color gradient (blue to red based on height)\n  vec3 color = mix(vec3(0.2, 0.5, 1.0), vec3(1.0, 0.2, 0.5), uv.y);\n\n  // Combine\n  float alpha = inBar * inHeight;\n\n  gl_FragColor = vec4(color * alpha, alpha);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"waveform-display",children:"Waveform Display"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-glsl",children:"precision mediump float;\n\nuniform vec2 u_resolution;\nuniform sampler2D u_waveformData;\nuniform float u_lineWidth;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Sample waveform\n  float waveform = texture2D(u_waveformData, vec2(uv.x, 0.0)).r;\n  waveform = waveform * 2.0 - 1.0;  // Convert from 0-1 to -1 to 1\n\n  // Center the waveform\n  float y = waveform * 0.4 + 0.5;\n\n  // Distance from waveform line\n  float dist = abs(uv.y - y);\n\n  // Line with glow\n  float line = smoothstep(u_lineWidth, 0.0, dist);\n  float glow = smoothstep(u_lineWidth * 10.0, 0.0, dist) * 0.5;\n\n  vec3 color = vec3(0.3, 1.0, 0.5) * (line + glow);\n\n  gl_FragColor = vec4(color, 1.0);\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"webgl-shader-setup-typescript",children:"WebGL Shader Setup (TypeScript)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"function createShaderProgram(\n  gl: WebGLRenderingContext,\n  vertexSource: string,\n  fragmentSource: string\n): WebGLProgram {\n  const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexSource);\n  const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentSource);\n\n  const program = gl.createProgram()!;\n  gl.attachShader(program, vertexShader);\n  gl.attachShader(program, fragmentShader);\n  gl.linkProgram(program);\n\n  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n    throw new Error('Shader program failed to link');\n  }\n\n  return program;\n}\n\nfunction compileShader(\n  gl: WebGLRenderingContext,\n  type: number,\n  source: string\n): WebGLShader {\n  const shader = gl.createShader(type)!;\n  gl.shaderSource(shader, source);\n  gl.compileShader(shader);\n\n  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {\n    const info = gl.getShaderInfoLog(shader);\n    throw new Error(`Shader compilation error: ${info}`);\n  }\n\n  return shader;\n}\n\n// Basic vertex shader (fullscreen quad)\nconst VERTEX_SHADER = `\n  attribute vec2 a_position;\n  void main() {\n    gl_Position = vec4(a_position, 0.0, 1.0);\n  }\n`;\n\n// Create fullscreen quad\nfunction createFullscreenQuad(gl: WebGLRenderingContext): WebGLBuffer {\n  const buffer = gl.createBuffer()!;\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(\n    gl.ARRAY_BUFFER,\n    new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]),\n    gl.STATIC_DRAW\n  );\n  return buffer;\n}\n"})})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>l});var a=r(96540);const o={},t=a.createContext(o);function i(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);