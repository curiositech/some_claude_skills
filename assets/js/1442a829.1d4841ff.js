"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[58410],{28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>i});var a=t(96540);const o={},r=a.createContext(o);function l(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),a.createElement(r.Provider,{value:n},e.children)}},97663:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"skills/color_theory_palette_harmony_expert/references/implementation-guide","title":"Implementation Guide","description":"Python Dependencies","source":"@site/docs/skills/color_theory_palette_harmony_expert/references/implementation-guide.md","sourceDirName":"skills/color_theory_palette_harmony_expert/references","slug":"/skills/color_theory_palette_harmony_expert/references/implementation-guide","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/implementation-guide","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Implementation Guide","sidebar_label":"Implementation Guide","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Diversity Algorithms: Preve...","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/diversity-algorithms"},"next":{"title":"Optimal Transport for Color...","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/optimal-transport"}}');var o=t(74848),r=t(28453);const l={title:"Implementation Guide",sidebar_label:"Implementation Guide",sidebar_position:3},i="Implementation Guide",s={},c=[{value:"Python Dependencies",id:"python-dependencies",level:2},{value:"Performance Targets",id:"performance-targets",level:2},{value:"GPU Acceleration (Metal Shaders)",id:"gpu-acceleration-metal-shaders",level:2},{value:"Compute EMD in Parallel (Cost Matrix)",id:"compute-emd-in-parallel-cost-matrix",level:3},{value:"Sinkhorn Iterations on GPU",id:"sinkhorn-iterations-on-gpu",level:3},{value:"Caching",id:"caching",level:2},{value:"Common Patterns",id:"common-patterns",level:2},{value:"Pattern 1: Progressive Color Matching",id:"pattern-1-progressive-color-matching",level:3},{value:"Pattern 2: Hierarchical Palette Matching",id:"pattern-2-hierarchical-palette-matching",level:3},{value:"Advanced Techniques",id:"advanced-techniques",level:2},{value:"Dynamic Palette Evolution",id:"dynamic-palette-evolution",level:3},{value:"Color Mood Transfer",id:"color-mood-transfer",level:3},{value:"Color Constancy Correction",id:"color-constancy-correction",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue: EMD too slow for large palettes",id:"issue-emd-too-slow-for-large-palettes",level:3},{value:"Issue: Photos look washed out after color grading",id:"issue-photos-look-washed-out-after-color-grading",level:3},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"implementation-guide",children:"Implementation Guide"})}),"\n",(0,o.jsx)(n.h2,{id:"python-dependencies",children:"Python Dependencies"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"pip install colormath opencv-python numpy scipy scikit-image scikit-learn pot hnswlib\n"})}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Package"}),(0,o.jsx)(n.th,{children:"Purpose"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"colormath"})}),(0,o.jsx)(n.td,{children:"CIEDE2000 implementation, LAB/LCH conversions"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"opencv-python"})}),(0,o.jsx)(n.td,{children:"Image color extraction, histogram analysis"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"scikit-image"})}),(0,o.jsx)(n.td,{children:"deltaE calculations, color space transforms"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"numpy"})}),(0,o.jsx)(n.td,{children:"Numerical computing"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"scipy"})}),(0,o.jsx)(n.td,{children:"Optimization for EMD/Wasserstein"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"scikit-learn"})}),(0,o.jsx)(n.td,{children:"K-means for palette extraction"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"pot"})}),(0,o.jsx)(n.td,{children:"Python Optimal Transport"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"hnswlib"})}),(0,o.jsx)(n.td,{children:"Fast k-NN search"})]})]})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Swift/Metal implementation:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Palette extraction (5 colors): < 50ms per photo\nSinkhorn EMD (5\xd75 palettes, \u03b5=0.1): < 5ms\nMS-SWD (100 projections, 3 scales): < 20ms\nMMR selection (1000 candidates, k=100): < 500ms\nGlobal color grading (1000\xd71000 image): < 100ms\nFull collage assembly (100 photos): < 10 seconds\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"gpu-acceleration-metal-shaders",children:"GPU Acceleration (Metal Shaders)"}),"\n",(0,o.jsx)(n.h3,{id:"compute-emd-in-parallel-cost-matrix",children:"Compute EMD in Parallel (Cost Matrix)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-metal",children:"kernel void compute_cost_matrix(\n    constant float3 *palette1 [[buffer(0)]],\n    constant float3 *palette2 [[buffer(1)]],\n    device float *cost_matrix [[buffer(2)]],\n    uint2 gid [[thread_position_in_grid]]\n) {\n    uint i = gid.x;\n    uint j = gid.y;\n\n    // CIEDE2000 distance (simplified)\n    float3 c1 = palette1[i];\n    float3 c2 = palette2[j];\n\n    float dL = c1.x - c2.x;\n    float da = c1.y - c2.y;\n    float db = c1.z - c2.z;\n\n    float delta_e = sqrt(dL*dL + da*da + db*db);\n    cost_matrix[i * palette2_size + j] = delta_e * delta_e;\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"sinkhorn-iterations-on-gpu",children:"Sinkhorn Iterations on GPU"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-metal",children:"kernel void sinkhorn_iteration_u(\n    constant float *K [[buffer(0)]],\n    constant float *v [[buffer(1)]],\n    constant float *a [[buffer(2)]],\n    device float *u [[buffer(3)]],\n    uint i [[thread_position_in_grid]]\n) {\n    // u[i] = a[i] / (K[i, :] @ v)\n    float sum = 0.0;\n    for (uint j = 0; j < v_size; j++) {\n        sum += K[i * v_size + j] * v[j];\n    }\n    u[i] = a[i] / sum;\n}\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"caching",children:"Caching"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class PaletteCache:\n    """Cache extracted palettes to avoid recomputation."""\n\n    def __init__(self):\n        self.cache = {}  # photo_id -> palette_LAB\n\n    def get_or_extract(self, photo_id, image):\n        if photo_id not in self.cache:\n            self.cache[photo_id] = extract_palette(image)\n        return self.cache[photo_id]\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"common-patterns",children:"Common Patterns"}),"\n",(0,o.jsx)(n.h3,{id:"pattern-1-progressive-color-matching",children:"Pattern 1: Progressive Color Matching"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Start with dominant color match, refine with full palette\ndef find_matches_progressive(query_palette, candidates, k=20):\n    # Stage 1: Filter by dominant color (fast)\n    dom_matches = [c for c in candidates\n                   if ciede2000(query_palette[0], c.palette[0]) < 30]\n\n    # Stage 2: Full EMD on remaining (slower)\n    scored = [(sinkhorn_emd(query_palette, c.palette), c)\n              for c in dom_matches]\n    scored.sort()\n\n    return [c for _, c in scored[:k]]\n"})}),"\n",(0,o.jsx)(n.h3,{id:"pattern-2-hierarchical-palette-matching",children:"Pattern 2: Hierarchical Palette Matching"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Cluster photos by dominant hue, search within cluster first\ndef cluster_photos_by_hue(photos):\n    hues = [dominant_hue(palette) for _, palette in photos]\n\n    # K-means clustering in circular hue space\n    from sklearn.cluster import KMeans\n\n    # Convert hue angles to 2D points on unit circle\n    hue_points = np.array([[np.cos(np.radians(h)), np.sin(np.radians(h))]\n                           for h in hues])\n\n    kmeans = KMeans(n_clusters=12, random_state=42)  # 12 = clock positions\n    labels = kmeans.fit_predict(hue_points)\n\n    # Group photos by cluster\n    clusters = {}\n    for (photo_id, palette), label in zip(photos, labels):\n        clusters.setdefault(label, []).append((photo_id, palette))\n\n    return clusters\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"advanced-techniques",children:"Advanced Techniques"}),"\n",(0,o.jsx)(n.h3,{id:"dynamic-palette-evolution",children:"Dynamic Palette Evolution"}),"\n",(0,o.jsx)(n.p,{children:"Track global palette as collage grows, adjust target:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"global_palette = seed_palette.copy()\n\nfor iteration in range(n_photos):\n    # Select next photo matching current global palette\n    next_photo = select_best_match(global_palette, candidates, diversity_lambda)\n\n    # Update global palette (exponential moving average)\n    alpha = 0.1  # Learning rate\n    global_palette = (1 - alpha) * global_palette + alpha * next_photo.palette\n"})}),"\n",(0,o.jsx)(n.h3,{id:"color-mood-transfer",children:"Color Mood Transfer"}),"\n",(0,o.jsx)(n.p,{children:"Given a reference artwork, extract mood and apply:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"def extract_color_mood(reference_image):\n    \"\"\"Extract color mood from reference (e.g., Rothko painting).\"\"\"\n    palette = extract_palette(reference_image, n_colors=5)\n    palette_lch = lab_to_lch(palette)\n\n    avg_L = np.mean([L for L, C, H, w in palette_lch])\n    avg_C = np.mean([C for L, C, H, w in palette_lch])\n    hue_variance = np.var([H for L, C, H, w in palette_lch])\n\n    return {\n        'target_palette': palette,\n        'lightness': avg_L,\n        'saturation': avg_C,\n        'hue_diversity': hue_variance\n    }\n\ndef apply_mood_to_collage(photos, mood):\n    \"\"\"Select and grade photos to match mood.\"\"\"\n    # Select photos with similar lightness/saturation\n    filtered = [p for p in photos\n                if abs(avg_lightness(p.palette) - mood['lightness']) < 20\n                and abs(avg_chroma(p.palette) - mood['saturation']) < 20]\n\n    # Apply color grading to match target palette\n    for photo in filtered:\n        M, b = compute_affine_color_transform(photo.palette, mood['target_palette'])\n        photo.image = apply_affine_color_transform(photo.image, M, b)\n\n    return filtered\n"})}),"\n",(0,o.jsx)(n.h3,{id:"color-constancy-correction",children:"Color Constancy Correction"}),"\n",(0,o.jsx)(n.p,{children:"Photos from different cameras/lighting have different white balance. Normalize:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def normalize_white_balance(image):\n    """Estimate and correct white balance using gray world assumption."""\n    # Convert to LAB\n    lab = rgb_to_lab(image)\n\n    # Compute mean a, b (should be ~0 for neutral)\n    mean_a = np.mean(lab[:, :, 1])\n    mean_b = np.mean(lab[:, :, 2])\n\n    # Subtract mean (shift to neutral)\n    lab[:, :, 1] -= mean_a\n    lab[:, :, 2] -= mean_b\n\n    return lab_to_rgb(lab)\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,o.jsx)(n.h3,{id:"issue-emd-too-slow-for-large-palettes",children:"Issue: EMD too slow for large palettes"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution:"})," Use Multiscale Sliced Wasserstein instead of Sinkhorn for O(M log M) complexity."]}),"\n",(0,o.jsx)(n.h3,{id:"issue-photos-look-washed-out-after-color-grading",children:"Issue: Photos look washed out after color grading"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution:"})," Reduce alpha blend strength or add chroma boost:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"graded_image[:, :, 1:] *= 1.1  # Boost a, b channels by 10%\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:'Peyr\xe9, G., & Cuturi, M. (2019). "Computational Optimal Transport."'}),"\n",(0,o.jsx)(n.li,{children:'Sharma, G., et al. (2005). "The CIEDE2000 color-difference formula."'}),"\n",(0,o.jsx)(n.li,{children:'"Multiscale Sliced Wasserstein Distances" (ECCV 2024)'}),"\n",(0,o.jsx)(n.li,{children:'Kulesza, A., & Taskar, B. (2012). "Determinantal Point Processes for Machine Learning."'}),"\n",(0,o.jsx)(n.li,{children:'Itten, J. (1970). "The Elements of Color."'}),"\n",(0,o.jsx)(n.li,{children:'Fairchild, M. D. (2013). "Color Appearance Models" (3rd ed.).'}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);