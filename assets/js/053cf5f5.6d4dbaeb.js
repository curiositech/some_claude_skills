"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[22160],{28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(96540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}},34547:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"skills/skill_logger/references/scoring-rubric","title":"Skill Scoring Rubric","description":"Overview","source":"@site/docs/skills/skill_logger/references/scoring-rubric.md","sourceDirName":"skills/skill_logger/references","slug":"/skills/skill_logger/references/scoring-rubric","permalink":"/docs/skills/skill_logger/references/scoring-rubric","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Skill Scoring Rubric","sidebar_label":"Skill Scoring Rubric","sidebar_position":1}}');var s=i(74848),o=i(28453);const r={title:"Skill Scoring Rubric",sidebar_label:"Skill Scoring Rubric",sidebar_position:1},a="Skill Scoring Rubric",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Multi-Dimensional Scoring Model",id:"multi-dimensional-scoring-model",level:2},{value:"Score Components",id:"score-components",level:3},{value:"Component Breakdown",id:"component-breakdown",level:2},{value:"1. Completion Score (25 points max)",id:"1-completion-score-25-points-max",level:3},{value:"2. Efficiency Score (20 points max)",id:"2-efficiency-score-20-points-max",level:3},{value:"3. Output Quality Score (30 points max)",id:"3-output-quality-score-30-points-max",level:3},{value:"4. User Satisfaction Score (25 points max)",id:"4-user-satisfaction-score-25-points-max",level:3},{value:"Score Interpretation",id:"score-interpretation",level:2},{value:"Quality Tiers",id:"quality-tiers",level:3},{value:"Trend Analysis",id:"trend-analysis",level:3},{value:"Automated Quality Gates",id:"automated-quality-gates",level:2},{value:"Dashboard Queries",id:"dashboard-queries",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"skill-scoring-rubric",children:"Skill Scoring Rubric"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This rubric defines how skill invocations are scored for quality, enabling data-driven improvement of the skill ecosystem."}),"\n",(0,s.jsx)(n.h2,{id:"multi-dimensional-scoring-model",children:"Multi-Dimensional Scoring Model"}),"\n",(0,s.jsx)(n.h3,{id:"score-components",children:"Score Components"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SKILL QUALITY SCORE (0-100)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  COMPLETION (25%)        EFFICIENCY (20%)                        \u2502\n\u2502  \u251c\u2500 Task completed?      \u251c\u2500 Token economy                       \u2502\n\u2502  \u251c\u2500 No errors?           \u251c\u2500 Tool call efficiency                \u2502\n\u2502  \u2514\u2500 Graceful recovery?   \u2514\u2500 Response time                       \u2502\n\u2502                                                                  \u2502\n\u2502  OUTPUT QUALITY (30%)    USER SATISFACTION (25%)                 \u2502\n\u2502  \u251c\u2500 Accuracy             \u251c\u2500 Accepted without edits?             \u2502\n\u2502  \u251c\u2500 Completeness         \u251c\u2500 Follow-up needed?                   \u2502\n\u2502  \u2514\u2500 Code quality (if applicable) \u2514\u2500 Explicit feedback           \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"component-breakdown",children:"Component Breakdown"}),"\n",(0,s.jsx)(n.h3,{id:"1-completion-score-25-points-max",children:"1. Completion Score (25 points max)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Outcome"}),(0,s.jsx)(n.th,{children:"Points"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Full completion, no errors"}),(0,s.jsx)(n.td,{children:"25"}),(0,s.jsx)(n.td,{children:"Task completed exactly as requested"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Completion with recovery"}),(0,s.jsx)(n.td,{children:"20"}),(0,s.jsx)(n.td,{children:"Hit error but recovered gracefully"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Partial completion"}),(0,s.jsx)(n.td,{children:"15"}),(0,s.jsx)(n.td,{children:"Some of the task accomplished"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Completion with workaround"}),(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"Achieved goal via alternative path"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Failed but informative"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"Couldn't complete but explained why"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Hard failure"}),(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"Crashed, hung, or produced nothing"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def score_completion(invocation: dict) -> int:\n    \"\"\"Score task completion (0-25 points).\"\"\"\n\n    errors = invocation.get('errors', [])\n    recovered = invocation.get('recovered', False)\n    partial = invocation.get('partial_completion', False)\n\n    if not errors:\n        return 25  # Perfect completion\n\n    if recovered:\n        return 20  # Recovered from error\n\n    if partial:\n        return 15  # Partial completion\n\n    if invocation.get('workaround_used'):\n        return 10  # Alternative path\n\n    if invocation.get('failure_explained'):\n        return 5   # At least explained the issue\n\n    return 0  # Hard failure\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-efficiency-score-20-points-max",children:"2. Efficiency Score (20 points max)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Max Points"}),(0,s.jsx)(n.th,{children:"Calculation"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Token efficiency"}),(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"8 * min(1, baseline_tokens / actual_tokens)"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Tool call efficiency"}),(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"6 * min(1, baseline_calls / actual_calls)"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Response time"}),(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"6 * min(1, baseline_time / actual_time)"})})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Baseline values by skill category\nEFFICIENCY_BASELINES = {\n    'code_generation': {\n        'tokens_per_loc': 50,      # Tokens per line of code generated\n        'calls_per_file': 3,       # Tool calls per file modified\n        'time_per_task': 30_000,   # Milliseconds per typical task\n    },\n    'analysis': {\n        'tokens_per_insight': 200,\n        'calls_per_analysis': 5,\n        'time_per_task': 20_000,\n    },\n    'design': {\n        'tokens_per_component': 150,\n        'calls_per_design': 4,\n        'time_per_task': 45_000,\n    },\n    'research': {\n        'tokens_per_finding': 100,\n        'calls_per_search': 8,\n        'time_per_task': 60_000,\n    },\n}\n\ndef score_efficiency(invocation: dict, skill_category: str) -> int:\n    \"\"\"Score efficiency (0-20 points).\"\"\"\n\n    baselines = EFFICIENCY_BASELINES.get(skill_category, EFFICIENCY_BASELINES['analysis'])\n\n    # Token efficiency (0-8 points)\n    actual_tokens = invocation['tokens_used']\n    output_size = invocation.get('output_size', 1)  # LOC, components, etc.\n    expected_tokens = baselines['tokens_per_loc'] * output_size\n    token_score = 8 * min(1.0, expected_tokens / max(actual_tokens, 1))\n\n    # Tool call efficiency (0-6 points)\n    actual_calls = len(invocation.get('tool_calls', []))\n    expected_calls = baselines['calls_per_file'] * invocation.get('files_changed', 1)\n    call_score = 6 * min(1.0, expected_calls / max(actual_calls, 1))\n\n    # Response time (0-6 points)\n    actual_time = invocation['duration_ms']\n    expected_time = baselines['time_per_task']\n    time_score = 6 * min(1.0, expected_time / max(actual_time, 1))\n\n    return int(token_score + call_score + time_score)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"3-output-quality-score-30-points-max",children:"3. Output Quality Score (30 points max)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Max Points"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Accuracy"}),(0,s.jsx)(n.td,{children:"12"}),(0,s.jsx)(n.td,{children:"Output is correct and appropriate"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Completeness"}),(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"All aspects of request addressed"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Code quality"}),(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:"Clean, idiomatic, no obvious bugs"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def score_output_quality(invocation: dict, feedback: dict = None) -> int:\n    \"\"\"Score output quality (0-30 points).\"\"\"\n\n    total = 0\n\n    # Accuracy (0-12 points)\n    if feedback:\n        # Direct user feedback\n        if feedback.get('accurate') == True:\n            total += 12\n        elif feedback.get('mostly_accurate'):\n            total += 9\n        elif feedback.get('partially_accurate'):\n            total += 6\n    else:\n        # Heuristic scoring\n        if invocation.get('output_validated'):\n            total += 12\n        elif not invocation.get('errors'):\n            total += 8  # Assume reasonable accuracy if no errors\n\n    # Completeness (0-10 points)\n    requested_items = invocation.get('requested_items', 1)\n    delivered_items = invocation.get('delivered_items', 1)\n    completeness_ratio = delivered_items / max(requested_items, 1)\n    total += int(10 * min(1.0, completeness_ratio))\n\n    # Code quality (0-8 points) - if applicable\n    if invocation.get('output_type') == 'code':\n        quality_signals = invocation.get('code_quality', {})\n\n        # Linter passed\n        if quality_signals.get('linter_passed', True):\n            total += 3\n\n        # Type safe\n        if quality_signals.get('types_valid', True):\n            total += 2\n\n        # Tests pass (if tests were run)\n        if quality_signals.get('tests_passed'):\n            total += 3\n    else:\n        total += 8  # Full points for non-code output\n\n    return total\n"})}),"\n",(0,s.jsx)(n.h3,{id:"4-user-satisfaction-score-25-points-max",children:"4. User Satisfaction Score (25 points max)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Signal"}),(0,s.jsx)(n.th,{children:"Max Points"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Accepted as-is"}),(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"User used output without modification"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Edit ratio"}),(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"8 * (1 - edit_ratio)"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"No follow-up"}),(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"User didn't need to ask for fixes"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def score_user_satisfaction(invocation: dict, follow_ups: list = None) -> int:\n    \"\"\"Score user satisfaction (0-25 points).\"\"\"\n\n    total = 0\n\n    # Accepted without changes (0-10 points)\n    if invocation.get('user_accepted'):\n        if invocation.get('user_edit_ratio', 0) < 0.05:\n            total += 10  # Accepted as-is\n        else:\n            total += 7   # Accepted with minor edits\n    elif invocation.get('user_used_output'):\n        total += 5       # Used but modified\n\n    # Edit ratio (0-8 points)\n    edit_ratio = invocation.get('user_edit_ratio', 0.5)\n    total += int(8 * (1 - min(edit_ratio, 1.0)))\n\n    # No follow-up needed (0-7 points)\n    if follow_ups is None or len(follow_ups) == 0:\n        total += 7\n    elif len(follow_ups) == 1:\n        total += 4  # One clarifying question is okay\n    elif all(f.get('resolved') for f in follow_ups):\n        total += 2  # Follow-ups were resolved\n\n    return total\n"})}),"\n",(0,s.jsx)(n.h2,{id:"score-interpretation",children:"Score Interpretation"}),"\n",(0,s.jsx)(n.h3,{id:"quality-tiers",children:"Quality Tiers"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Score Range"}),(0,s.jsx)(n.th,{children:"Tier"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Action"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"90-100"}),(0,s.jsx)(n.td,{children:"Excellent"}),(0,s.jsx)(n.td,{children:"Exceptional performance"}),(0,s.jsx)(n.td,{children:"Document as exemplar"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"75-89"}),(0,s.jsx)(n.td,{children:"Good"}),(0,s.jsx)(n.td,{children:"Meets expectations"}),(0,s.jsx)(n.td,{children:"Monitor for consistency"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"60-74"}),(0,s.jsx)(n.td,{children:"Acceptable"}),(0,s.jsx)(n.td,{children:"Room for improvement"}),(0,s.jsx)(n.td,{children:"Review for patterns"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"40-59"}),(0,s.jsx)(n.td,{children:"Below Average"}),(0,s.jsx)(n.td,{children:"Significant issues"}),(0,s.jsx)(n.td,{children:"Prioritize improvements"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"20-39"}),(0,s.jsx)(n.td,{children:"Poor"}),(0,s.jsx)(n.td,{children:"Major problems"}),(0,s.jsx)(n.td,{children:"Immediate attention needed"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0-19"}),(0,s.jsx)(n.td,{children:"Failing"}),(0,s.jsx)(n.td,{children:"Critical failure"}),(0,s.jsx)(n.td,{children:"Investigate root cause"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"trend-analysis",children:"Trend Analysis"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def analyze_skill_trends(skill_name: str, days: int = 30) -> dict:\n    \"\"\"Analyze quality trends for a skill.\"\"\"\n\n    # Get recent invocations\n    invocations = get_invocations(skill_name, days=days)\n\n    if len(invocations) < 10:\n        return {'status': 'insufficient_data'}\n\n    # Calculate rolling averages\n    scores = [inv['quality_score'] for inv in invocations]\n    recent_avg = np.mean(scores[-7:])    # Last week\n    previous_avg = np.mean(scores[:-7])  # Before that\n\n    # Trend detection\n    trend = 'stable'\n    change_pct = (recent_avg - previous_avg) / max(previous_avg, 1) * 100\n\n    if change_pct > 10:\n        trend = 'improving'\n    elif change_pct < -10:\n        trend = 'declining'\n\n    # Identify weak components\n    component_avgs = {\n        'completion': np.mean([inv['scores']['completion'] for inv in invocations]),\n        'efficiency': np.mean([inv['scores']['efficiency'] for inv in invocations]),\n        'quality': np.mean([inv['scores']['quality'] for inv in invocations]),\n        'satisfaction': np.mean([inv['scores']['satisfaction'] for inv in invocations]),\n    }\n\n    weak_component = min(component_avgs, key=lambda k: component_avgs[k] / COMPONENT_MAX[k])\n\n    return {\n        'current_avg': recent_avg,\n        'previous_avg': previous_avg,\n        'trend': trend,\n        'change_percent': change_pct,\n        'weak_component': weak_component,\n        'component_scores': component_avgs,\n        'recommendation': get_improvement_recommendation(weak_component, component_avgs[weak_component])\n    }\n\ndef get_improvement_recommendation(component: str, score: float) -> str:\n    \"\"\"Get specific improvement recommendation based on weak component.\"\"\"\n\n    recommendations = {\n        'completion': {\n            'low': 'Add more error handling and recovery patterns to SKILL.md',\n            'medium': 'Review common failure cases and add guidance',\n        },\n        'efficiency': {\n            'low': 'Reduce context size, consider progressive disclosure',\n            'medium': 'Optimize tool call patterns, reduce unnecessary reads',\n        },\n        'quality': {\n            'low': 'Add more examples and anti-patterns to skill',\n            'medium': 'Include validation steps in skill workflow',\n        },\n        'satisfaction': {\n            'low': 'Gather user feedback, analyze edit patterns',\n            'medium': 'Add clarifying questions to skill workflow',\n        },\n    }\n\n    level = 'low' if score < 50 else 'medium'\n    return recommendations.get(component, {}).get(level, 'Review skill performance')\n"})}),"\n",(0,s.jsx)(n.h2,{id:"automated-quality-gates",children:"Automated Quality Gates"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"QUALITY_GATES = {\n    'publish': {\n        'min_score': 70,\n        'min_invocations': 10,\n        'max_error_rate': 0.1,\n        'description': 'Minimum requirements to publish a skill'\n    },\n    'feature': {\n        'min_score': 85,\n        'min_invocations': 50,\n        'max_error_rate': 0.05,\n        'description': 'Requirements to be featured in showcase'\n    },\n    'deprecation': {\n        'max_score': 40,\n        'min_invocations': 20,\n        'max_age_without_improvement': 90,\n        'description': 'Triggers deprecation review'\n    }\n}\n\ndef check_quality_gate(skill_name: str, gate: str) -> dict:\n    \"\"\"Check if skill passes a quality gate.\"\"\"\n\n    gate_config = QUALITY_GATES[gate]\n    stats = get_skill_stats(skill_name)\n\n    passed = True\n    failures = []\n\n    if stats['avg_score'] < gate_config.get('min_score', 0):\n        passed = False\n        failures.append(f\"Score {stats['avg_score']:.1f} < {gate_config['min_score']}\")\n\n    if stats['invocation_count'] < gate_config.get('min_invocations', 0):\n        passed = False\n        failures.append(f\"Invocations {stats['invocation_count']} < {gate_config['min_invocations']}\")\n\n    if stats['error_rate'] > gate_config.get('max_error_rate', 1.0):\n        passed = False\n        failures.append(f\"Error rate {stats['error_rate']:.2%} > {gate_config['max_error_rate']:.2%}\")\n\n    return {\n        'gate': gate,\n        'passed': passed,\n        'failures': failures,\n        'stats': stats\n    }\n"})}),"\n",(0,s.jsx)(n.h2,{id:"dashboard-queries",children:"Dashboard Queries"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Skill leaderboard\nSELECT\n    skill_name,\n    COUNT(*) as uses,\n    AVG(quality_score) as avg_score,\n    AVG(completion_score) as avg_completion,\n    AVG(efficiency_score) as avg_efficiency,\n    AVG(quality_score_component) as avg_quality,\n    AVG(satisfaction_score) as avg_satisfaction\nFROM skill_invocations\nWHERE timestamp > datetime('now', '-30 days')\nGROUP BY skill_name\nHAVING uses >= 5\nORDER BY avg_score DESC;\n\n-- Quality distribution\nSELECT\n    skill_name,\n    CASE\n        WHEN quality_score >= 90 THEN 'Excellent'\n        WHEN quality_score >= 75 THEN 'Good'\n        WHEN quality_score >= 60 THEN 'Acceptable'\n        WHEN quality_score >= 40 THEN 'Below Average'\n        ELSE 'Poor'\n    END as tier,\n    COUNT(*) as count\nFROM skill_invocations\nWHERE timestamp > datetime('now', '-30 days')\nGROUP BY skill_name, tier;\n\n-- Improvement opportunities\nSELECT\n    skill_name,\n    'completion' as weak_area,\n    AVG(completion_score) / 25.0 as normalized_score\nFROM skill_invocations\nWHERE timestamp > datetime('now', '-30 days')\nGROUP BY skill_name\nHAVING normalized_score < 0.7\n\nUNION ALL\n\nSELECT\n    skill_name,\n    'efficiency' as weak_area,\n    AVG(efficiency_score) / 20.0 as normalized_score\nFROM skill_invocations\nWHERE timestamp > datetime('now', '-30 days')\nGROUP BY skill_name\nHAVING normalized_score < 0.7\n\nORDER BY normalized_score ASC;\n"})})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);