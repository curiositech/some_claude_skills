"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[72842],{16430:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>c,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"skills/computer_vision_pipeline/references/video-processing","title":"Video Processing for Computer Vision","description":"Efficient video frame extraction, preprocessing, and scene detection for object detection pipelines.","source":"@site/docs/skills/computer_vision_pipeline/references/video-processing.md","sourceDirName":"skills/computer_vision_pipeline/references","slug":"/skills/computer_vision_pipeline/references/video-processing","permalink":"/docs/skills/computer_vision_pipeline/references/video-processing","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Video Processing for Computer Vision","sidebar_label":"Video Processing for Comput...","sidebar_position":2}}');var r=i(74848),t=i(28453);const c={title:"Video Processing for Computer Vision",sidebar_label:"Video Processing for Comput...",sidebar_position:2},l="Video Processing for Computer Vision",a={},d=[{value:"Frame Extraction with FFmpeg",id:"frame-extraction-with-ffmpeg",level:2},{value:"Basic Frame Extraction",id:"basic-frame-extraction",level:3},{value:"Resolution and Aspect Ratio",id:"resolution-and-aspect-ratio",level:3},{value:"Scene Change Detection",id:"scene-change-detection",level:2},{value:"FFmpeg Scene Detection",id:"ffmpeg-scene-detection",level:3},{value:"Python Scene Detection with OpenCV",id:"python-scene-detection-with-opencv",level:3},{value:"Advanced: Structural Similarity (SSIM)",id:"advanced-structural-similarity-ssim",level:3},{value:"Memory-Efficient Streaming",id:"memory-efficient-streaming",level:2},{value:"Problem: Loading Entire Video",id:"problem-loading-entire-video",level:3},{value:"Solution: Batch Processing",id:"solution-batch-processing",level:3},{value:"Video Codec Optimization",id:"video-codec-optimization",level:2},{value:"Choosing the Right Codec",id:"choosing-the-right-codec",level:3},{value:"Re-encoding for Speed",id:"re-encoding-for-speed",level:3},{value:"Preprocessing Pipeline",id:"preprocessing-pipeline",level:2},{value:"Complete Pipeline",id:"complete-pipeline",level:3},{value:"FFmpeg Advanced Filters",id:"ffmpeg-advanced-filters",level:2},{value:"Multi-Stage Filtering",id:"multi-stage-filtering",level:3},{value:"Extracting Specific Time Ranges",id:"extracting-specific-time-ranges",level:3},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"Frame Extraction Speed",id:"frame-extraction-speed",level:3},{value:"Scene Detection Performance",id:"scene-detection-performance",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Common Pitfalls",id:"common-pitfalls",level:2},{value:"Pitfall 1: Extracting Every Frame",id:"pitfall-1-extracting-every-frame",level:3},{value:"Pitfall 2: Not Preprocessing",id:"pitfall-2-not-preprocessing",level:3},{value:"Pitfall 3: Poor Quality Settings",id:"pitfall-3-poor-quality-settings",level:3},{value:"Resources",id:"resources",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"video-processing-for-computer-vision",children:"Video Processing for Computer Vision"})}),"\n",(0,r.jsx)(n.p,{children:"Efficient video frame extraction, preprocessing, and scene detection for object detection pipelines."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"frame-extraction-with-ffmpeg",children:"Frame Extraction with FFmpeg"}),"\n",(0,r.jsx)(n.h3,{id:"basic-frame-extraction",children:"Basic Frame Extraction"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Extract every 30th frame (1 FPS for 30 FPS video)\nffmpeg -i video.mp4 -vf \"select='not(mod(n\\,30))'\" -vsync vfr frames/frame_%06d.jpg\n\n# Extract at specific FPS\nffmpeg -i video.mp4 -vf fps=1 frames/frame_%06d.jpg\n\n# Extract with quality control\nffmpeg -i video.mp4 -vf fps=1 -q:v 2 frames/frame_%06d.jpg\n# q:v range: 1 (best) to 31 (worst)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"resolution-and-aspect-ratio",children:"Resolution and Aspect Ratio"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Resize to 640x640 (for YOLO)\nffmpeg -i video.mp4 -vf "fps=1,scale=640:640:force_original_aspect_ratio=decrease,pad=640:640:(ow-iw)/2:(oh-ih)/2:color=gray" frames/frame_%06d.jpg\n\n# Maintain aspect ratio with padding\nffmpeg -i video.mp4 -vf "fps=1,scale=640:-1" frames/frame_%06d.jpg\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Explanation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"scale=640:640:force_original_aspect_ratio=decrease"})," - Shrink to fit within 640x640"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"pad=640:640:(ow-iw)/2:(oh-ih)/2"})," - Center padding to make square"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"color=gray"})," - Gray padding (114,114,114 matches YOLO default)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"scene-change-detection",children:"Scene Change Detection"}),"\n",(0,r.jsx)(n.h3,{id:"ffmpeg-scene-detection",children:"FFmpeg Scene Detection"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Extract keyframes only (scene changes)\nffmpeg -i video.mp4 -vf \"select='gt(scene,0.3)',showinfo\" -vsync vfr frames/scene_%06d.jpg\n\n# Adjust sensitivity (0.0 = all frames, 1.0 = major changes only)\nffmpeg -i video.mp4 -vf \"select='gt(scene,0.4)'\" -vsync vfr frames/scene_%06d.jpg\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scene threshold guide"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0.1"})," - Very sensitive (every small change)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0.3"})," - Moderate (good for drone footage)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0.5"})," - Conservative (only major scene changes)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"python-scene-detection-with-opencv",children:"Python Scene Detection with OpenCV"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\nfrom typing import List, Tuple\n\ndef detect_scene_changes(\n    video_path: str,\n    threshold: float = 0.3,\n    min_frame_gap: int = 10\n) -> List[int]:\n    """\n    Detect scene changes using histogram comparison\n\n    Args:\n        video_path: Path to video file\n        threshold: Scene change threshold (0.0-1.0)\n        min_frame_gap: Minimum frames between scene changes\n\n    Returns:\n        List of frame numbers where scenes change\n    """\n    video = cv2.VideoCapture(video_path)\n\n    scene_frames = []\n    prev_hist = None\n    frame_count = 0\n    last_scene_frame = -min_frame_gap\n\n    while True:\n        ret, frame = video.read()\n        if not ret:\n            break\n\n        # Convert to grayscale\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n        # Calculate histogram\n        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n        cv2.normalize(hist, hist)\n\n        if prev_hist is not None:\n            # Compare histograms\n            correlation = cv2.compareHist(\n                prev_hist,\n                hist,\n                cv2.HISTCMP_CORREL\n            )\n\n            # Scene change detected\n            if correlation < (1 - threshold):\n                # Respect minimum gap\n                if frame_count - last_scene_frame >= min_frame_gap:\n                    scene_frames.append(frame_count)\n                    last_scene_frame = frame_count\n\n        prev_hist = hist\n        frame_count += 1\n\n    video.release()\n    return scene_frames\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"advanced-structural-similarity-ssim",children:"Advanced: Structural Similarity (SSIM)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from skimage.metrics import structural_similarity as ssim\n\ndef detect_scenes_ssim(\n    video_path: str,\n    threshold: float = 0.7\n) -> List[int]:\n    """\n    Detect scene changes using SSIM\n\n    More accurate than histogram, but slower\n    """\n    video = cv2.VideoCapture(video_path)\n\n    scene_frames = []\n    prev_frame = None\n    frame_count = 0\n\n    while True:\n        ret, frame = video.read()\n        if not ret:\n            break\n\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n        if prev_frame is not None:\n            # Calculate SSIM\n            score = ssim(prev_frame, gray)\n\n            # Low SSIM = scene change\n            if score < threshold:\n                scene_frames.append(frame_count)\n\n        prev_frame = gray\n        frame_count += 1\n\n    video.release()\n    return scene_frames\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"SSIM vs Histogram"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Histogram"}),": Fast (200 FPS), good for gross changes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SSIM"}),": Slower (50 FPS), better for subtle changes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use histogram"})," for drone footage, wildlife"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use SSIM"})," for indoor scenes, dialogue cuts"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"memory-efficient-streaming",children:"Memory-Efficient Streaming"}),"\n",(0,r.jsx)(n.h3,{id:"problem-loading-entire-video",children:"Problem: Loading Entire Video"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# \u274c WRONG: Loads entire video into memory\nvideo = cv2.VideoCapture('large_video.mp4')\nframes = []\nwhile True:\n    ret, frame = video.read()\n    if not ret:\n        break\n    frames.append(frame)  # 4K frame = 32 MB!\n\n# 30 seconds of 4K @ 30 FPS = 28 GB RAM\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"solution-batch-processing",children:"Solution: Batch Processing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# \u2705 CORRECT: Process in batches\ndef process_video_batched(\n    video_path: str,\n    model,\n    batch_size: int = 16,\n    sample_rate: int = 30\n):\n    """Process video in batches to limit memory usage"""\n    video = cv2.VideoCapture(video_path)\n\n    batch = []\n    frame_count = 0\n\n    while True:\n        ret, frame = video.read()\n        if not ret:\n            # Process final batch\n            if batch:\n                yield model(batch)\n            break\n\n        frame_count += 1\n\n        # Sample frames\n        if frame_count % sample_rate != 0:\n            continue\n\n        # Preprocess\n        processed = preprocess_frame(frame)\n        batch.append(processed)\n\n        # Process batch when full\n        if len(batch) >= batch_size:\n            results = model(batch)\n            yield results\n            batch = []  # Clear memory\n\n    video.release()\n\n# Usage\nfor batch_results in process_video_batched(\'video.mp4\', yolo_model):\n    # Process results immediately\n    save_results(batch_results)\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Memory savings"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Batch of 16 frames @ 640x640 = 31 MB"}),"\n",(0,r.jsx)(n.li,{children:"vs 900 frames @ 4K = 28 GB"}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"900x less memory"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"video-codec-optimization",children:"Video Codec Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"choosing-the-right-codec",children:"Choosing the Right Codec"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Codec"}),(0,r.jsx)(n.th,{children:"Speed"}),(0,r.jsx)(n.th,{children:"Size"}),(0,r.jsx)(n.th,{children:"Quality"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"H.264"}),(0,r.jsx)(n.td,{children:"Fast"}),(0,r.jsx)(n.td,{children:"Small"}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"General purpose"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"H.265"}),(0,r.jsx)(n.td,{children:"Slow"}),(0,r.jsx)(n.td,{children:"Smaller"}),(0,r.jsx)(n.td,{children:"Better"}),(0,r.jsx)(n.td,{children:"High quality, storage"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"VP9"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Small"}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"Web delivery"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ProRes"}),(0,r.jsx)(n.td,{children:"Very Fast"}),(0,r.jsx)(n.td,{children:"Large"}),(0,r.jsx)(n.td,{children:"Excellent"}),(0,r.jsx)(n.td,{children:"Editing, CV processing"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For CV pipelines"}),": Use ",(0,r.jsx)(n.strong,{children:"H.264"})," for storage, ",(0,r.jsx)(n.strong,{children:"extract frames"})," for processing"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"re-encoding-for-speed",children:"Re-encoding for Speed"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Re-encode to H.264 for faster seeking\nffmpeg -i input.mp4 -c:v libx264 -preset ultrafast -crf 23 output.mp4\n\n# Preset options:\n# - ultrafast: Fastest encoding, larger files\n# - fast: Good balance\n# - medium: Default\n# - slow: Better compression\n\n# CRF (quality):\n# - 0: Lossless (huge files)\n# - 18-23: High quality (visually lossless)\n# - 28: Acceptable quality\n# - 51: Worst quality\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"preprocessing-pipeline",children:"Preprocessing Pipeline"}),"\n",(0,r.jsx)(n.h3,{id:"complete-pipeline",children:"Complete Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\n\nclass VideoPreprocessor:\n    """Complete preprocessing pipeline for CV"""\n\n    def __init__(\n        self,\n        target_size: int = 640,\n        normalize: bool = True,\n        enhance_contrast: bool = False\n    ):\n        self.target_size = target_size\n        self.normalize = normalize\n        self.enhance_contrast = enhance_contrast\n\n    def preprocess_frame(self, frame: np.ndarray) -> np.ndarray:\n        """\n        Full preprocessing pipeline\n\n        1. Resize to target size\n        2. Pad to square\n        3. Enhance contrast (optional)\n        4. Normalize (optional)\n        """\n        # 1. Resize\n        h, w = frame.shape[:2]\n        scale = self.target_size / max(h, w)\n        new_w, new_h = int(w * scale), int(h * scale)\n\n        resized = cv2.resize(\n            frame,\n            (new_w, new_h),\n            interpolation=cv2.INTER_LINEAR\n        )\n\n        # 2. Pad to square\n        pad_w = (self.target_size - new_w) // 2\n        pad_h = (self.target_size - new_h) // 2\n\n        padded = cv2.copyMakeBorder(\n            resized,\n            pad_h, self.target_size - new_h - pad_h,\n            pad_w, self.target_size - new_w - pad_w,\n            cv2.BORDER_CONSTANT,\n            value=(114, 114, 114)  # Gray padding\n        )\n\n        # 3. Enhance contrast (optional)\n        if self.enhance_contrast:\n            lab = cv2.cvtColor(padded, cv2.COLOR_BGR2LAB)\n            l, a, b = cv2.split(lab)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            l = clahe.apply(l)\n            padded = cv2.merge([l, a, b])\n            padded = cv2.cvtColor(padded, cv2.COLOR_LAB2BGR)\n\n        # 4. Normalize (optional)\n        if self.normalize:\n            padded = padded.astype(np.float32) / 255.0\n\n        return padded\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"ffmpeg-advanced-filters",children:"FFmpeg Advanced Filters"}),"\n",(0,r.jsx)(n.h3,{id:"multi-stage-filtering",children:"Multi-Stage Filtering"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Extract, resize, denoise, and sharpen\nffmpeg -i video.mp4 \\\n  -vf "fps=1,scale=640:640:force_original_aspect_ratio=decrease,pad=640:640:(ow-iw)/2:(oh-ih)/2,hqdn3d=4:3:6:4.5,unsharp=5:5:1.0:5:5:0.0" \\\n  -q:v 2 \\\n  frames/frame_%06d.jpg\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Filter breakdown"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"fps=1"})," - 1 frame per second"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"scale=640:640:force_original_aspect_ratio=decrease"})," - Resize"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"pad=640:640:(ow-iw)/2:(oh-ih)/2"})," - Center padding"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"hqdn3d=4:3:6:4.5"})," - Denoise (luma:chroma:luma_temporal",":chroma_temporal",")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"unsharp=5:5:1.0:5:5:0.0"})," - Sharpen (luma only)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"extracting-specific-time-ranges",children:"Extracting Specific Time Ranges"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Extract frames from 1:30 to 2:00\nffmpeg -i video.mp4 -ss 00:01:30 -to 00:02:00 -vf fps=1 frames/frame_%06d.jpg\n\n# Extract frames starting at 5:00 for 30 seconds\nffmpeg -i video.mp4 -ss 00:05:00 -t 30 -vf fps=1 frames/frame_%06d.jpg\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,r.jsx)(n.h3,{id:"frame-extraction-speed",children:"Frame Extraction Speed"}),"\n",(0,r.jsx)(n.p,{children:"Tested on 10-minute 4K drone footage (30 FPS, 18,000 frames):"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Time"}),(0,r.jsx)(n.th,{children:"Frames"}),(0,r.jsx)(n.th,{children:"Throughput"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Python (cv2.VideoCapture)"}),(0,r.jsx)(n.td,{children:"45s"}),(0,r.jsx)(n.td,{children:"600"}),(0,r.jsx)(n.td,{children:"13 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FFmpeg (fps filter)"}),(0,r.jsx)(n.td,{children:"12s"}),(0,r.jsx)(n.td,{children:"600"}),(0,r.jsx)(n.td,{children:"50 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FFmpeg (select filter)"}),(0,r.jsx)(n.td,{children:"8s"}),(0,r.jsx)(n.td,{children:"600"}),(0,r.jsx)(n.td,{children:"75 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FFmpeg (scene detection)"}),(0,r.jsx)(n.td,{children:"22s"}),(0,r.jsx)(n.td,{children:"324"}),(0,r.jsx)(n.td,{children:"15 FPS"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Winner"}),": FFmpeg with select filter (6x faster than Python)"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"scene-detection-performance",children:"Scene Detection Performance"}),"\n",(0,r.jsx)(n.p,{children:"10-minute video, detecting scene changes:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Time"}),(0,r.jsx)(n.th,{children:"Scenes"}),(0,r.jsx)(n.th,{children:"Accuracy"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Histogram (OpenCV)"}),(0,r.jsx)(n.td,{children:"18s"}),(0,r.jsx)(n.td,{children:"67"}),(0,r.jsx)(n.td,{children:"Good"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SSIM (scikit-image)"}),(0,r.jsx)(n.td,{children:"98s"}),(0,r.jsx)(n.td,{children:"73"}),(0,r.jsx)(n.td,{children:"Excellent"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FFmpeg scene filter"}),(0,r.jsx)(n.td,{children:"22s"}),(0,r.jsx)(n.td,{children:"71"}),(0,r.jsx)(n.td,{children:"Very Good"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Winner"}),": FFmpeg scene filter (fast + accurate)"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Always sample frames"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:"fps=1"})," for general use"]}),"\n",(0,r.jsx)(n.li,{children:"Use scene detection for narrative content"}),"\n",(0,r.jsx)(n.li,{children:"Process every frame only for critical applications"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Resize before detection"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"YOLO expects 640x640"}),"\n",(0,r.jsx)(n.li,{children:"Resizing during extraction is 3x faster than after"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Use FFmpeg for extraction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"6x faster than Python"}),"\n",(0,r.jsx)(n.li,{children:"Better quality control"}),"\n",(0,r.jsx)(n.li,{children:"GPU acceleration available"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Batch process frames"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Load 16-32 frames at once"}),"\n",(0,r.jsx)(n.li,{children:"Process batch together"}),"\n",(0,r.jsx)(n.li,{children:"Clear memory between batches"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Choose codec wisely"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"H.264 for general use"}),"\n",(0,r.jsx)(n.li,{children:"ProRes for frame-accurate seeking"}),"\n",(0,r.jsx)(n.li,{children:"Avoid H.265 for extraction (slow to decode)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"common-pitfalls",children:"Common Pitfalls"}),"\n",(0,r.jsx)(n.h3,{id:"pitfall-1-extracting-every-frame",children:"Pitfall 1: Extracting Every Frame"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# \u274c WRONG: 18,000 frames for 10-minute video\nffmpeg -i video.mp4 frames/frame_%06d.jpg\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why it's wrong"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"18,000 inferences (slow, expensive)"}),"\n",(0,r.jsx)(n.li,{children:"Adjacent frames are nearly identical"}),"\n",(0,r.jsx)(n.li,{children:"Wasting GPU cycles on duplicate information"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# \u2705 CORRECT: 600 frames (97% reduction)\nffmpeg -i video.mp4 -vf fps=1 frames/frame_%06d.jpg\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"pitfall-2-not-preprocessing",children:"Pitfall 2: Not Preprocessing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# \u274c WRONG: Extract at original resolution\nffmpeg -i 4k_video.mp4 -vf fps=1 frames/frame_%06d.jpg\n# Then resize in Python (slow)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why it's wrong"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Large files (32 MB per 4K frame)"}),"\n",(0,r.jsx)(n.li,{children:"Slower I/O"}),"\n",(0,r.jsx)(n.li,{children:"Extra preprocessing step"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# \u2705 CORRECT: Resize during extraction\nffmpeg -i 4k_video.mp4 -vf "fps=1,scale=640:640:force_original_aspect_ratio=decrease,pad=640:640:(ow-iw)/2:(oh-ih)/2" frames/frame_%06d.jpg\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"pitfall-3-poor-quality-settings",children:"Pitfall 3: Poor Quality Settings"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# \u274c WRONG: Default quality (artifacts)\nffmpeg -i video.mp4 -vf fps=1 frames/frame_%06d.jpg\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why it's wrong"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"JPEG compression artifacts hurt detection accuracy"}),"\n",(0,r.jsx)(n.li,{children:"Default quality varies by FFmpeg version"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# \u2705 CORRECT: Explicit quality setting\nffmpeg -i video.mp4 -vf fps=1 -q:v 2 frames/frame_%06d.jpg\n# q:v 2 = very high quality\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://ffmpeg.org/ffmpeg-filters.html",children:"FFmpeg Filters Documentation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html",children:"OpenCV Video Processing"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://pyscenedetect.readthedocs.io/",children:"Scene Detection Library (PySceneDetect)"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>c,x:()=>l});var s=i(96540);const r={},t=s.createContext(r);function c(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);