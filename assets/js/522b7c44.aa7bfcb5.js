"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[33628],{15386:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"skills/collage_layout_expert/references/algorithms","title":"Core Collage Algorithms","description":"Mathematical and computational techniques for collage composition.","source":"@site/docs/skills/collage_layout_expert/references/algorithms.md","sourceDirName":"skills/collage_layout_expert/references","slug":"/skills/collage_layout_expert/references/algorithms","permalink":"/docs/skills/collage_layout_expert/references/algorithms","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Core Collage Algorithms","sidebar_label":"Core Collage Algorithms","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Advanced Collage Techniques","permalink":"/docs/skills/collage_layout_expert/references/advanced-techniques"},"next":{"title":"Art-Historical Collage Styles","permalink":"/docs/skills/collage_layout_expert/references/art-historical-styles"}}');var s=r(74848),t=r(28453);const o={title:"Core Collage Algorithms",sidebar_label:"Core Collage Algorithms",sidebar_position:2},a="Core Collage Algorithms",l={},c=[{value:"Edge-Based Assembly (Hockney/Joiners)",id:"edge-based-assembly-hockneyjoiners",level:2},{value:"Edge Extraction",id:"edge-extraction",level:3},{value:"Line Continuation Score",id:"line-continuation-score",level:3},{value:"Poisson Blending (Seamless Transitions)",id:"poisson-blending-seamless-transitions",level:2},{value:"When to Use Each Mode",id:"when-to-use-each-mode",level:3},{value:"Performance Notes",id:"performance-notes",level:3},{value:"Optimal Transport (Color Harmonization)",id:"optimal-transport-color-harmonization",level:2},{value:"Sinkhorn Algorithm (Full Optimal Transport)",id:"sinkhorn-algorithm-full-optimal-transport",level:3},{value:"Force-Directed Layout (Organic Scatter)",id:"force-directed-layout-organic-scatter",level:2},{value:"Collision Avoidance",id:"collision-avoidance",level:3},{value:"Bin Packing (Tight Grid Layout)",id:"bin-packing-tight-grid-layout",level:2},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"core-collage-algorithms",children:"Core Collage Algorithms"})}),"\n",(0,s.jsx)(n.p,{children:"Mathematical and computational techniques for collage composition."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"edge-based-assembly-hockneyjoiners",children:"Edge-Based Assembly (Hockney/Joiners)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def edge_compatibility(edge1, edge2):\n    """Score how well two edges can connect (0-1)."""\n    return (\n        0.30 * line_continuation_score +\n        0.15 * curve_flow_score +\n        0.25 * color_harmony_score +\n        0.20 * semantic_coherence +  # CLIP similarity\n        0.10 * complexity_balance\n    )\n'})}),"\n",(0,s.jsx)(n.h3,{id:"edge-extraction",children:"Edge Extraction"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def extract_edges(image, edge_position='right'):\n    \"\"\"\n    Extract edge strip from image for compatibility scoring.\n    \"\"\"\n    edge_width = 20  # pixels\n\n    if edge_position == 'right':\n        return image[:, -edge_width:]\n    elif edge_position == 'left':\n        return image[:, :edge_width]\n    elif edge_position == 'top':\n        return image[:edge_width, :]\n    elif edge_position == 'bottom':\n        return image[-edge_width:, :]\n"})}),"\n",(0,s.jsx)(n.h3,{id:"line-continuation-score",children:"Line Continuation Score"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def line_continuation_score(edge1, edge2):\n    """\n    Score how well lines continue across edge boundary.\n    Uses Hough line detection.\n    """\n    # Detect lines in both edges\n    lines1 = cv2.HoughLinesP(edge1, 1, np.pi/180, 50)\n    lines2 = cv2.HoughLinesP(edge2, 1, np.pi/180, 50)\n\n    if lines1 is None or lines2 is None:\n        return 0.5  # Neutral score\n\n    # Find lines that approach the boundary\n    boundary_lines1 = [l for l in lines1 if approaches_boundary(l, \'right\')]\n    boundary_lines2 = [l for l in lines2 if approaches_boundary(l, \'left\')]\n\n    # Score angle continuity\n    score = 0\n    for l1 in boundary_lines1:\n        for l2 in boundary_lines2:\n            angle_diff = abs(get_angle(l1) - get_angle(l2))\n            score += max(0, 1 - angle_diff / 45)  # Within 45\xb0 = good\n\n    return min(1.0, score / max(len(boundary_lines1), 1))\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"poisson-blending-seamless-transitions",children:"Poisson Blending (Seamless Transitions)"}),"\n",(0,s.jsx)(n.p,{children:"Preserves gradients from source while matching boundary conditions."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def poisson_blend(source, target, mask, center):\n    """\n    Seamless clone using OpenCV\'s implementation.\n    """\n    # Ensure mask is binary\n    mask = (mask > 127).astype(np.uint8) * 255\n\n    # NORMAL_CLONE preserves source gradients\n    # MIXED_CLONE preserves stronger gradient from either\n    result = cv2.seamlessClone(\n        source, target, mask, center,\n        cv2.NORMAL_CLONE  # or cv2.MIXED_CLONE\n    )\n\n    return result\n'})}),"\n",(0,s.jsx)(n.h3,{id:"when-to-use-each-mode",children:"When to Use Each Mode"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"NORMAL_CLONE"}),": Standard seamless blending, preserves source fully"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"MIXED_CLONE"}),": Preserves dominant gradients (good for textured backgrounds)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"MONOCHROME_TRANSFER"}),": Transfers lighting only, not color"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"performance-notes",children:"Performance Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"GPU-parallelizable with Jacobi iteration"}),"\n",(0,s.jsx)(n.li,{children:"~20ms for 512\xd7512 on modern GPU"}),"\n",(0,s.jsx)(n.li,{children:"~100ms for 1080p on CPU"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"optimal-transport-color-harmonization",children:"Optimal Transport (Color Harmonization)"}),"\n",(0,s.jsx)(n.p,{children:'Wasserstein distance measures "effort" to transform color distributions.'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def color_transfer_optimal_transport(source, target):\n    """\n    Transfer color distribution from target to source\n    using optimal transport.\n    """\n    # Convert to LAB for perceptual uniformity\n    source_lab = cv2.cvtColor(source, cv2.COLOR_BGR2LAB)\n    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB)\n\n    # Compute means and covariances\n    source_mean, source_std = compute_stats(source_lab)\n    target_mean, target_std = compute_stats(target_lab)\n\n    # Affine transformation\n    result = (source_lab - source_mean) * (target_std / source_std) + target_mean\n\n    return cv2.cvtColor(result.astype(np.uint8), cv2.COLOR_LAB2BGR)\n\ndef compute_stats(lab_image):\n    """Compute per-channel mean and std."""\n    mean = np.mean(lab_image, axis=(0, 1))\n    std = np.std(lab_image, axis=(0, 1))\n    std = np.where(std == 0, 1, std)  # Avoid division by zero\n    return mean, std\n'})}),"\n",(0,s.jsx)(n.h3,{id:"sinkhorn-algorithm-full-optimal-transport",children:"Sinkhorn Algorithm (Full Optimal Transport)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def sinkhorn_color_transfer(source, target, reg=0.01, iterations=100):\n    """\n    More accurate but slower color transfer using Sinkhorn.\n    """\n    import ot  # POT library\n\n    # Flatten and sample colors\n    source_colors = source.reshape(-1, 3).astype(float)\n    target_colors = target.reshape(-1, 3).astype(float)\n\n    # Sample for speed (full image too slow)\n    n_samples = 1000\n    source_sample = source_colors[np.random.choice(len(source_colors), n_samples)]\n    target_sample = target_colors[np.random.choice(len(target_colors), n_samples)]\n\n    # Compute cost matrix (Euclidean distance in LAB)\n    M = ot.dist(source_sample, target_sample, metric=\'euclidean\')\n\n    # Sinkhorn transport\n    T = ot.sinkhorn(\n        np.ones(n_samples) / n_samples,\n        np.ones(n_samples) / n_samples,\n        M, reg\n    )\n\n    # Apply transport (simplified - full implementation more complex)\n    return source  # Placeholder\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"force-directed-layout-organic-scatter",children:"Force-Directed Layout (Organic Scatter)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def force_directed_layout(images, canvas_size, iterations=100):\n    """\n    Organic layout using physics simulation.\n    """\n    # Initialize random positions\n    for img in images:\n        img.position = np.random.rand(2) * canvas_size\n        img.velocity = np.zeros(2)\n\n    canvas_center = np.array(canvas_size) / 2\n\n    for _ in range(iterations):\n        for img in images:\n            force = np.zeros(2)\n\n            # Repulsion from other images\n            for other in images:\n                if img != other:\n                    diff = img.position - other.position\n                    dist = np.linalg.norm(diff)\n                    if dist < 1:\n                        dist = 1\n                    # Inverse square repulsion\n                    force += diff / (dist ** 2) * 100\n\n            # Attraction to center (prevent drift)\n            center_diff = canvas_center - img.position\n            force += center_diff * 0.01\n\n            # Boundary repulsion\n            for i in range(2):\n                if img.position[i] < 50:\n                    force[i] += 10\n                if img.position[i] > canvas_size[i] - 50:\n                    force[i] -= 10\n\n            # Apply force with damping\n            img.velocity = img.velocity * 0.9 + force * 0.1\n            img.position += img.velocity\n\n    return images\n'})}),"\n",(0,s.jsx)(n.h3,{id:"collision-avoidance",children:"Collision Avoidance"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def check_overlap(img1, img2):\n    """Check if two positioned images overlap."""\n    r1 = img1.get_rect()  # (x, y, w, h)\n    r2 = img2.get_rect()\n\n    return (r1.x < r2.x + r2.w and\n            r1.x + r1.w > r2.x and\n            r1.y < r2.y + r2.h and\n            r1.y + r1.h > r2.y)\n\ndef resolve_overlap(img1, img2):\n    """Push overlapping images apart."""\n    diff = img1.position - img2.position\n    dist = np.linalg.norm(diff)\n    if dist < 1:\n        diff = np.random.rand(2) - 0.5\n        dist = np.linalg.norm(diff)\n\n    # Move each image half the overlap distance\n    overlap = get_overlap_distance(img1, img2)\n    push = diff / dist * overlap / 2\n\n    img1.position += push\n    img2.position -= push\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"bin-packing-tight-grid-layout",children:"Bin Packing (Tight Grid Layout)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def guillotine_pack(images, canvas_width):\n    """\n    Pack images using guillotine algorithm.\n    Returns positions for each image.\n    """\n    # Sort by height (tallest first)\n    sorted_images = sorted(images, key=lambda x: -x.height)\n\n    # Initialize free rectangles\n    free_rects = [(0, 0, canvas_width, float(\'inf\'))]\n    positions = []\n\n    for img in sorted_images:\n        # Find best fit\n        best_rect = None\n        best_score = float(\'inf\')\n\n        for rect in free_rects:\n            if rect[2] >= img.width and rect[3] >= img.height:\n                score = rect[2] * rect[3]  # Area\n                if score < best_score:\n                    best_score = score\n                    best_rect = rect\n\n        if best_rect:\n            # Place image\n            positions.append((img, best_rect[0], best_rect[1]))\n\n            # Split remaining space (guillotine cut)\n            free_rects.remove(best_rect)\n            # Right split\n            if best_rect[2] - img.width > 0:\n                free_rects.append((\n                    best_rect[0] + img.width,\n                    best_rect[1],\n                    best_rect[2] - img.width,\n                    img.height\n                ))\n            # Bottom split\n            if best_rect[3] - img.height > 0:\n                free_rects.append((\n                    best_rect[0],\n                    best_rect[1] + img.height,\n                    best_rect[2],\n                    best_rect[3] - img.height\n                ))\n\n    return positions\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Operation"}),(0,s.jsx)(n.th,{children:"Mac M2"}),(0,s.jsx)(n.th,{children:"iPhone 15 Pro"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Grid layout (20 photos)"}),(0,s.jsx)(n.td,{children:"<50ms"}),(0,s.jsx)(n.td,{children:"<100ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Photo mosaic (10k tiles)"}),(0,s.jsx)(n.td,{children:"2s"}),(0,s.jsx)(n.td,{children:"5s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Force-directed (50 images, 100 iter)"}),(0,s.jsx)(n.td,{children:"200ms"}),(0,s.jsx)(n.td,{children:"500ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Poisson blending (512\xd7512)"}),(0,s.jsx)(n.td,{children:"20ms"}),(0,s.jsx)(n.td,{children:"50ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Hockney assembly (10 photos)"}),(0,s.jsx)(n.td,{children:"0.5s"}),(0,s.jsx)(n.td,{children:"2s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Color transfer (1080p)"}),(0,s.jsx)(n.td,{children:"100ms"}),(0,s.jsx)(n.td,{children:"300ms"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var i=r(96540);const s={},t=i.createContext(s);function o(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);