"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[62546],{28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>t});var l=r(96540);const s={},i=l.createContext(s);function a(e){const n=l.useContext(i);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),l.createElement(i.Provider,{value:n},e.children)}},89803:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});const l=JSON.parse('{"id":"skills/color_theory_palette_harmony_expert/references/perceptual-color-spaces","title":"Perceptual Color Spaces","description":"Why LAB/LCH Instead of RGB/HSV?","source":"@site/docs/skills/color_theory_palette_harmony_expert/references/perceptual-color-spaces.md","sourceDirName":"skills/color_theory_palette_harmony_expert/references","slug":"/skills/color_theory_palette_harmony_expert/references/perceptual-color-spaces","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/perceptual-color-spaces","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Perceptual Color Spaces","sidebar_label":"Perceptual Color Spaces","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Optimal Transport for Color...","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/optimal-transport"},"next":{"title":"Warm/Cool Temperature Class...","permalink":"/docs/skills/color_theory_palette_harmony_expert/references/temperature-classification"}}');var s=r(74848),i=r(28453);const a={title:"Perceptual Color Spaces",sidebar_label:"Perceptual Color Spaces",sidebar_position:5},t="Perceptual Color Spaces",o={},c=[{value:"Why LAB/LCH Instead of RGB/HSV?",id:"why-lablch-instead-of-rgbhsv",level:2},{value:"CIELAB (LAB) Space",id:"cielab-lab-space",level:2},{value:"CIE LCH (Cylindrical Representation of LAB)",id:"cie-lch-cylindrical-representation-of-lab",level:2},{value:"CIEDE2000: The Superior Perceptual Metric",id:"ciede2000-the-superior-perceptual-metric",level:2},{value:"Practical Implementation",id:"practical-implementation",level:2},{value:"Handling Edge Cases",id:"handling-edge-cases",level:2},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"perceptual-color-spaces",children:"Perceptual Color Spaces"})}),"\n",(0,s.jsx)(n.h2,{id:"why-lablch-instead-of-rgbhsv",children:"Why LAB/LCH Instead of RGB/HSV?"}),"\n",(0,s.jsx)(n.p,{children:"RGB and HSV are device-dependent and not perceptually uniform. A \u0394E of 10 in one region looks different than \u0394E of 10 in another."}),"\n",(0,s.jsx)(n.h2,{id:"cielab-lab-space",children:"CIELAB (LAB) Space"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"L: Lightness (0 = black, 100 = white)\na: Green (-128) to Red (+128)\nb: Blue (-128) to Yellow (+128)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Property:"})," Euclidean distance approximates perceived color difference:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u0394E*ab = \u221a((L\u2082 - L\u2081)\xb2 + (a\u2082 - a\u2081)\xb2 + (b\u2082 - b\u2081)\xb2)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"cie-lch-cylindrical-representation-of-lab",children:"CIE LCH (Cylindrical Representation of LAB)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"L: Lightness (same as LAB)\nC: Chroma = \u221a(a\xb2 + b\xb2)  (colorfulness, 0-180)\nH: Hue = atan2(b, a)    (angle in degrees, 0-360)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why LCH for Color Harmony?"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Hue angle directly corresponds to color wheel position"}),"\n",(0,s.jsx)(n.li,{children:'Chroma separates colorfulness from hue (easier to classify "vivid" vs "muted")'}),"\n",(0,s.jsx)(n.li,{children:"Lightness separates brightness independently"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Conversion Chain:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"RGB \u2192 sRGB (gamma correction) \u2192 XYZ (D65 illuminant) \u2192 LAB \u2192 LCH\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"ciede2000-the-superior-perceptual-metric",children:"CIEDE2000: The Superior Perceptual Metric"}),"\n",(0,s.jsxs)(n.p,{children:["The original \u0394E*ab formula has perceptual non-uniformities. ",(0,s.jsx)(n.strong,{children:"CIEDE2000 (published 2001, refined 2025)"})," addresses:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Lightness weighting (darker colors appear more different)"}),"\n",(0,s.jsx)(n.li,{children:"Chroma weighting (high-chroma colors more sensitive)"}),"\n",(0,s.jsx)(n.li,{children:"Hue rotation (blue region compressed)"}),"\n",(0,s.jsx)(n.li,{children:"Interaction between lightness, chroma, and hue"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Formula (simplified conceptual form):"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u0394E\u2080\u2080 = \u221a[(\u0394L'/k_L\xb7S_L)\xb2 + (\u0394C'/k_C\xb7S_C)\xb2 + (\u0394H'/k_H\xb7S_H)\xb2 + R_T\xb7(\u0394C'/k_C\xb7S_C)\xb7(\u0394H'/k_H\xb7S_H)]\n"})}),"\n",(0,s.jsx)(n.p,{children:"Where:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u0394L', \u0394C', \u0394H': Weighted lightness, chroma, hue differences"}),"\n",(0,s.jsx)(n.li,{children:"S_L, S_C, S_H: Weighting functions based on sample location"}),"\n",(0,s.jsx)(n.li,{children:"k_L, k_C, k_H: Parametric factors (typically 1.0)"}),"\n",(0,s.jsx)(n.li,{children:"R_T: Rotation term for blue region"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Implementation Notes (Sharma et al., 2005):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use small-angle approximations carefully"}),"\n",(0,s.jsx)(n.li,{children:"Handle hue discontinuity at 360\xb0/0\xb0"}),"\n",(0,s.jsx)(n.li,{children:"Numerical stability around neutral axis (C \u2248 0)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Performance:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"CIEDE2000 correlates better with human perception (r > 0.95)"}),"\n",(0,s.jsx)(n.li,{children:"Recommended for all palette distance calculations"}),"\n",(0,s.jsxs)(n.li,{children:["Python: ",(0,s.jsx)(n.code,{children:"colormath"})," library has vetted implementation"]}),"\n",(0,s.jsx)(n.li,{children:"Swift/Metal: Port from Sharma reference implementation"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"practical-implementation",children:"Practical Implementation"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Color Space Conversions:"})}),"\n",(0,s.jsx)(n.p,{children:"Use vetted libraries to avoid bugs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Python: colormath\nfrom colormath.color_objects import sRGBColor, LabColor\nfrom colormath.color_conversions import convert_color\n\nrgb = sRGBColor(0.5, 0.3, 0.8)\nlab = convert_color(rgb, LabColor)\n\n# Swift/Metal: Custom shaders\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"CIEDE2000 Implementation:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Python: colormath has vetted implementation\nfrom colormath.color_diff import delta_e_cie2000\n\ndelta_e = delta_e_cie2000(lab1, lab2)\n\n# Or use skimage\nfrom skimage.color import deltaE_ciede2000\ndelta_e = deltaE_ciede2000(lab1, lab2)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Palette Extraction:"})}),"\n",(0,s.jsx)(n.p,{children:"K-means in LAB space with smart initialization:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from sklearn.cluster import KMeans\n\n# Convert image to LAB\nimage_lab = rgb_to_lab(image)\npixels = image_lab.reshape(-1, 3)\n\n# Sample pixels (for large images)\nif len(pixels) > 10000:\n    indices = np.random.choice(len(pixels), 10000, replace=False)\n    pixels = pixels[indices]\n\n# K-means with k-means++ initialization\nkmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=42)\nkmeans.fit(pixels)\n\n# Palette = cluster centers\npalette = kmeans.cluster_centers_  # (5, 3) in LAB space\n\n# Weights = cluster sizes\nlabels = kmeans.labels_\nweights = np.bincount(labels) / len(labels)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"handling-edge-cases",children:"Handling Edge Cases"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Grayscale images (low chroma)\nif avg_chroma < 5:\n    # Treat as neutral, use lightness-based matching only\n    return lightness_only_compatibility(palette1, palette2)\n\n# Single-color images (very low entropy)\nif palette_entropy(palette) < 0.5:\n    # Dominant color match\n    return dominant_color_distance(palette1[0], palette2[0])\n\n# Very dark/light images (extreme lightness)\nif avg_lightness < 10 or avg_lightness > 90:\n    # Relax lightness balance constraint\n    scores['lightness_balance'] *= 0.5\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Sharma, G., Wu, W., & Dalal, E. N. (2005). "The CIEDE2000 color-difference formula: Implementation notes, supplementary test data, and mathematical observations." Color Research & Application.'}),"\n",(0,s.jsx)(n.li,{children:'Fairchild, M. D. (2013). "Color Appearance Models" (3rd ed.).'}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);