"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[15139],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var i=t(96540);const o={},s=i.createContext(o);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},31013:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"skills/event_detection_temporal_intelligence_expert/references/temporal-diversity-pipeline","title":"Temporal Diversity & Complete Pipeline","description":"Temporal Diversity for Photo Selection","source":"@site/docs/skills/event_detection_temporal_intelligence_expert/references/temporal-diversity-pipeline.md","sourceDirName":"skills/event_detection_temporal_intelligence_expert/references","slug":"/skills/event_detection_temporal_intelligence_expert/references/temporal-diversity-pipeline","permalink":"/docs/skills/event_detection_temporal_intelligence_expert/references/temporal-diversity-pipeline","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Temporal Diversity & Complete Pipeline","sidebar_label":"Temporal Diversity & Comple...","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"ST-DBSCAN Implementation Re...","permalink":"/docs/skills/event_detection_temporal_intelligence_expert/references/st-dbscan-implementation"},"next":{"title":"Photo Composition Critic","permalink":"/docs/skills/photo_composition_critic/"}}');var o=t(74848),s=t(28453);const r={title:"Temporal Diversity & Complete Pipeline",sidebar_label:"Temporal Diversity & Comple...",sidebar_position:4},l="Temporal Diversity & Complete Pipeline",a={},c=[{value:"Temporal Diversity for Photo Selection",id:"temporal-diversity-for-photo-selection",level:2},{value:"Method 1: Temporal Binning",id:"method-1-temporal-binning",level:3},{value:"Method 2: Temporal MMR (Maximal Marginal Relevance)",id:"method-2-temporal-mmr-maximal-marginal-relevance",level:3},{value:"Method 3: Event-Based Diversity",id:"method-3-event-based-diversity",level:3},{value:"Complete Event Detection Pipeline",id:"complete-event-detection-pipeline",level:2},{value:"Integration with Collage Assembly",id:"integration-with-collage-assembly",level:2},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"Selection Algorithm Comparison",id:"selection-algorithm-comparison",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"temporal-diversity--complete-pipeline",children:"Temporal Diversity & Complete Pipeline"})}),"\n",(0,o.jsx)(n.h2,{id:"temporal-diversity-for-photo-selection",children:"Temporal Diversity for Photo Selection"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Problem:"})," Without diversity constraints, all photos might come from single event (e.g., all from last vacation)."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Goal:"})," Ensure temporal spread across photo collection."]}),"\n",(0,o.jsx)(n.h3,{id:"method-1-temporal-binning",children:"Method 1: Temporal Binning"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def select_photos_with_temporal_diversity(photos, target_count, bin_size_days=7):\n    """\n    Select photos with temporal diversity.\n\n    Ensures photos span entire collection timeframe.\n\n    Args:\n        photos: List of PhotoPoint objects\n        target_count: Number of photos to select\n        bin_size_days: Size of temporal bins (e.g., 7 = one photo per week)\n\n    Returns:\n        Selected photos with temporal spread\n    """\n    # Sort by timestamp\n    photos = sorted(photos, key=lambda p: p.timestamp)\n\n    # Find time range\n    min_time = photos[0].timestamp\n    max_time = photos[-1].timestamp\n    total_days = (max_time - min_time).days\n\n    # Create temporal bins\n    num_bins = max(1, total_days // bin_size_days)\n    bins = [[] for _ in range(num_bins)]\n\n    for photo in photos:\n        days_since_start = (photo.timestamp - min_time).days\n        bin_idx = min(days_since_start // bin_size_days, num_bins - 1)\n        bins[bin_idx].append(photo)\n\n    # Select best photo from each bin\n    selected = []\n    photos_per_bin = max(1, target_count // num_bins)\n\n    for bin_photos in bins:\n        if not bin_photos:\n            continue\n\n        # Sort by quality\n        bin_photos.sort(key=lambda p: p.aesthetic_score, reverse=True)\n        selected.extend(bin_photos[:photos_per_bin])\n\n    # If under target, add more from best bins\n    if len(selected) < target_count:\n        remaining = target_count - len(selected)\n        all_remaining = [p for bin in bins for p in bin if p not in selected]\n        all_remaining.sort(key=lambda p: p.aesthetic_score, reverse=True)\n        selected.extend(all_remaining[:remaining])\n\n    return selected[:target_count]\n'})}),"\n",(0,o.jsx)(n.h3,{id:"method-2-temporal-mmr-maximal-marginal-relevance",children:"Method 2: Temporal MMR (Maximal Marginal Relevance)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def select_photos_temporal_mmr(photos, target_count, lambda_temporal=0.5):\n    """\n    Select photos using MMR with temporal diversity.\n\n    Args:\n        photos: List of PhotoPoint objects\n        target_count: Number to select\n        lambda_temporal: Diversity parameter (0.5 = balanced)\n\n    Returns:\n        Selected photos\n    """\n    selected = []\n\n    # Select first photo: highest quality\n    best_photo = max(photos, key=lambda p: p.aesthetic_score)\n    selected.append(best_photo)\n    remaining = [p for p in photos if p != best_photo]\n\n    # Select remaining using MMR\n    for _ in range(target_count - 1):\n        best_score = -float(\'inf\')\n        best_photo = None\n\n        for photo in remaining:\n            # Quality score\n            quality = photo.aesthetic_score\n\n            # Temporal diversity: min distance to selected photos\n            min_time_diff = min(\n                abs((photo.timestamp - s.timestamp).total_seconds())\n                for s in selected\n            )\n\n            # Normalize time diff (closer in time = higher penalty)\n            temporal_diversity = 1 - np.exp(-min_time_diff / (7 * 24 * 3600))\n\n            # MMR score\n            mmr_score = lambda_temporal * quality + (1 - lambda_temporal) * temporal_diversity\n\n            if mmr_score > best_score:\n                best_score = mmr_score\n                best_photo = photo\n\n        if best_photo:\n            selected.append(best_photo)\n            remaining.remove(best_photo)\n\n    return selected\n'})}),"\n",(0,o.jsx)(n.h3,{id:"method-3-event-based-diversity",children:"Method 3: Event-Based Diversity"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def select_photos_event_diversity(events, photos_per_event=2):\n    """\n    Select photos ensuring representation from each significant event.\n\n    Args:\n        events: List of Event objects (from ST-DBSCAN)\n        photos_per_event: Photos to select per event\n\n    Returns:\n        Selected photos\n    """\n    selected = []\n\n    # Sort events by significance\n    events.sort(key=lambda e: e.significance_score, reverse=True)\n\n    for event in events:\n        # Sort photos in event by quality\n        event.photos.sort(key=lambda p: p.aesthetic_score, reverse=True)\n        selected.extend(event.photos[:photos_per_event])\n\n    return selected\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"complete-event-detection-pipeline",children:"Complete Event Detection Pipeline"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class EventDetectionPipeline:\n    """\n    End-to-end pipeline for event detection and analysis.\n    """\n\n    def __init__(self):\n        self.st_dbscan = ST_DBSCAN()\n        self.event_scorer = EventSignificanceScorer()\n        self.place_recognizer = PlaceRecognizer()\n        self.shareability_predictor = ShareabilityPredictor()\n        self.life_event_detector = LifeEventDetector()\n\n    def process_photo_corpus(self, photos):\n        """\n        Process entire photo collection.\n\n        Returns:\n            dict with events, significance scores, shareability, etc.\n        """\n        results = {}\n\n        # 1. Cluster photos into events (ST-DBSCAN)\n        event_labels = self.st_dbscan.cluster(\n            photos,\n            eps_spatial=5000,\n            eps_temporal=8 * 3600,\n            min_pts=3\n        )\n\n        # Group photos by event\n        events = self.group_by_event(photos, event_labels)\n\n        # 2. Score each event\'s significance\n        for event in events:\n            event.significance_score, event.factors = \\\n                self.event_scorer.score_event(event.photos, photos)\n\n            # 3. Analyze location\n            event.place_analysis = self.place_recognizer.analyze_location(\n                event.median_lat, event.median_lon, photos\n            )\n\n            # 4. Generate event label\n            event.label = self.generate_event_label(event)\n\n        # 3. Predict shareability for each photo\n        for photo in photos:\n            event_context = self.find_photo_event(photo, events)\n            photo.shareability, photo.shareability_features = \\\n                self.shareability_predictor.predict(photo, event_context)\n\n        # 4. Detect life events\n        life_events = self.life_event_detector.detect_life_events(photos)\n\n        results[\'events\'] = events\n        results[\'life_events\'] = life_events\n        results[\'processed_photos\'] = photos\n\n        return results\n\n    def select_for_collage(self, processed_results, target_count=100):\n        """\n        Select photos for collage using event intelligence.\n\n        Priorities:\n        1. Life events (graduations, weddings, etc.)\n        2. High-significance events (vacations, celebrations)\n        3. High shareability\n        4. Temporal diversity\n        """\n        photos = processed_results[\'processed_photos\']\n        events = processed_results[\'events\']\n        life_events = processed_results[\'life_events\']\n\n        selected = []\n\n        # Priority 1: Life events (1-3 photos per life event)\n        for life_event in life_events:\n            life_event.photos.sort(key=lambda p: p.aesthetic_score, reverse=True)\n            selected.extend(life_event.photos[:3])\n\n        # Priority 2: Significant events (2 photos per high-sig event)\n        significant_events = [e for e in events if e.significance_score > 0.7]\n        significant_events.sort(key=lambda e: e.significance_score, reverse=True)\n\n        for event in significant_events[:20]:\n            event.photos.sort(key=lambda p: p.shareability, reverse=True)\n            selected.extend([p for p in event.photos[:2] if p not in selected])\n\n        # Priority 3: Fill remaining with temporal diversity\n        if len(selected) < target_count:\n            remaining_count = target_count - len(selected)\n            remaining_photos = [p for p in photos if p not in selected]\n\n            diverse_photos = select_photos_temporal_mmr(\n                remaining_photos, remaining_count, lambda_temporal=0.7\n            )\n            selected.extend(diverse_photos)\n\n        return selected[:target_count]\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"integration-with-collage-assembly",children:"Integration with Collage Assembly"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Modify Greedy Edge Growth to Use Event Intelligence:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def assemble_collage_event_aware(photo_database, target_size=(10, 10)):\n    """\n    Collage assembly with event-based prioritization.\n    """\n    # 1. Run event detection pipeline\n    pipeline = EventDetectionPipeline()\n    event_results = pipeline.process_photo_corpus(photo_database.all_photos)\n\n    # 2. Select diverse photos using event intelligence\n    candidate_photos = pipeline.select_for_collage(event_results, target_count=200)\n\n    # 3. Build collage using greedy edge growth\n    seed = max(candidate_photos, key=lambda p: p.significance * p.aesthetic)\n\n    canvas = Canvas(target_size)\n    canvas.place_photo(seed, position=\'center\')\n\n    placed_events = {seed.event_id}  # Track which events used\n\n    open_edges = PriorityQueue()\n    for edge in seed.edges:\n        open_edges.push(edge, priority=1.0)\n\n    while canvas.coverage < 0.8 and not open_edges.empty():\n        current_edge = open_edges.pop()\n\n        # Find compatible photos, preferring NEW events\n        candidates = photo_database.find_compatible_edges(current_edge, k=50)\n\n        # Filter: prefer photos from events not yet used\n        novel_event_candidates = [c for c in candidates\n                                 if c.event_id not in placed_events]\n\n        if novel_event_candidates:\n            candidates = novel_event_candidates\n\n        # Score candidates\n        for candidate in candidates:\n            local_fit = edge_compatibility(current_edge, candidate.opposite_edge)\n            event_bonus = 1.2 if candidate.event_id not in placed_events else 1.0\n            shareability_bonus = 1.0 + candidate.shareability * 0.2\n\n            total_score = local_fit * event_bonus * shareability_bonus\n\n            if total_score > 0.6:\n                canvas.place_photo(candidate, adjacent_to=current_edge)\n                placed_events.add(candidate.event_id)\n\n                for new_edge in candidate.new_open_edges:\n                    urgency = compute_edge_urgency(new_edge)\n                    open_edges.push(new_edge, priority=urgency)\n\n                break\n\n    canvas.refine_boundaries()\n    return canvas.render()\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Target Performance (Swift/Metal/Core ML):"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"ST-DBSCAN (10K photos):          < 2 seconds\nEvent significance scoring:       < 100ms per event\nShareability prediction:          < 50ms per photo\nPlace recognition (cached):       < 10ms per photo\nFull pipeline (10K photos):       < 5 seconds\nEvent-aware collage assembly:     < 15 seconds (100 photos)\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"selection-algorithm-comparison",children:"Selection Algorithm Comparison"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Method"}),(0,o.jsx)(n.th,{children:"Best For"}),(0,o.jsx)(n.th,{children:"Tradeoff"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Temporal Binning"}),(0,o.jsx)(n.td,{children:"Even time coverage"}),(0,o.jsx)(n.td,{children:"May miss quality"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Temporal MMR"}),(0,o.jsx)(n.td,{children:"Balanced quality + diversity"}),(0,o.jsx)(n.td,{children:"Slower computation"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Event-Based"}),(0,o.jsx)(n.td,{children:"Event representation"}),(0,o.jsx)(n.td,{children:"Depends on event quality"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Combined Pipeline"}),(0,o.jsx)(n.td,{children:"Production use"}),(0,o.jsx)(n.td,{children:"Most comprehensive"})]})]})]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}}}]);