"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[11128],{28453:(e,i,n)=>{n.d(i,{R:()=>a,x:()=>l});var t=n(96540);const s={},o=t.createContext(s);function a(e){const i=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:i},e.children)}},43878:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>r,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"skills/video_processing_editing/references/timeline-editing","title":"Timeline Editing Reference","description":"Multi-track timeline editing concepts and FFmpeg implementation.","source":"@site/docs/skills/video_processing_editing/references/timeline-editing.md","sourceDirName":"skills/video_processing_editing/references","slug":"/skills/video_processing_editing/references/timeline-editing","permalink":"/docs/skills/video_processing_editing/references/timeline-editing","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Timeline Editing Reference","sidebar_label":"Timeline Editing Reference","sidebar_position":3}}');var s=n(74848),o=n(28453);const a={title:"Timeline Editing Reference",sidebar_label:"Timeline Editing Reference",sidebar_position:3},l="Timeline Editing Reference",r={},c=[{value:"Timeline Concepts",id:"timeline-concepts",level:2},{value:"Video Track Structure",id:"video-track-structure",level:3},{value:"In/Out Points",id:"inout-points",level:3},{value:"Multi-Track Video Composition",id:"multi-track-video-composition",level:2},{value:"Layering Videos (Overlay)",id:"layering-videos-overlay",level:3},{value:"Split Screen",id:"split-screen",level:3},{value:"Insert Edit (Non-destructive)",id:"insert-edit-non-destructive",level:3},{value:"Overwrite Edit",id:"overwrite-edit",level:3},{value:"Multi-Track Audio",id:"multi-track-audio",level:2},{value:"Audio Layering",id:"audio-layering",level:3},{value:"Audio with Timeline Positioning",id:"audio-with-timeline-positioning",level:3},{value:"Ducking (Lower music when dialogue plays)",id:"ducking-lower-music-when-dialogue-plays",level:3},{value:"Keyframe Animation",id:"keyframe-animation",level:2},{value:"Position Animation",id:"position-animation",level:3},{value:"Opacity Animation",id:"opacity-animation",level:3},{value:"Scale Animation (Zoom)",id:"scale-animation-zoom",level:3},{value:"Time Remapping",id:"time-remapping",level:2},{value:"Speed Changes",id:"speed-changes",level:3},{value:"Reverse",id:"reverse",level:3},{value:"Frame Hold (Freeze Frame)",id:"frame-hold-freeze-frame",level:3},{value:"Markers and Sync Points",id:"markers-and-sync-points",level:2},{value:"Scene Detection for Auto-Markers",id:"scene-detection-for-auto-markers",level:3},{value:"Audio Sync with Clapboard",id:"audio-sync-with-clapboard",level:3},{value:"Align Two Clips by Audio",id:"align-two-clips-by-audio",level:3},{value:"Complex Timeline Example",id:"complex-timeline-example",level:2},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"timeline-editing-reference",children:"Timeline Editing Reference"})}),"\n",(0,s.jsx)(i.p,{children:"Multi-track timeline editing concepts and FFmpeg implementation."}),"\n",(0,s.jsx)(i.h2,{id:"timeline-concepts",children:"Timeline Concepts"}),"\n",(0,s.jsx)(i.h3,{id:"video-track-structure",children:"Video Track Structure"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{children:"Timeline:\n\u251c\u2500\u2500 Video Track 1 (Primary footage)\n\u251c\u2500\u2500 Video Track 2 (Overlay/B-roll)\n\u251c\u2500\u2500 Video Track 3 (Graphics/Text)\n\u251c\u2500\u2500 Audio Track 1 (Dialogue)\n\u251c\u2500\u2500 Audio Track 2 (Music)\n\u2514\u2500\u2500 Audio Track 3 (Sound effects)\n"})}),"\n",(0,s.jsx)(i.h3,{id:"inout-points",children:"In/Out Points"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Each clip has:\n# - IN point:  Where the clip starts on timeline\n# - OUT point: Where the clip ends on timeline\n# - SRC IN:    Where to start reading from source\n# - SRC OUT:   Where to stop reading from source\n\n# Example: Place 5s of source (from 10s-15s) at timeline position 30s\nffmpeg -i source.mp4 -ss 10 -t 5 -i bg.mp4 \\\n  -filter_complex "[1:v][0:v]overlay=enable=\'between(t,30,35)\'[out]" \\\n  -map "[out]" output.mp4\n'})}),"\n",(0,s.jsx)(i.h2,{id:"multi-track-video-composition",children:"Multi-Track Video Composition"}),"\n",(0,s.jsx)(i.h3,{id:"layering-videos-overlay",children:"Layering Videos (Overlay)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Layer video2 over video1 (picture-in-picture)\nffmpeg -i background.mp4 -i overlay.mp4 -filter_complex \\\n  \"[1:v]scale=320:240[pip]; \\\n   [0:v][pip]overlay=W-w-10:H-h-10:enable='between(t,5,15)'[out]\" \\\n  -map \"[out]\" -map 0:a \\\n  output.mp4\n\n# enable='between(t,5,15)': Only show overlay from 5s to 15s\n"})}),"\n",(0,s.jsx)(i.h3,{id:"split-screen",children:"Split Screen"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Side-by-side (2 videos)\nffmpeg -i left.mp4 -i right.mp4 -filter_complex \\\n  "[0:v]scale=960:1080[left]; \\\n   [1:v]scale=960:1080[right]; \\\n   [left][right]hstack[out]" \\\n  -map "[out]" output.mp4\n\n# Top/bottom split\nffmpeg -i top.mp4 -i bottom.mp4 -filter_complex \\\n  "[0:v]scale=1920:540[top]; \\\n   [1:v]scale=1920:540[bottom]; \\\n   [top][bottom]vstack[out]" \\\n  -map "[out]" output.mp4\n\n# 2x2 Grid\nffmpeg -i v1.mp4 -i v2.mp4 -i v3.mp4 -i v4.mp4 -filter_complex \\\n  "[0:v]scale=960:540[v1]; \\\n   [1:v]scale=960:540[v2]; \\\n   [2:v]scale=960:540[v3]; \\\n   [3:v]scale=960:540[v4]; \\\n   [v1][v2]hstack[top]; \\\n   [v3][v4]hstack[bottom]; \\\n   [top][bottom]vstack[out]" \\\n  -map "[out]" output.mp4\n'})}),"\n",(0,s.jsx)(i.h3,{id:"insert-edit-non-destructive",children:"Insert Edit (Non-destructive)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Insert clip B into clip A at specific point\n# A: 0-60s, insert B (10s) at A's 30s mark\n# Result: A[0-30], B[0-10], A[30-60]\n\n# Step 1: Split clip A\nffmpeg -i A.mp4 -t 30 -c copy A_part1.mp4\nffmpeg -i A.mp4 -ss 30 -c copy A_part2.mp4\n\n# Step 2: Concatenate with insert\necho \"file 'A_part1.mp4'\" > list.txt\necho \"file 'B.mp4'\" >> list.txt\necho \"file 'A_part2.mp4'\" >> list.txt\n\nffmpeg -f concat -safe 0 -i list.txt -c copy output.mp4\n"})}),"\n",(0,s.jsx)(i.h3,{id:"overwrite-edit",children:"Overwrite Edit"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Replace segment of clip A with clip B\n# A: 0-60s, overwrite 20-30s with B (10s)\n# Result: A[0-20], B[0-10], A[30-60]\n\nffmpeg -i A.mp4 -i B.mp4 -filter_complex \\\n  "[0:v]trim=0:20,setpts=PTS-STARTPTS[v1]; \\\n   [1:v]trim=0:10,setpts=PTS-STARTPTS[v2]; \\\n   [0:v]trim=30:60,setpts=PTS-STARTPTS[v3]; \\\n   [v1][v2][v3]concat=n=3:v=1[out]" \\\n  -map "[out]" output.mp4\n'})}),"\n",(0,s.jsx)(i.h2,{id:"multi-track-audio",children:"Multi-Track Audio"}),"\n",(0,s.jsx)(i.h3,{id:"audio-layering",children:"Audio Layering"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Mix multiple audio tracks with individual volume control\nffmpeg -i video.mp4 -i dialogue.wav -i music.mp3 -i sfx.wav \\\n  -filter_complex \\\n  "[1:a]volume=1.0[dlg]; \\\n   [2:a]volume=0.3[mus]; \\\n   [3:a]volume=0.5[sfx]; \\\n   [dlg][mus][sfx]amix=inputs=3:duration=first[aout]" \\\n  -map 0:v -map "[aout]" \\\n  -c:v copy -c:a aac -b:a 256k \\\n  output.mp4\n'})}),"\n",(0,s.jsx)(i.h3,{id:"audio-with-timeline-positioning",children:"Audio with Timeline Positioning"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Position audio at specific timeline points\nffmpeg -i video.mp4 -i sfx1.wav -i sfx2.wav -filter_complex \\\n  "[1:a]adelay=5000|5000[sfx1]; \\\n   [2:a]adelay=12000|12000[sfx2]; \\\n   [0:a][sfx1][sfx2]amix=inputs=3:duration=first[aout]" \\\n  -map 0:v -map "[aout]" \\\n  output.mp4\n\n# adelay values are in milliseconds\n# adelay=5000|5000 = delay 5s on left and right channels\n'})}),"\n",(0,s.jsx)(i.h3,{id:"ducking-lower-music-when-dialogue-plays",children:"Ducking (Lower music when dialogue plays)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Automatic ducking using sidechaincompress\nffmpeg -i video.mp4 -i music.mp3 -filter_complex \\\n  "[0:a]asplit[voice][duck_trigger]; \\\n   [1:a][duck_trigger]sidechaincompress=threshold=0.1:ratio=10:attack=100:release=1000[ducked_music]; \\\n   [voice][ducked_music]amix=inputs=2:duration=first[aout]" \\\n  -map 0:v -map "[aout]" \\\n  output.mp4\n'})}),"\n",(0,s.jsx)(i.h2,{id:"keyframe-animation",children:"Keyframe Animation"}),"\n",(0,s.jsx)(i.h3,{id:"position-animation",children:"Position Animation"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Move overlay from left to right over 5 seconds\nffmpeg -i bg.mp4 -i overlay.png -filter_complex \\\n  \"[1:v]scale=200:200[ovr]; \\\n   [0:v][ovr]overlay=x='min(t*100,W-200)':y=100[out]\" \\\n  -map \"[out]\" -t 10 output.mp4\n\n# x='min(t*100,W-200)': Move 100 pixels/second until reaching right edge\n"})}),"\n",(0,s.jsx)(i.h3,{id:"opacity-animation",children:"Opacity Animation"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Fade overlay in/out\nffmpeg -i bg.mp4 -i overlay.png -filter_complex \\\n  "[1:v]format=rgba,fade=in:st=0:d=1:alpha=1,fade=out:st=4:d=1:alpha=1[ovr]; \\\n   [0:v][ovr]overlay=10:10[out]" \\\n  -map "[out]" output.mp4\n\n# Fade in from 0-1s, fade out from 4-5s\n'})}),"\n",(0,s.jsx)(i.h3,{id:"scale-animation-zoom",children:"Scale Animation (Zoom)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Zoom effect (Ken Burns)\nffmpeg -i photo.jpg -filter_complex \\\n  \"zoompan=z='min(1.5,zoom+0.001)':d=300:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)':s=1920x1080\" \\\n  -c:v libx264 -t 10 output.mp4\n\n# z='min(1.5,zoom+0.001)': Slowly zoom to 1.5x\n# d=300: 300 frames duration (10s at 30fps)\n"})}),"\n",(0,s.jsx)(i.h2,{id:"time-remapping",children:"Time Remapping"}),"\n",(0,s.jsx)(i.h3,{id:"speed-changes",children:"Speed Changes"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# 2x speed (fast forward)\nffmpeg -i input.mp4 -filter:v "setpts=0.5*PTS" -filter:a "atempo=2.0" output.mp4\n\n# 0.5x speed (slow motion)\nffmpeg -i input.mp4 -filter:v "setpts=2.0*PTS" -filter:a "atempo=0.5" output.mp4\n\n# Variable speed (speed ramp)\n# Slow from 0-5s, normal 5-10s, fast 10-15s\nffmpeg -i input.mp4 -filter_complex \\\n  "[0:v]trim=0:5,setpts=2*PTS[slow]; \\\n   [0:v]trim=5:10,setpts=PTS-STARTPTS[normal]; \\\n   [0:v]trim=10:15,setpts=0.5*PTS-STARTPTS[fast]; \\\n   [slow][normal][fast]concat=n=3:v=1[out]" \\\n  -map "[out]" output.mp4\n'})}),"\n",(0,s.jsx)(i.h3,{id:"reverse",children:"Reverse"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Reverse video\nffmpeg -i input.mp4 -vf reverse output.mp4\n\n# Reverse segment\nffmpeg -i input.mp4 -filter_complex \\\n  "[0:v]trim=5:10,setpts=PTS-STARTPTS,reverse[rev]; \\\n   [0:v]trim=0:5,setpts=PTS-STARTPTS[before]; \\\n   [0:v]trim=10:20,setpts=PTS-STARTPTS[after]; \\\n   [before][rev][after]concat=n=3:v=1[out]" \\\n  -map "[out]" output.mp4\n'})}),"\n",(0,s.jsx)(i.h3,{id:"frame-hold-freeze-frame",children:"Frame Hold (Freeze Frame)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Freeze at 5 seconds for 3 seconds\nffmpeg -i input.mp4 -filter_complex \\\n  "[0:v]trim=0:5[before]; \\\n   [0:v]trim=5:5.033,loop=90:1:0[freeze]; \\\n   [0:v]trim=5:,setpts=PTS-STARTPTS+3/TB[after]; \\\n   [before][freeze][after]concat=n=3:v=1[out]" \\\n  -map "[out]" output.mp4\n\n# loop=90:1:0 = 90 frames loop (3s at 30fps)\n'})}),"\n",(0,s.jsx)(i.h2,{id:"markers-and-sync-points",children:"Markers and Sync Points"}),"\n",(0,s.jsx)(i.h3,{id:"scene-detection-for-auto-markers",children:"Scene Detection for Auto-Markers"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Detect scene changes (potential cut points)\nffmpeg -i input.mp4 -filter:v \"select='gt(scene,0.3)',showinfo\" -f null - 2>&1 | grep pts_time\n\n# Output timestamps where scene changes occur (threshold 0.3)\n"})}),"\n",(0,s.jsx)(i.h3,{id:"audio-sync-with-clapboard",children:"Audio Sync with Clapboard"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Find audio spike (clap) for sync\nffmpeg -i input.mp4 -af "silencedetect=n=-30dB:d=0.5" -f null - 2>&1 | grep silence_end\n\n# This detects when silence ends (loud sound begins)\n'})}),"\n",(0,s.jsx)(i.h3,{id:"align-two-clips-by-audio",children:"Align Two Clips by Audio"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:"# Step 1: Generate audio fingerprints\n# (Requires external tool like sync-audio-tracks or Praat)\n\n# Step 2: Apply calculated offset\nffmpeg -i video1.mp4 -itsoffset 0.250 -i video2.mp4 \\\n  -map 0:v -map 1:a \\\n  -c:v copy -c:a aac \\\n  synced_output.mp4\n"})}),"\n",(0,s.jsx)(i.h2,{id:"complex-timeline-example",children:"Complex Timeline Example"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'# Full multi-track edit:\n# - Background video (0-60s)\n# - B-roll insert (at 10-20s)\n# - Lower third graphic (at 5-8s)\n# - Dialogue audio (continuous)\n# - Music bed (ducked, 30% volume)\n\nffmpeg \\\n  -i main.mp4 \\\n  -i broll.mp4 \\\n  -i lowerthird.png \\\n  -i music.mp3 \\\n  -filter_complex \\\n  "\n  [0:v]trim=0:10,setpts=PTS-STARTPTS[main1];\n  [1:v]trim=0:10,setpts=PTS-STARTPTS[broll];\n  [0:v]trim=20:60,setpts=PTS-STARTPTS[main2];\n  [main1][broll][main2]concat=n=3:v=1[base];\n\n  [2:v]format=rgba,fade=in:st=0:d=0.5:alpha=1,fade=out:st=2.5:d=0.5:alpha=1[lt];\n  [base][lt]overlay=0:H-150:enable=\'between(t,5,8)\'[video];\n\n  [0:a]volume=1.0[dialogue];\n  [3:a]volume=0.3[music];\n  [dialogue][music]amix=inputs=2:duration=first[audio]\n  " \\\n  -map "[video]" -map "[audio]" \\\n  -c:v libx264 -crf 18 -preset medium \\\n  -c:a aac -b:a 192k \\\n  final_edit.mp4\n'})}),"\n",(0,s.jsx)(i.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan your timeline on paper first"})," - Draw out tracks, timing, transitions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Use intermediate files for complex edits"})," - Don't try to do everything in one command"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Match frame rates before combining"})," - Avoid judder from mismatched FPS"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Keep audio and video sync"})," - Always test playback at multiple points"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Use setpts=PTS-STARTPTS after trim"})," - Reset timestamps to avoid gaps"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Label your filter chains"})," - Use descriptive names like ",(0,s.jsx)(i.code,{children:"[dialogue]"})," not ",(0,s.jsx)(i.code,{children:"[a1]"})]}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsxs)(i.p,{children:["This reference covers timeline editing concepts. For transitions between clips, see the main SKILL.md. For export settings, see ",(0,s.jsx)(i.code,{children:"export-optimization.md"}),"."]})]})}function p(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);