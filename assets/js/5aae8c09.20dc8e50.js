"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[92433],{28453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>a});var t=s(96540);const o={},r=t.createContext(o);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),t.createElement(r.Provider,{value:n},e.children)}},71136:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"skills/collage_layout_expert/references/advanced-techniques","title":"Advanced Collage Techniques","description":"Cross-Photo Interactions","source":"@site/docs/skills/collage_layout_expert/references/advanced-techniques.md","sourceDirName":"skills/collage_layout_expert/references","slug":"/skills/collage_layout_expert/references/advanced-techniques","permalink":"/docs/skills/collage_layout_expert/references/advanced-techniques","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Advanced Collage Techniques","sidebar_label":"Advanced Collage Techniques","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Collage Layout Expert","permalink":"/docs/skills/collage_layout_expert/"},"next":{"title":"Core Collage Algorithms","permalink":"/docs/skills/collage_layout_expert/references/algorithms"}}');var o=s(74848),r=s(28453);const i={title:"Advanced Collage Techniques",sidebar_label:"Advanced Collage Techniques",sidebar_position:1},a="Advanced Collage Techniques",l={},c=[{value:"Cross-Photo Interactions",id:"cross-photo-interactions",level:2},{value:"Types of Interactions",id:"types-of-interactions",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Negative Space Awareness",id:"negative-space-awareness",level:2},{value:"Multi-Layer Compositing",id:"multi-layer-compositing",level:2},{value:"Narrative Sequences",id:"narrative-sequences",level:2},{value:"Simulated Annealing for Photo Swapping",id:"simulated-annealing-for-photo-swapping",level:2},{value:"Genetic Algorithms for Layout Evolution",id:"genetic-algorithms-for-layout-evolution",level:2},{value:"Constraint Satisfaction Problem (CSP) Formulation",id:"constraint-satisfaction-problem-csp-formulation",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"advanced-collage-techniques",children:"Advanced Collage Techniques"})}),"\n",(0,o.jsx)(n.h2,{id:"cross-photo-interactions",children:"Cross-Photo Interactions"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Concept"}),': Photos "talk" to each other across boundaries.']}),"\n",(0,o.jsx)(n.h3,{id:"types-of-interactions",children:"Types of Interactions"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gesture-Response Pairs"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Photo A (left): Person waving to the right \u2192\nPhoto B (right): Person waving to the left \u2190\nResult: Two people greeting each other\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Pointing Interactions"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Photo A: Person pointing right \u2192\nPhoto B: Interesting object/scene\nResult: Person pointing at the object\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gaze Direction"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Photo A: Person looking right \u2192\nPhoto B: Beautiful landscape\nResult: Person admiring the view\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Passing Objects"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Photo A (top): Hands reaching down \u2193\nPhoto B (bottom): Hands reaching up \u2191\nResult: Handing something between photos\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"implementation",children:"Implementation"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class InteractionDetector:\n    def __init__(self):\n        self.pose_estimator = load_pose_model()\n        self.action_classifier = load_action_model()\n\n    def find_interaction_pairs(self, photo1, photo2, edge_pair):\n        \"\"\"Find natural interactions across photo boundary.\"\"\"\n        people1 = self.detect_people(photo1)\n        people2 = self.detect_people(photo2)\n\n        interactions = []\n        for p1 in people1:\n            if not self.is_near_edge(p1, edge_pair[0]):\n                continue\n\n            gesture1 = self.detect_gesture(photo1, p1.bbox)\n\n            for p2 in people2:\n                if not self.is_near_edge(p2, edge_pair[1]):\n                    continue\n\n                gesture2 = self.detect_gesture(photo2, p2.bbox)\n                score = self.score_interaction(gesture1, gesture2)\n\n                if score > 0.5:\n                    interactions.append({\n                        'person1': p1,\n                        'person2': p2,\n                        'type': self.classify_interaction(gesture1, gesture2),\n                        'score': score\n                    })\n\n        return interactions\n\n    def score_interaction(self, gesture1, gesture2):\n        \"\"\"Natural interaction pairs.\"\"\"\n        NATURAL_PAIRS = {\n            ('waving', 'waving'): 0.9,\n            ('waving', 'looking'): 0.8,\n            ('pointing', 'looking'): 0.85,\n            ('reaching', 'reaching'): 0.7,\n            ('throwing', 'catching'): 0.95,\n            ('looking_right', 'looking_left'): 0.7,\n        }\n\n        key = (gesture1['gesture'], gesture2['gesture'])\n        base_score = NATURAL_PAIRS.get(key, 0.3)\n\n        if self.directions_align(gesture1, gesture2):\n            base_score += 0.1\n\n        return min(1.0, base_score)\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"negative-space-awareness",children:"Negative Space Awareness"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"The Insight"}),": Empty space is as important as filled space."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class NegativeSpaceAnalyzer:\n    def analyze_negative_space(self, photo, subject_mask):\n        \"\"\"Analyze quality and distribution of negative space.\"\"\"\n        h, w = photo.shape[:2]\n        negative_mask = 1 - subject_mask\n\n        breathing_room = {\n            'top': negative_mask[:h//3, :].mean(),\n            'bottom': negative_mask[2*h//3:, :].mean(),\n            'left': negative_mask[:, :w//3].mean(),\n            'right': negative_mask[:, 2*w//3:].mean(),\n            'overall': negative_mask.mean()\n        }\n\n        background = photo * negative_mask[..., None]\n        bg_variance = np.var(background)\n        quality = 1.0 - min(1.0, bg_variance / 1000.0)\n\n        return {\n            'distribution': breathing_room,\n            'quality': quality,\n            'total_ratio': breathing_room['overall']\n        }\n\n    def match_negative_space(self, analysis1, analysis2):\n        \"\"\"Find complementary negative space patterns.\"\"\"\n        # Subject on left + Subject on right = good pair\n        if (analysis1['distribution']['left'] < 0.3 and\n            analysis2['distribution']['right'] < 0.3):\n            return 'left_right_pair', 0.9\n\n        if (analysis1['distribution']['bottom'] < 0.3 and\n            analysis2['distribution']['top'] < 0.3):\n            return 'top_bottom_pair', 0.9\n\n        if (analysis1['distribution']['right'] > 0.6 and\n            analysis2['distribution']['right'] > 0.6):\n            return 'right_stack', 0.7\n\n        return None, 0.0\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Use Case"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Photo A: Person on left, empty beach on right\nPhoto B: Sunset on right, empty ocean on left\n\nComposite: Person (from A) on left + Sunset (from B) on right\nResult: Person appears to be watching the sunset\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"multi-layer-compositing",children:"Multi-Layer Compositing"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Concept"}),": Create depth through foreground/midground/background layers."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class LayeredCollage:\n    def create_layered_composition(self, photos):\n        """Build composition with depth layers."""\n\n        background_photos = self.select_backgrounds(photos)\n        midground_photos = self.select_midgrounds(photos)\n        foreground_photos = self.select_foregrounds(photos)\n\n        layers = {\n            \'background\': self.create_background_layer(background_photos),\n            \'midground\': self.create_midground_layer(midground_photos),\n            \'foreground\': self.create_foreground_layer(foreground_photos)\n        }\n\n        canvas = self.composite_layers(layers)\n        return canvas\n\n    def select_backgrounds(self, photos):\n        """Select photos suitable for background layer."""\n        candidates = []\n\n        for photo in photos:\n            score = 0.0\n\n            if self.contains_sky(photo):\n                score += 0.5\n            if self.is_landscape_oriented(photo):\n                score += 0.3\n\n            depth = self.estimate_depth(photo)\n            if depth.mean() > 0.7:\n                score += 0.2\n\n            if score > 0.5:\n                candidates.append((photo, score))\n\n        return [p for p, s in sorted(candidates, key=lambda x: -x[1])]\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"narrative-sequences",children:"Narrative Sequences"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Concept"}),": Tell a story across the collage."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class NarrativeCollageBuilder:\n    def build_story_collage(self, photos, story_type='journey'):\n        \"\"\"Build collage that tells a story.\"\"\"\n\n        if story_type == 'journey':\n            # Start \u2192 Travel \u2192 Arrive \u2192 Experience \u2192 Depart\n            segments = self.segment_by_story_arc(photos)\n            layout = self.create_flow_layout(segments)\n\n        elif story_type == 'day_in_life':\n            # Morning \u2192 Midday \u2192 Evening \u2192 Night\n            segments = self.segment_by_time_of_day(photos)\n            layout = self.create_temporal_gradient_layout(segments)\n\n        elif story_type == 'emotion_arc':\n            # Calm \u2192 Excitement \u2192 Joy \u2192 Reflection\n            segments = self.segment_by_emotion(photos)\n            layout = self.create_emotional_flow_layout(segments)\n\n        return layout\n\n    def segment_by_story_arc(self, photos):\n        \"\"\"Cluster photos into narrative segments.\"\"\"\n        features = []\n        for photo in photos:\n            feat = np.concatenate([\n                photo.clip_embedding,\n                self.encode_location(photo.gps),\n                self.encode_time(photo.timestamp)\n            ])\n            features.append(feat)\n\n        segments = self.hierarchical_cluster(features, n_clusters=5)\n\n        segments = sorted(segments,\n                         key=lambda s: np.mean([p.timestamp for p in s]))\n\n        return {\n            'beginning': segments[0],\n            'rising': segments[1],\n            'climax': segments[2],\n            'falling': segments[3],\n            'end': segments[4]\n        }\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"simulated-annealing-for-photo-swapping",children:"Simulated Annealing for Photo Swapping"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"When to Use"}),": User explicitly wants to explore alternative arrangements, or initial assembly has suboptimal global aesthetics."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"What It Does"}),": Randomly swaps photos in the existing collage and accepts swaps that improve the global energy function."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def refine_with_simulated_annealing(canvas, max_iters=10000):\n    """\n    Refine existing collage by swapping photos.\n    NOTE: This is a refinement, NOT the primary assembly algorithm.\n    """\n    T = 10.0\n    T_min = 0.01\n    cooling_rate = 0.95\n\n    current_energy = compute_total_energy(canvas)\n    best_canvas = canvas.copy()\n    best_energy = current_energy\n\n    for iteration in range(max_iters):\n        canvas_new = canvas.copy()\n        i, j = random.sample(range(len(canvas.shards)), 2)\n        canvas_new.swap_shards(i, j)\n\n        new_energy = compute_total_energy(canvas_new)\n        delta_E = new_energy - current_energy\n\n        if delta_E < 0:\n            canvas = canvas_new\n            current_energy = new_energy\n        else:\n            acceptance_prob = np.exp(-delta_E / T)\n            if np.random.random() < acceptance_prob:\n                canvas = canvas_new\n                current_energy = new_energy\n\n        if current_energy < best_energy:\n            best_canvas = canvas.copy()\n            best_energy = current_energy\n\n        T = max(T_min, T * cooling_rate)\n\n    return best_canvas\n'})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Performance"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Time: 5-15 seconds for 50 photos"}),"\n",(0,o.jsx)(n.li,{children:"Quality gain: 5-10% improvement in global aesthetics"}),"\n",(0,o.jsx)(n.li,{children:"Diminishing returns after 1000-2000 iterations"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"When NOT to Use"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Interactive editing (too slow)"}),"\n",(0,o.jsx)(n.li,{children:"Initial assembly (use greedy edge growth)"}),"\n",(0,o.jsx)(n.li,{children:"User wants predictable results (stochastic)"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"genetic-algorithms-for-layout-evolution",children:"Genetic Algorithms for Layout Evolution"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Concept"}),": Maintain population of collages, breed and mutate to explore layout space."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Operations"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Crossover"}),": Swap regions between two parent collages"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Mutation"}),": Random perturbations (rotate, scale, move shards)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Selection"}),": Keep top-scoring collages, discard poor ones"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Performance"}),": Even slower than simulated annealing, typically for offline rendering."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"constraint-satisfaction-problem-csp-formulation",children:"Constraint Satisfaction Problem (CSP) Formulation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Concept"}),": Define collage assembly as constraint satisfaction problem."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Constraints"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Edge compatibility > threshold"}),"\n",(0,o.jsx)(n.li,{children:"No overlaps (or controlled overlaps for Hockney)"}),"\n",(0,o.jsx)(n.li,{children:"Minimum global aesthetics score"}),"\n",(0,o.jsx)(n.li,{children:"Semantic coherence within range"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Listed as alternative strategy, not recommended for MVP."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);